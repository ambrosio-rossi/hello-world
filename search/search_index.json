{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Project XSK What Is XSK? Overview Project XSK is a compatible environment for applications based on SAP HANA Extended Application Services (XS). You can deploy it separately from a SAP HANA instance as a Docker container on Kubernetes , on Cloud Foundry , or even locally in standalone mode. The compatibility stack is an extension of the Eclipse Dirigible cloud development platform. Try it Out Architecture Comparison with Other Solutions Aspect XSK Others Description No code modifications \u2705 \u274c Preserving the existing artifacts and APIs No change of development model \u2705 \u274c No further education needed Single-step guided migration \u2705 \u274c Wizard-based migration assistant is built-in Complete end-to-end stack \u2705 \u274c Covers all the features in a single distribution Can be deployed anywhere \u2705 \u274c Kubernetes, Kyma, Docker, Cloud Foundry, Buildpack, XSA, and on your PC Zero-cost migration \u2705 \u274c No additional cost for the migration itself as well as the running cost is expected to be less Open source \u2705 \u274c Entirely open source and free Who Uses It? If you have an existing SAP HANA Extended Application Services ( XS classic application ), which currently runs on your SAP HANA database and you want to scale it out horizontally on a hyperscaler of your choice, XSK is your solution! It also provides the migration tooling for transferring the application code from your existing SAP HANA. By preserving the existing artifacts, APIs and development model, you can leverage your existing knowledge and experience to continue running existing applications and even to build new ones, if you want. Is It Free? XSK is an open source project provided by SAP on GitHub . It is under the Apache 2.0 License . You can help us improve the project by following the Contribution Guidelines and creating issues . Releases You can find all the different distributions of the XSK project at https://github.com/SAP/xsk/releases along with the instructions how to deploy them on the target platforms. Contact Us We run the project in compliance with the high standard of transparency and openness. In case of questions or suggestions you are welcome to our public discussions space. We have a public Slack channel as well.","title":"Welcome"},{"location":"#project-xsk","text":"","title":"Project XSK"},{"location":"#what-is-xsk","text":"","title":"What Is XSK?"},{"location":"#overview","text":"Project XSK is a compatible environment for applications based on SAP HANA Extended Application Services (XS). You can deploy it separately from a SAP HANA instance as a Docker container on Kubernetes , on Cloud Foundry , or even locally in standalone mode. The compatibility stack is an extension of the Eclipse Dirigible cloud development platform. Try it Out","title":"Overview"},{"location":"#architecture","text":"","title":"Architecture"},{"location":"#comparison-with-other-solutions","text":"Aspect XSK Others Description No code modifications \u2705 \u274c Preserving the existing artifacts and APIs No change of development model \u2705 \u274c No further education needed Single-step guided migration \u2705 \u274c Wizard-based migration assistant is built-in Complete end-to-end stack \u2705 \u274c Covers all the features in a single distribution Can be deployed anywhere \u2705 \u274c Kubernetes, Kyma, Docker, Cloud Foundry, Buildpack, XSA, and on your PC Zero-cost migration \u2705 \u274c No additional cost for the migration itself as well as the running cost is expected to be less Open source \u2705 \u274c Entirely open source and free","title":"Comparison with Other Solutions"},{"location":"#who-uses-it","text":"If you have an existing SAP HANA Extended Application Services ( XS classic application ), which currently runs on your SAP HANA database and you want to scale it out horizontally on a hyperscaler of your choice, XSK is your solution! It also provides the migration tooling for transferring the application code from your existing SAP HANA. By preserving the existing artifacts, APIs and development model, you can leverage your existing knowledge and experience to continue running existing applications and even to build new ones, if you want.","title":"Who Uses It?"},{"location":"#is-it-free","text":"XSK is an open source project provided by SAP on GitHub . It is under the Apache 2.0 License . You can help us improve the project by following the Contribution Guidelines and creating issues .","title":"Is It Free?"},{"location":"#releases","text":"You can find all the different distributions of the XSK project at https://github.com/SAP/xsk/releases along with the instructions how to deploy them on the target platforms.","title":"Releases"},{"location":"#contact-us","text":"We run the project in compliance with the high standard of transparency and openness. In case of questions or suggestions you are welcome to our public discussions space. We have a public Slack channel as well.","title":"Contact Us"},{"location":"community/","text":"Community Welcome to the community page for contributors! Here you will find resources to help you create even better documentation for XSK. Contributor Guide XSK is an open source project, which means that you can propose contributions by sending pull requests through GitHub . Before you get started, here are some prerequisites that you need to complete: Legal Considerations You must be aware of the Apache License (which describes contributions) and accept the Developer Certificate of Origin. This is common practice in major Open Source projects. To make this process as simple as possible, we are using CLA assistant for individual contributions. CLA assistant is an open source tool that integrates with GitHub very well and enables a one-click experience for accepting the CLA. For more information see the Contributor Guide . Style Guide In this section we have outlined text stylizing options and for what elements they should be used. If everyone follows it, we will have visually consistent documentation . Bold How it looks as text: Bold Text How it looks in markdown: **Bold Text** Use it for: UI elements Navigation paths Monospace How it looks as text: Monospace Text How it looks in markdown: `Monospace Text` Use it for: File names and extensions Terms File paths Monospace/Bold How it looks as text: Monospace/Bold Text How it looks in markdown: **`Monospace/Bold Text`** Use it for: User input Headings How it looks: Use Heading 1 for the titles Heading 2 is for main topics Continue with Heading 3 and 4 where needed Structure your topic with no more than 3 heading levels(heading 2, 3 and 4) Join the Discussion Reach out to other contributors and join in the discussion around project XSK at our public discussions space in GitHub. In case you want to participate to the regular meetings such as plannings and reviews, let us know.","title":"Community"},{"location":"community/#community","text":"Welcome to the community page for contributors! Here you will find resources to help you create even better documentation for XSK.","title":"Community"},{"location":"community/#contributor-guide","text":"XSK is an open source project, which means that you can propose contributions by sending pull requests through GitHub . Before you get started, here are some prerequisites that you need to complete:","title":"Contributor Guide"},{"location":"community/#legal-considerations","text":"You must be aware of the Apache License (which describes contributions) and accept the Developer Certificate of Origin. This is common practice in major Open Source projects. To make this process as simple as possible, we are using CLA assistant for individual contributions. CLA assistant is an open source tool that integrates with GitHub very well and enables a one-click experience for accepting the CLA. For more information see the Contributor Guide .","title":"Legal Considerations"},{"location":"community/#style-guide","text":"In this section we have outlined text stylizing options and for what elements they should be used. If everyone follows it, we will have visually consistent documentation . Bold How it looks as text: Bold Text How it looks in markdown: **Bold Text** Use it for: UI elements Navigation paths Monospace How it looks as text: Monospace Text How it looks in markdown: `Monospace Text` Use it for: File names and extensions Terms File paths Monospace/Bold How it looks as text: Monospace/Bold Text How it looks in markdown: **`Monospace/Bold Text`** Use it for: User input Headings How it looks: Use Heading 1 for the titles Heading 2 is for main topics Continue with Heading 3 and 4 where needed Structure your topic with no more than 3 heading levels(heading 2, 3 and 4)","title":"Style Guide"},{"location":"community/#join-the-discussion","text":"Reach out to other contributors and join in the discussion around project XSK at our public discussions space in GitHub. In case you want to participate to the regular meetings such as plannings and reviews, let us know.","title":"Join the Discussion"},{"location":"api/","text":"APIs Overview This page lists the SAP HANA XS Classic JavaScript APIs and whether they are supported by XSK. Reference SAP HANA XS Classic JavaScript APIs For more information on the APIs, see SAP HANA Extended Application Services (SAP HANA XS) API . Namespaces $ Classes Class Supported Application No Session Yes Members Member Supported application No request Yes response Yes session Yes Methods Method Supported import(package, library) Yes import(path) Yes $.db Classes Class Supported CallableStatement Yes Connection Yes ParameterMetaData Yes PreparedStatement Yes ResultSet Yes ResultSetMetaData Yes SQLException No (did not exist) Members Member Supported isolation No types No Methods Method Supported getConnection Partially (parameters ignored) Type Definitions Definition Supported configurationObject No $.hdb Classes Class Supported ColumnMetadata Yes Connection Yes ProcedureResult Yes ResultSet Yes ResultSetIterator Yes ResultSetMetaData Yes SQLException No (did not exist) Members Member Supported isolation No types No Methods Method Supported getConnection Partially (parameters ignored) $.jobs Classes Class Supported Job Yes JobLog No JobSchedules No $.net Classes Class Supported Destination Yes Mail Yes SMTPConnection Yes Members Member Supported http Yes $.net.http Classes Class Supported Client Yes Destination Yes Request Yes Methods Method Supported readDestination Yes* - package ignored, read from SAP BTP Destination service $.security Classes Class Supported AntiVirus No Store Yes $.security.crypto Methods Member Supported md5 No sha1 No sha256 No $.security.x509 Methods Method Supported getIssuer No getSubject No $.text.analysis Classes Class Supported Session No $.text.mining Classes Class Supported Session No $.trace Methods Method Supported debug Yes error Yes fatal Yes info Yes isDebugEnabled Yes isErrorEnabled Yes isFatalEnabled Yes isInfoEnabled Yes isWarningEnabled Yes warning Yes $.util Classes Class Supported SAXParser No Zip Partially - no password support Methods Method Supported createdUuid Yes stringify Yes $.util.codec Methods Method Supported decodeBase64 Yes decodeHex Yes encodeBase64 Yes encodeHex Yes $.util.compression Methods Method Supported gunzip No gzip No $.util.sql Methods Method Supported isValidParam No $.web Classes Class Supported Body Yes EntityList Yes TupelList Yes WebEntityRequest Yes WebEntityResponse Yes WebRequest Yes WebResponse Yes","title":"APIs"},{"location":"api/#apis","text":"","title":"APIs"},{"location":"api/#overview","text":"This page lists the SAP HANA XS Classic JavaScript APIs and whether they are supported by XSK.","title":"Overview"},{"location":"api/#reference","text":"SAP HANA XS Classic JavaScript APIs For more information on the APIs, see SAP HANA Extended Application Services (SAP HANA XS) API .","title":"Reference"},{"location":"api/#namespaces","text":"","title":"Namespaces"},{"location":"api/#_1","text":"","title":"$"},{"location":"api/#classes","text":"Class Supported Application No Session Yes","title":"Classes"},{"location":"api/#members","text":"Member Supported application No request Yes response Yes session Yes","title":"Members"},{"location":"api/#methods","text":"Method Supported import(package, library) Yes import(path) Yes","title":"Methods"},{"location":"api/#db","text":"","title":"$.db"},{"location":"api/#classes_1","text":"Class Supported CallableStatement Yes Connection Yes ParameterMetaData Yes PreparedStatement Yes ResultSet Yes ResultSetMetaData Yes SQLException No (did not exist)","title":"Classes"},{"location":"api/#members_1","text":"Member Supported isolation No types No","title":"Members"},{"location":"api/#methods_1","text":"Method Supported getConnection Partially (parameters ignored)","title":"Methods"},{"location":"api/#type-definitions","text":"Definition Supported configurationObject No","title":"Type Definitions"},{"location":"api/#hdb","text":"","title":"$.hdb"},{"location":"api/#classes_2","text":"Class Supported ColumnMetadata Yes Connection Yes ProcedureResult Yes ResultSet Yes ResultSetIterator Yes ResultSetMetaData Yes SQLException No (did not exist)","title":"Classes"},{"location":"api/#members_2","text":"Member Supported isolation No types No","title":"Members"},{"location":"api/#methods_2","text":"Method Supported getConnection Partially (parameters ignored)","title":"Methods"},{"location":"api/#jobs","text":"","title":"$.jobs"},{"location":"api/#classes_3","text":"Class Supported Job Yes JobLog No JobSchedules No","title":"Classes"},{"location":"api/#net","text":"","title":"$.net"},{"location":"api/#classes_4","text":"Class Supported Destination Yes Mail Yes SMTPConnection Yes","title":"Classes"},{"location":"api/#members_3","text":"Member Supported http Yes","title":"Members"},{"location":"api/#nethttp","text":"","title":"$.net.http"},{"location":"api/#classes_5","text":"Class Supported Client Yes Destination Yes Request Yes","title":"Classes"},{"location":"api/#methods_3","text":"Method Supported readDestination Yes* - package ignored, read from SAP BTP Destination service","title":"Methods"},{"location":"api/#security","text":"","title":"$.security"},{"location":"api/#classes_6","text":"Class Supported AntiVirus No Store Yes","title":"Classes"},{"location":"api/#securitycrypto","text":"","title":"$.security.crypto"},{"location":"api/#methods_4","text":"Member Supported md5 No sha1 No sha256 No","title":"Methods"},{"location":"api/#securityx509","text":"","title":"$.security.x509"},{"location":"api/#methods_5","text":"Method Supported getIssuer No getSubject No","title":"Methods"},{"location":"api/#textanalysis","text":"","title":"$.text.analysis"},{"location":"api/#classes_7","text":"Class Supported Session No","title":"Classes"},{"location":"api/#textmining","text":"","title":"$.text.mining"},{"location":"api/#classes_8","text":"Class Supported Session No","title":"Classes"},{"location":"api/#trace","text":"","title":"$.trace"},{"location":"api/#methods_6","text":"Method Supported debug Yes error Yes fatal Yes info Yes isDebugEnabled Yes isErrorEnabled Yes isFatalEnabled Yes isInfoEnabled Yes isWarningEnabled Yes warning Yes","title":"Methods"},{"location":"api/#util","text":"","title":"$.util"},{"location":"api/#classes_9","text":"Class Supported SAXParser No Zip Partially - no password support","title":"Classes"},{"location":"api/#methods_7","text":"Method Supported createdUuid Yes stringify Yes","title":"Methods"},{"location":"api/#utilcodec","text":"","title":"$.util.codec"},{"location":"api/#methods_8","text":"Method Supported decodeBase64 Yes decodeHex Yes encodeBase64 Yes encodeHex Yes","title":"Methods"},{"location":"api/#utilcompression","text":"","title":"$.util.compression"},{"location":"api/#methods_9","text":"Method Supported gunzip No gzip No","title":"Methods"},{"location":"api/#utilsql","text":"","title":"$.util.sql"},{"location":"api/#methods_10","text":"Method Supported isValidParam No","title":"Methods"},{"location":"api/#web","text":"","title":"$.web"},{"location":"api/#classes_10","text":"Class Supported Body Yes EntityList Yes TupelList Yes WebEntityRequest Yes WebEntityResponse Yes WebRequest Yes WebResponse Yes","title":"Classes"},{"location":"api/db/","text":"$.db $.db represents the namespace for database access. Overview Definition: https://github.com/SAP/xsk/issues/15 Module: db/db.js Status: alpha Sample Usage let connection ; try { connection = $ . db . getConnection (); // Make sure to create the table only once try { connection . prepareStatement ( \"CREATE TABLE SAMPLE_USERS (NAME varchar(255), AGE int)\" ). execute (); } catch ( e ) { // Do nothing, as the table already exists } let insertStatement = connection . prepareStatement ( \"INSERT INTO SAMPLE_USERS (NAME, AGE) VALUES ('Bob', 20)\" ); insertStatement . executeUpdate (); insertStatement . close (); insertStatement = connection . prepareStatement ( \"INSERT INTO SAMPLE_USERS (NAME, AGE) VALUES ('Alice', 21)\" ); insertStatement . executeUpdate (); insertStatement . close (); let selectStatement = connection . prepareStatement ( \"SELECT * FROM SAMPLE_USERS\" ); selectStatement . execute (); let resultSet = selectStatement . getResultSet (); let names = []; while ( resultSet . next ()) { names . push ( resultSet . getString ( 1 )); } selectStatement . close (); resultSet . close (); $ . response . setBody ( names . toString ()); } catch ( e ) { if ( connection ) { connection . rollback (); } $ . response . setBody ( \"Transaction was rolled back: \" + e . message ); } finally { connection . close (); } Functions Function Description Returns getConnection() Returns a connection to the database. $.db.Connection Classes $.db.Connection Functions Function Description Returns close() Closes the connection. - commit() Commits the changes. - isClosed() Checks if the connection is closed. boolean prepareCall(statement) Prepares a stored procedure for execution $.db.CallableStatement prepareStatement(statement) Prepares a statement for execution $.db.PreparedStatement rollback() Rolls back the changes. - setAutoCommit(enable) Changes the auto-commit flag of the connection - $.db.CallableStatement Functions Function Description Returns close() Closes the statement - execute() Executes a specified statement boolean getBigInt(index) Returns an Int64 value of a BIGINT parameter integer getBlob(index) Returns the ArrayBuffer value of a BLOB specified parameter ArrayBuffer getBString(index) Returns an ArrayBuffer object of the specified column. getBString is used for BINARY and VARBINARY column types. ArrayBuffer getClob(index) Returns the string value of a CLOB parameter string getDate(index) Used to retrieve the value of a DATE parameter Date getDecimal(index) Returns a number value of a DECIMAL parameter number getDouble(index) Returns a number value of a DOUBLE, FLOAT or REAL parameter number getFloat(columnIndex) Returns a number value of the specified column. getFloat is used for FLOAT column types. number getInteger(index) Returns an integer value of a TINYINT, SMALLINT, INT or BIGINT parameter types integer getMoreResults() Checks if more result sets are available and prepares the next result set for retrieval boolean getNClob(index) Returns the string value of an NCLOB or TEXT parameter string getNString(index) Returns the string value of an NCHAR, an NVARCHAR, or a SHORTTEXT parameter string getParameterMetaData() Returns the metadata for this statement $.db.ParameterMetadata getReal(columnIndex) Returns a number value of the specified column. getReal is used for REAL column types. number getResultSet() Returns a result set representing a table output parameter $.db.ResultSet getString(index) Returns a string value of a CHAR or VARCHAR parameter; ASCII only, not suitable for strings containing Unicode characters. string getText(index) Returns the string value of a TEXT parameter string getTime(index) Used to retrieve the value of a TIME parameter Date getTimestamp(index) Used to retrieve the value of a TIMESTAMP parameter. Date isClosed() Checks if the statement is closed. boolean setBigInt(index, value) Sets an integer parameter used for BIGINT parameter types - setBlob(index, value) setBlob is used to specify the values for CHAR, VARCHAR, NCHAR, NVARCHAR, BINARY, VARBINARY parameter types. - setBString(index, value) Sets a string parameter used for BINARY, VARBINARY parameter types. - setClob(index, value) setClob is used to specify the values for CLOB parameter types. - setDate(index, value, format) Sets a Date parameter for DATE parameters, but works with TIME and TIMESTAMP. - setDecimal(index, value) setDecimal sets a decimal parameter used for DECIMAL parameter types - setDouble(index, value) setDouble sets a double parameter used for FLOAT and DOUBLE parameter types - setFloat(index, value) setFloat sets a float parameter used for FLOAT parameter types - setInteger(index, value) Sets an integer parameter used for TINYINT, SMALLINT, INT parameter types - setNClob(index, value) setNClob is used to specify the values for NCLOB parameter types. - setNString(columnIndex, value) Sets a string parameter used for NCHAR, NVARCHAR parameter types, which should be used for strings containing Unicode characters. - setReal(index, value) setReal sets a real parameter used for REAL parameter types - setSmallInt(index, value) Sets an integer parameter used for SMALLINT parameter types - setString(columnIndex, value) Sets a string parameter used for CHAR, VARCHAR column types; ASCII only, not suitable for strings containing Unicode characters - setText(columnIndex, value) setText is used to specify the values for TEXT column types. - setTime(index, value, format) Sets a Time parameter used for TIME parameter types (hour, min, sec) - milliseconds(mls) cannot be set - setTimestamp(index, value, format) Sets a Timestamp parameter used for TIMESTAMP parameter types - setTinyInt(index, value) Sets an integer parameter used for TINYINT parameter types - $.db.ParameterMetaData Functions Function Description Returns getParameterCount() Returns the number of the parameters in the prepared statement integer getParameterMode(index) Returns the mode of the specified parameter integer getParameterName(columnIndex) Returns the name of the specified parameter string getParameterType(columnIndex) Returns the type ($.db.types) of the specified parameter number getParameterTypeName(columnIndex) Returns the type name of the specified parameter string getPrecision(columnIndex) Returns the designated parameter's number of decimal digits string getScale(columnIndex) Returns the designated parameter's scale integer isNullable(index) Checks if the specified parameter is nullable integer isSigned(index) Checks if the specified parameter is signed integer $.db.PreparedStatement Functions Function Description Returns addBatch() Adds last parameter values and iterates to the next batch slot - close() Closes the statement - execute() Executes a common statement boolean executeBatch() Executes a batch insertion. Use setBatchSize and addBatch to prepare for batch execution. array executeQuery() Executes an SQL statement $.db.ResultSet executeUpdate() Executes an update statement integer getMetaData() Returns the metadata of the ResultSet $.db.ResultSetMetaData getMoreResults() Checks if more result sets are available and prepares the next result set for retrieval boolean getParameterMetaData() Returns the metadata of the prepared statement $.db.ParameterMetaData getResultSet() Returns a result set representing a table output parameter $.db.ResultSet getSQLWarning() Returns the warning of the most recently executed statement. Object/null isClosed() Checks if the statement is closed. boolean setBigInt(index, value) Sets an integer parameter used for BIGINT parameter types - setBlob(index, value) setBlob is used to specify the values for CHAR, VARCHAR, NCHAR, NVARCHAR, BINARY, VARBINARY parameter types. - setBString(index, value) Sets a string parameter used for BINARY, VARBINARY parameter types. - setClob(index, value) setClob is used to specify the values for CLOB parameter types. - setDate(index, value, format) Sets a Date parameter for DATE parameters, but works with TIME and TIMESTAMP. - setDecimal(index, value) setDecimal sets a decimal parameter used for DECIMAL parameter types - setDouble(index, value) setDouble sets a double parameter used for FLOAT and DOUBLE parameter types - setFloat(index, value) setFloat sets a float parameter used for FLOAT parameter types - setInteger(index, value) Sets an integer parameter used for TINYINT, SMALLINT, INT parameter types - setNClob(index, value) setNClob is used to specify the values for NCLOB parameter types. - setNString(columnIndex, value) Sets a string parameter used for NCHAR, NVARCHAR parameter types, which should be used for strings containing Unicode characters. - setReal(index, value) setReal sets a real parameter used for REAL parameter types - setSmallInt(index, value) Sets an integer parameter used for SMALLINT parameter types - setString(columnIndex, value) Sets a string parameter used for CHAR, VARCHAR column types; ASCII only, not suitable for strings containing Unicode characters - setText(columnIndex, value) setText is used to specify the values for TEXT column types. - setTime(index, value, format) Sets a Time parameter used for TIME parameter types (hour, min, sec) - milliseconds(mls) cannot be set - setTimestamp(index, value, format) Sets a Timestamp parameter used for TIMESTAMP parameter types - setTinyInt(index, value) Sets an integer parameter used for TINYINT parameter types - $.db.ResultSet Functions Function Description Returns close() Closes the ResultSet - getBigInt(index) Returns an Int64 value of a BIGINT parameter integer getBlob(index) Returns the ArrayBuffer value of a BLOB specified parameter ArrayBuffer getClob(index) Returns the string value of a CLOB parameter string getDate(index) Used to retrieve the value of a DATE parameter Date getDecimal(index) Returns a number value of a DECIMAL parameter number getDouble(index) Returns a number value of a DOUBLE, FLOAT or REAL parameter number getFloat(columnIndex) Returns a number value of the specified column. getFloat is used for FLOAT column types. number getInteger(index) Returns an integer value of a TINYINT, SMALLINT, INT or BIGINT parameter types integer getMetaData() Returns the metadata of the result set $.db.ResultSetMetaData getNClob(index) Returns the string value of an NCLOB or TEXT parameter string getNString(index) Returns the string value of an NCHAR, an NVARCHAR, or a SHORTTEXT parameter string getReal(columnIndex) Returns a number value of the specified column. getReal is used for REAL column types. number getString(index) Returns a string value of a CHAR or VARCHAR parameter; ASCII only, not suitable for strings containing Unicode characters. string getText(index) Returns the string value of a TEXT parameter string getTime(index) Used to retrieve the value of a TIME parameter Date getTimestamp(index) Used to retrieve the value of a TIMESTAMP parameter. Date isClosed() Checks if the ResultSet is closed. boolean next() Fetches the next row boolean $.db.ResultSetMetaData Function Function Description Returns getCatalogName(columnIndex) Returns the catalog name for the specified column string getColumnCount() Returns the number of the columns in the result set integer getColumnDisplaySize(columnIndex) Returns the column display size of the specified column integer getColumnLabel(columnIndex) Returns the alias or name of the specified column string getColumnName(columnIndex) Returns the name of the specified column string getColumnType(columnIndex) Returns the type of the specified column number getColumnTypeName(columnIndex) Returns the name of the specified column type string getPrecision(columnIndex) Returns the precision of the specified column integer getScale(columnIndex) Returns the scale of the specified column integer getTableName(columnIndex) Returns the table name for the specified column string","title":"$.db"},{"location":"api/db/#db","text":"$.db represents the namespace for database access.","title":"$.db"},{"location":"api/db/#overview","text":"Definition: https://github.com/SAP/xsk/issues/15 Module: db/db.js Status: alpha","title":"Overview"},{"location":"api/db/#sample-usage","text":"let connection ; try { connection = $ . db . getConnection (); // Make sure to create the table only once try { connection . prepareStatement ( \"CREATE TABLE SAMPLE_USERS (NAME varchar(255), AGE int)\" ). execute (); } catch ( e ) { // Do nothing, as the table already exists } let insertStatement = connection . prepareStatement ( \"INSERT INTO SAMPLE_USERS (NAME, AGE) VALUES ('Bob', 20)\" ); insertStatement . executeUpdate (); insertStatement . close (); insertStatement = connection . prepareStatement ( \"INSERT INTO SAMPLE_USERS (NAME, AGE) VALUES ('Alice', 21)\" ); insertStatement . executeUpdate (); insertStatement . close (); let selectStatement = connection . prepareStatement ( \"SELECT * FROM SAMPLE_USERS\" ); selectStatement . execute (); let resultSet = selectStatement . getResultSet (); let names = []; while ( resultSet . next ()) { names . push ( resultSet . getString ( 1 )); } selectStatement . close (); resultSet . close (); $ . response . setBody ( names . toString ()); } catch ( e ) { if ( connection ) { connection . rollback (); } $ . response . setBody ( \"Transaction was rolled back: \" + e . message ); } finally { connection . close (); }","title":"Sample Usage"},{"location":"api/db/#functions","text":"Function Description Returns getConnection() Returns a connection to the database. $.db.Connection","title":"Functions"},{"location":"api/db/#classes","text":"","title":"Classes"},{"location":"api/db/#dbconnection","text":"","title":"$.db.Connection"},{"location":"api/db/#functions_1","text":"Function Description Returns close() Closes the connection. - commit() Commits the changes. - isClosed() Checks if the connection is closed. boolean prepareCall(statement) Prepares a stored procedure for execution $.db.CallableStatement prepareStatement(statement) Prepares a statement for execution $.db.PreparedStatement rollback() Rolls back the changes. - setAutoCommit(enable) Changes the auto-commit flag of the connection -","title":"Functions"},{"location":"api/db/#dbcallablestatement","text":"","title":"$.db.CallableStatement"},{"location":"api/db/#functions_2","text":"Function Description Returns close() Closes the statement - execute() Executes a specified statement boolean getBigInt(index) Returns an Int64 value of a BIGINT parameter integer getBlob(index) Returns the ArrayBuffer value of a BLOB specified parameter ArrayBuffer getBString(index) Returns an ArrayBuffer object of the specified column. getBString is used for BINARY and VARBINARY column types. ArrayBuffer getClob(index) Returns the string value of a CLOB parameter string getDate(index) Used to retrieve the value of a DATE parameter Date getDecimal(index) Returns a number value of a DECIMAL parameter number getDouble(index) Returns a number value of a DOUBLE, FLOAT or REAL parameter number getFloat(columnIndex) Returns a number value of the specified column. getFloat is used for FLOAT column types. number getInteger(index) Returns an integer value of a TINYINT, SMALLINT, INT or BIGINT parameter types integer getMoreResults() Checks if more result sets are available and prepares the next result set for retrieval boolean getNClob(index) Returns the string value of an NCLOB or TEXT parameter string getNString(index) Returns the string value of an NCHAR, an NVARCHAR, or a SHORTTEXT parameter string getParameterMetaData() Returns the metadata for this statement $.db.ParameterMetadata getReal(columnIndex) Returns a number value of the specified column. getReal is used for REAL column types. number getResultSet() Returns a result set representing a table output parameter $.db.ResultSet getString(index) Returns a string value of a CHAR or VARCHAR parameter; ASCII only, not suitable for strings containing Unicode characters. string getText(index) Returns the string value of a TEXT parameter string getTime(index) Used to retrieve the value of a TIME parameter Date getTimestamp(index) Used to retrieve the value of a TIMESTAMP parameter. Date isClosed() Checks if the statement is closed. boolean setBigInt(index, value) Sets an integer parameter used for BIGINT parameter types - setBlob(index, value) setBlob is used to specify the values for CHAR, VARCHAR, NCHAR, NVARCHAR, BINARY, VARBINARY parameter types. - setBString(index, value) Sets a string parameter used for BINARY, VARBINARY parameter types. - setClob(index, value) setClob is used to specify the values for CLOB parameter types. - setDate(index, value, format) Sets a Date parameter for DATE parameters, but works with TIME and TIMESTAMP. - setDecimal(index, value) setDecimal sets a decimal parameter used for DECIMAL parameter types - setDouble(index, value) setDouble sets a double parameter used for FLOAT and DOUBLE parameter types - setFloat(index, value) setFloat sets a float parameter used for FLOAT parameter types - setInteger(index, value) Sets an integer parameter used for TINYINT, SMALLINT, INT parameter types - setNClob(index, value) setNClob is used to specify the values for NCLOB parameter types. - setNString(columnIndex, value) Sets a string parameter used for NCHAR, NVARCHAR parameter types, which should be used for strings containing Unicode characters. - setReal(index, value) setReal sets a real parameter used for REAL parameter types - setSmallInt(index, value) Sets an integer parameter used for SMALLINT parameter types - setString(columnIndex, value) Sets a string parameter used for CHAR, VARCHAR column types; ASCII only, not suitable for strings containing Unicode characters - setText(columnIndex, value) setText is used to specify the values for TEXT column types. - setTime(index, value, format) Sets a Time parameter used for TIME parameter types (hour, min, sec) - milliseconds(mls) cannot be set - setTimestamp(index, value, format) Sets a Timestamp parameter used for TIMESTAMP parameter types - setTinyInt(index, value) Sets an integer parameter used for TINYINT parameter types -","title":"Functions"},{"location":"api/db/#dbparametermetadata","text":"","title":"$.db.ParameterMetaData"},{"location":"api/db/#functions_3","text":"Function Description Returns getParameterCount() Returns the number of the parameters in the prepared statement integer getParameterMode(index) Returns the mode of the specified parameter integer getParameterName(columnIndex) Returns the name of the specified parameter string getParameterType(columnIndex) Returns the type ($.db.types) of the specified parameter number getParameterTypeName(columnIndex) Returns the type name of the specified parameter string getPrecision(columnIndex) Returns the designated parameter's number of decimal digits string getScale(columnIndex) Returns the designated parameter's scale integer isNullable(index) Checks if the specified parameter is nullable integer isSigned(index) Checks if the specified parameter is signed integer","title":"Functions"},{"location":"api/db/#dbpreparedstatement","text":"","title":"$.db.PreparedStatement"},{"location":"api/db/#functions_4","text":"Function Description Returns addBatch() Adds last parameter values and iterates to the next batch slot - close() Closes the statement - execute() Executes a common statement boolean executeBatch() Executes a batch insertion. Use setBatchSize and addBatch to prepare for batch execution. array executeQuery() Executes an SQL statement $.db.ResultSet executeUpdate() Executes an update statement integer getMetaData() Returns the metadata of the ResultSet $.db.ResultSetMetaData getMoreResults() Checks if more result sets are available and prepares the next result set for retrieval boolean getParameterMetaData() Returns the metadata of the prepared statement $.db.ParameterMetaData getResultSet() Returns a result set representing a table output parameter $.db.ResultSet getSQLWarning() Returns the warning of the most recently executed statement. Object/null isClosed() Checks if the statement is closed. boolean setBigInt(index, value) Sets an integer parameter used for BIGINT parameter types - setBlob(index, value) setBlob is used to specify the values for CHAR, VARCHAR, NCHAR, NVARCHAR, BINARY, VARBINARY parameter types. - setBString(index, value) Sets a string parameter used for BINARY, VARBINARY parameter types. - setClob(index, value) setClob is used to specify the values for CLOB parameter types. - setDate(index, value, format) Sets a Date parameter for DATE parameters, but works with TIME and TIMESTAMP. - setDecimal(index, value) setDecimal sets a decimal parameter used for DECIMAL parameter types - setDouble(index, value) setDouble sets a double parameter used for FLOAT and DOUBLE parameter types - setFloat(index, value) setFloat sets a float parameter used for FLOAT parameter types - setInteger(index, value) Sets an integer parameter used for TINYINT, SMALLINT, INT parameter types - setNClob(index, value) setNClob is used to specify the values for NCLOB parameter types. - setNString(columnIndex, value) Sets a string parameter used for NCHAR, NVARCHAR parameter types, which should be used for strings containing Unicode characters. - setReal(index, value) setReal sets a real parameter used for REAL parameter types - setSmallInt(index, value) Sets an integer parameter used for SMALLINT parameter types - setString(columnIndex, value) Sets a string parameter used for CHAR, VARCHAR column types; ASCII only, not suitable for strings containing Unicode characters - setText(columnIndex, value) setText is used to specify the values for TEXT column types. - setTime(index, value, format) Sets a Time parameter used for TIME parameter types (hour, min, sec) - milliseconds(mls) cannot be set - setTimestamp(index, value, format) Sets a Timestamp parameter used for TIMESTAMP parameter types - setTinyInt(index, value) Sets an integer parameter used for TINYINT parameter types -","title":"Functions"},{"location":"api/db/#dbresultset","text":"","title":"$.db.ResultSet"},{"location":"api/db/#functions_5","text":"Function Description Returns close() Closes the ResultSet - getBigInt(index) Returns an Int64 value of a BIGINT parameter integer getBlob(index) Returns the ArrayBuffer value of a BLOB specified parameter ArrayBuffer getClob(index) Returns the string value of a CLOB parameter string getDate(index) Used to retrieve the value of a DATE parameter Date getDecimal(index) Returns a number value of a DECIMAL parameter number getDouble(index) Returns a number value of a DOUBLE, FLOAT or REAL parameter number getFloat(columnIndex) Returns a number value of the specified column. getFloat is used for FLOAT column types. number getInteger(index) Returns an integer value of a TINYINT, SMALLINT, INT or BIGINT parameter types integer getMetaData() Returns the metadata of the result set $.db.ResultSetMetaData getNClob(index) Returns the string value of an NCLOB or TEXT parameter string getNString(index) Returns the string value of an NCHAR, an NVARCHAR, or a SHORTTEXT parameter string getReal(columnIndex) Returns a number value of the specified column. getReal is used for REAL column types. number getString(index) Returns a string value of a CHAR or VARCHAR parameter; ASCII only, not suitable for strings containing Unicode characters. string getText(index) Returns the string value of a TEXT parameter string getTime(index) Used to retrieve the value of a TIME parameter Date getTimestamp(index) Used to retrieve the value of a TIMESTAMP parameter. Date isClosed() Checks if the ResultSet is closed. boolean next() Fetches the next row boolean","title":"Functions"},{"location":"api/db/#dbresultsetmetadata","text":"","title":"$.db.ResultSetMetaData"},{"location":"api/db/#function","text":"Function Description Returns getCatalogName(columnIndex) Returns the catalog name for the specified column string getColumnCount() Returns the number of the columns in the result set integer getColumnDisplaySize(columnIndex) Returns the column display size of the specified column integer getColumnLabel(columnIndex) Returns the alias or name of the specified column string getColumnName(columnIndex) Returns the name of the specified column string getColumnType(columnIndex) Returns the type of the specified column number getColumnTypeName(columnIndex) Returns the name of the specified column type string getPrecision(columnIndex) Returns the precision of the specified column integer getScale(columnIndex) Returns the scale of the specified column integer getTableName(columnIndex) Returns the table name for the specified column string","title":"Function"},{"location":"api/hdb/","text":"$.hdb $.hdb namespace provides means for seamless HANA database access. It is intended to be a replacement for the older $.db namespace. The fundamental goal of the new interface is to ensure simplicity, convenience, completeness, and performance. Overview Definition: https://github.com/SAP/xsk/issues/14 Module: hdb/hdb.js Status: alpha Sample Usage var db = $ . hdb ; let connection = null ; try { connection = db . getConnection (); try { connection . executeUpdate ( \"DROP TABLE CARS\" ); } catch ( e ) { // Do nothing } connection . executeUpdate ( \"CREATE TABLE CARS (MAKE varchar(255), MODEL varchar(255))\" ); let rows = connection . executeUpdate ( \"INSERT INTO CARS (MAKE, MODEL) VALUES ('BMW', '325')\" ); rows += connection . executeUpdate ( \"INSERT INTO CARS (MAKE, MODEL) VALUES ('HONDA', 'ACCORD')\" ); let totalText = `Query OK, ${ rows } rows affected\\n\\n` ; let result = connection . executeQuery ( \"SELECT * FROM CARS\" ); let iterator = result . getIterator (); let metadata = result . metadata . columns ; while ( iterator . next ()) { var currentRow = iterator . value (); totalText += ` ${ metadata [ 0 ]. name } : ${ currentRow [ 0 ] } , ${ metadata [ 1 ]. name } : ${ currentRow [ 1 ] } \\n` ; // totalText += `${metadata[0].name}: ${currentRow[metadata[0].name]}, ${metadata[1].name}: ${currentRow[metadata[1].name]}\\n`; } $ . response . setBody ( totalText ); } catch ( e ) { connection . rollback (); $ . response . setBody ( \"Transaction was rolled back: \" + e . message ); } finally { if ( connection ) { connection . close (); } } Functions Function Description Returns getConnection() Returns a connection to the database. $.hdb.Connection Properties Name Description Type Default isolation.READ_COMITTED - number 2 isolation.REPEATABLE_READ - number 4 isolation.SERIALIZABLE - number 8 types.TINYINT - number 1 types.SMALLINT - number 2 types.INTEGER - number 3 types.BIGINT - number 4 types.DECIMAL - number 5 types.REAL - number 6 types.DOUBLE - number 7 types.CHAR - number 8 types.VARCHAR - number 9 types.NCHAR - number 10 types.NVARCHAR - number 11 types.BINARY - number 12 types.VARBINARY - number 13 types.DATE - number 14 types.TIME - number 15 types.TIMESTAMP - number 16 types.CLOB - number 25 types.NCLOB - number 26 types.BLOB - number 27 types.SMALLDECIMAL - number 47 types.TEXT - number 51 types.SHORTTEXT - number 52 types.ALPHANUM - number 55 types.SECONDDATE - number 62 types.ST_GEOMETRY - number 74 types.ST_POINT - number 75 Note isolation - constants that represent the isolation levels for a transaction. types - set of constants of the database column types. types.ST_GEOMETRY - consider using SQL's ST_asGeoJSON() on ST_GEOMETRY columns for easy consumption. types.ST_POINT - consider using SQL's ST_asGeoJSON() on ST_POINT columns for easy consumption Classes $.hdb.Connection Functions Function Description Returns close() Closes the connection. - commit() Commits the changes. - isClosed() Checks if the connection is closed. boolean executeQuery(query, args) Executes a database query. $.hdb.ResultSet executeUpdate(statement, args) Executes a SQL statement, which changes the database state. $.hdb.ResultSet rollback() Rolls back the changes. - setAutoCommit(enable) Changes the auto-commit flag of the connection. - $.hdb.ResultSet Functions Function Description Returns getIterator() Returns an iterator over this result set. $.hdb.ResultSetIterator Properties Name Description Type lenght The number of rows in the $.hdb.ResultSet object number metadata Returns the ResultSetMetaData from $.hdb.ResultSet object. $.hdb.ResultSetMetaData $.hdb.ResultSetIterator Functions Method Description Type next() Checks if the result set has more rows and sets the value of the iterator to the next row if it exists. boolean value() Returns the current row that the iterator's value is set to, should always be called after a call to next() . row of a $.hdb.ResultSet $.hdb.ResultSetMetaData Properties Name Description Type column Returns an array of column metadata objects, each of which represents the metadata for a particular column. array of $.hdb.ColumnMetadata $.hdb. ColumnMetadata Properties Name Description Type catalogName Returns the column's catalog name. string displaySize Returns the column's display size. number isNullable Returns true if the column is nullable and false otherwise. number label Returns the column's label. string precision Returns the column's name. string scale Returns the column's scale. string tableName Returns the name of the table to which the column belongs. string type Returns the column's type. string typeName Returns the column's type name. $.hdb.types","title":"$.hdb"},{"location":"api/hdb/#hdb","text":"$.hdb namespace provides means for seamless HANA database access. It is intended to be a replacement for the older $.db namespace. The fundamental goal of the new interface is to ensure simplicity, convenience, completeness, and performance.","title":"$.hdb"},{"location":"api/hdb/#overview","text":"Definition: https://github.com/SAP/xsk/issues/14 Module: hdb/hdb.js Status: alpha","title":"Overview"},{"location":"api/hdb/#sample-usage","text":"var db = $ . hdb ; let connection = null ; try { connection = db . getConnection (); try { connection . executeUpdate ( \"DROP TABLE CARS\" ); } catch ( e ) { // Do nothing } connection . executeUpdate ( \"CREATE TABLE CARS (MAKE varchar(255), MODEL varchar(255))\" ); let rows = connection . executeUpdate ( \"INSERT INTO CARS (MAKE, MODEL) VALUES ('BMW', '325')\" ); rows += connection . executeUpdate ( \"INSERT INTO CARS (MAKE, MODEL) VALUES ('HONDA', 'ACCORD')\" ); let totalText = `Query OK, ${ rows } rows affected\\n\\n` ; let result = connection . executeQuery ( \"SELECT * FROM CARS\" ); let iterator = result . getIterator (); let metadata = result . metadata . columns ; while ( iterator . next ()) { var currentRow = iterator . value (); totalText += ` ${ metadata [ 0 ]. name } : ${ currentRow [ 0 ] } , ${ metadata [ 1 ]. name } : ${ currentRow [ 1 ] } \\n` ; // totalText += `${metadata[0].name}: ${currentRow[metadata[0].name]}, ${metadata[1].name}: ${currentRow[metadata[1].name]}\\n`; } $ . response . setBody ( totalText ); } catch ( e ) { connection . rollback (); $ . response . setBody ( \"Transaction was rolled back: \" + e . message ); } finally { if ( connection ) { connection . close (); } }","title":"Sample Usage"},{"location":"api/hdb/#functions","text":"Function Description Returns getConnection() Returns a connection to the database. $.hdb.Connection","title":"Functions"},{"location":"api/hdb/#properties","text":"Name Description Type Default isolation.READ_COMITTED - number 2 isolation.REPEATABLE_READ - number 4 isolation.SERIALIZABLE - number 8 types.TINYINT - number 1 types.SMALLINT - number 2 types.INTEGER - number 3 types.BIGINT - number 4 types.DECIMAL - number 5 types.REAL - number 6 types.DOUBLE - number 7 types.CHAR - number 8 types.VARCHAR - number 9 types.NCHAR - number 10 types.NVARCHAR - number 11 types.BINARY - number 12 types.VARBINARY - number 13 types.DATE - number 14 types.TIME - number 15 types.TIMESTAMP - number 16 types.CLOB - number 25 types.NCLOB - number 26 types.BLOB - number 27 types.SMALLDECIMAL - number 47 types.TEXT - number 51 types.SHORTTEXT - number 52 types.ALPHANUM - number 55 types.SECONDDATE - number 62 types.ST_GEOMETRY - number 74 types.ST_POINT - number 75 Note isolation - constants that represent the isolation levels for a transaction. types - set of constants of the database column types. types.ST_GEOMETRY - consider using SQL's ST_asGeoJSON() on ST_GEOMETRY columns for easy consumption. types.ST_POINT - consider using SQL's ST_asGeoJSON() on ST_POINT columns for easy consumption","title":"Properties"},{"location":"api/hdb/#classes","text":"","title":"Classes"},{"location":"api/hdb/#hdbconnection","text":"","title":"$.hdb.Connection"},{"location":"api/hdb/#functions_1","text":"Function Description Returns close() Closes the connection. - commit() Commits the changes. - isClosed() Checks if the connection is closed. boolean executeQuery(query, args) Executes a database query. $.hdb.ResultSet executeUpdate(statement, args) Executes a SQL statement, which changes the database state. $.hdb.ResultSet rollback() Rolls back the changes. - setAutoCommit(enable) Changes the auto-commit flag of the connection. -","title":"Functions"},{"location":"api/hdb/#hdbresultset","text":"","title":"$.hdb.ResultSet"},{"location":"api/hdb/#functions_2","text":"Function Description Returns getIterator() Returns an iterator over this result set. $.hdb.ResultSetIterator","title":"Functions"},{"location":"api/hdb/#properties_1","text":"Name Description Type lenght The number of rows in the $.hdb.ResultSet object number metadata Returns the ResultSetMetaData from $.hdb.ResultSet object. $.hdb.ResultSetMetaData","title":"Properties"},{"location":"api/hdb/#hdbresultsetiterator","text":"","title":"$.hdb.ResultSetIterator"},{"location":"api/hdb/#functions_3","text":"Method Description Type next() Checks if the result set has more rows and sets the value of the iterator to the next row if it exists. boolean value() Returns the current row that the iterator's value is set to, should always be called after a call to next() . row of a $.hdb.ResultSet","title":"Functions"},{"location":"api/hdb/#hdbresultsetmetadata","text":"","title":"$.hdb.ResultSetMetaData"},{"location":"api/hdb/#properties_2","text":"Name Description Type column Returns an array of column metadata objects, each of which represents the metadata for a particular column. array of $.hdb.ColumnMetadata","title":"Properties"},{"location":"api/hdb/#hdb-columnmetadata","text":"","title":"$.hdb. ColumnMetadata"},{"location":"api/hdb/#properties_3","text":"Name Description Type catalogName Returns the column's catalog name. string displaySize Returns the column's display size. number isNullable Returns true if the column is nullable and false otherwise. number label Returns the column's label. string precision Returns the column's name. string scale Returns the column's scale. string tableName Returns the name of the table to which the column belongs. string type Returns the column's type. string typeName Returns the column's type name. $.hdb.types","title":"Properties"},{"location":"api/import/","text":"$.import $.import namespace provides means for importing server-side JavaScript library artifacts. These are design-time artifacts located in the repository. JavaScript library design-time artifacts have the suffix *.xsjslib . Overview Definition: https://github.com/SAP/xsk/issues/18 Module: import/import.js Status: alpha Sample Usage Note If you want to use sample usage code, file structure of project in your workspace browser should look like this: import.xsjs math.xsjslib // Import .xsjslib to our file using $.import api (\"package\",\"library\") // In our case package equals to \"sap.myapp.lib\" let mathlib = $ . import ( \"sap.myapp.lib\" , \"math\" ); let square = mathlib . square ( 6 ); let multiply = mathlib . multiply ( 4 , 9 ); let division = mathlib . division ( 9 , 3 ); let result = `Square is: ${ square } ` ; result += `\\nMultiply is: ${ multiply } ` ; result += `\\nDivision is: ${ division } ` ; $ . response . setBody ( result ); function square ( x ) { return x * x ; } function multiply ( x , y ) { return x * y ; } function division ( x , y ) { return x / y ; } Parameters Name type Description package string The name of the package in which the library object is located library string The name of the library object in the repository (without the suffix .xsjslib)","title":"$.import"},{"location":"api/import/#import","text":"$.import namespace provides means for importing server-side JavaScript library artifacts. These are design-time artifacts located in the repository. JavaScript library design-time artifacts have the suffix *.xsjslib .","title":"$.import"},{"location":"api/import/#overview","text":"Definition: https://github.com/SAP/xsk/issues/18 Module: import/import.js Status: alpha","title":"Overview"},{"location":"api/import/#sample-usage","text":"Note If you want to use sample usage code, file structure of project in your workspace browser should look like this: import.xsjs math.xsjslib // Import .xsjslib to our file using $.import api (\"package\",\"library\") // In our case package equals to \"sap.myapp.lib\" let mathlib = $ . import ( \"sap.myapp.lib\" , \"math\" ); let square = mathlib . square ( 6 ); let multiply = mathlib . multiply ( 4 , 9 ); let division = mathlib . division ( 9 , 3 ); let result = `Square is: ${ square } ` ; result += `\\nMultiply is: ${ multiply } ` ; result += `\\nDivision is: ${ division } ` ; $ . response . setBody ( result ); function square ( x ) { return x * x ; } function multiply ( x , y ) { return x * y ; } function division ( x , y ) { return x / y ; }","title":"Sample Usage"},{"location":"api/import/#parameters","text":"Name type Description package string The name of the package in which the library object is located library string The name of the library object in the repository (without the suffix .xsjslib)","title":"Parameters"},{"location":"api/jobs/","text":"$.jobs $.jobs represents an XS scheduled job. Overview Definition: https://github.com/SAP/xsk/issues/388 Module: jobs/jobs.js Status: alpha Sample usage: Definition Handler Trigger Create a definition.xsjob file in a project named xsjob_demo : { \"description\" : \"My Job configuration\" , \"action\" : \"xsjob_demo:handler.xsjslib::writeInDB\" , \"schedules\" : [ { \"description\" : \"Execute every 5 seconds\" , \"xscron\" : \"* * * * * * */5\" , \"parameter\" : { } } ] } Create a handler.xsjslib file in the xsjob_demo project: function writeInDB () { let connection ; try { connection = $ . db . getConnection (); let insertStatement = connection . prepareStatement ( \"INSERT INTO XSJOB_DEMO (EXECUTED_AT) VALUES (CURRENT_TIMESTAMP)\" ); insertStatement . executeUpdate (); insertStatement . close (); } catch ( e ) { connection . rollback (); console . log ( \"Transaction was rolled back: \" + e . message ); } finally { connection . close (); } } And now, to use the API, create a trigger.xsjs file: let job = new $ . jobs . Job ({ uri : \"xsjob_demo/definition.xsjob\" }); // execute the job for 60 seconds, starting from now job . configure ({ status : true , start_time : new Date (), end_time : new Date ( Date . now () + 60000 ) }); Functions Function Description Returns activate() Activates an XS Job that has already been configured. - configure(config) Configure an XS Job. The function provides additional means to programmatically configure an XS Job. Configuration must be done prior to activate/deactivate an XS Job. - deactivate() Deactivates an XS Job that has already been configured. - getConfiguration() Retrieve current configuration of an XS Job as object. Object","title":"$.jobs"},{"location":"api/jobs/#jobs","text":"$.jobs represents an XS scheduled job.","title":"$.jobs"},{"location":"api/jobs/#overview","text":"Definition: https://github.com/SAP/xsk/issues/388 Module: jobs/jobs.js Status: alpha","title":"Overview"},{"location":"api/jobs/#sample-usage","text":"Definition Handler Trigger Create a definition.xsjob file in a project named xsjob_demo : { \"description\" : \"My Job configuration\" , \"action\" : \"xsjob_demo:handler.xsjslib::writeInDB\" , \"schedules\" : [ { \"description\" : \"Execute every 5 seconds\" , \"xscron\" : \"* * * * * * */5\" , \"parameter\" : { } } ] } Create a handler.xsjslib file in the xsjob_demo project: function writeInDB () { let connection ; try { connection = $ . db . getConnection (); let insertStatement = connection . prepareStatement ( \"INSERT INTO XSJOB_DEMO (EXECUTED_AT) VALUES (CURRENT_TIMESTAMP)\" ); insertStatement . executeUpdate (); insertStatement . close (); } catch ( e ) { connection . rollback (); console . log ( \"Transaction was rolled back: \" + e . message ); } finally { connection . close (); } } And now, to use the API, create a trigger.xsjs file: let job = new $ . jobs . Job ({ uri : \"xsjob_demo/definition.xsjob\" }); // execute the job for 60 seconds, starting from now job . configure ({ status : true , start_time : new Date (), end_time : new Date ( Date . now () + 60000 ) });","title":"Sample usage:"},{"location":"api/jobs/#functions","text":"Function Description Returns activate() Activates an XS Job that has already been configured. - configure(config) Configure an XS Job. The function provides additional means to programmatically configure an XS Job. Configuration must be done prior to activate/deactivate an XS Job. - deactivate() Deactivates an XS Job that has already been configured. - getConfiguration() Retrieve current configuration of an XS Job as object. Object","title":"Functions"},{"location":"api/request/","text":"$.request $.request object represents the client HTTP request currently being processed. Overview Definition: https://github.com/SAP/xsk/issues/12 Module: web/web.js Status: alpha Sample Usage // defined a hardcoded users array for the example let users = [ { id : '1' , name : 'John' }, { id : '2' , name : 'Ben' }, { id : '3' , name : 'George' } ] function getUser ( id ) { // retrieve user operation by id return users . find ( function ( user ) { return user . id === id ; }) } function createUser ( data ) { // create user operation which will update the users array only for the scope of the current request call as the users are hardcoded users . push ({ id : data . id , name : data . name }); } function deleteUser ( id ) { // delete user operation which will remove a user only for the current scope of the request as the users are hardcoded users = users . filter ( function ( user ) { return user . id !== id }) } function allUsers () { // retrieve all users operation return users ; } // get id query param const id = $ . request . parameters . get ( \"id\" ); // check the type of the request switch ( $ . request . method ) { case $ . net . http . PUT : if ( $ . request . contentType === \"application/json\" ) { createUser ( JSON . parse ( $ . request . body . asString ())); $ . response . setBody ( `created user [ ${ JSON . stringify ( $ . request . body . asString ()) } ]` ); } else { $ . response . setBody ( JSON . stringify ({ \"error\" : \"Unsupported content type.\" })); } break ; case $ . net . http . GET : if ( id ) { let user = getUser ( id ); $ . response . setBody ( JSON . stringify ({ user : user })); } else { let users = allUsers (); $ . response . setBody ( JSON . stringify ({ users : users })); } break ; case $ . net . http . DELETE : if ( id ) { deleteUser ( id ); $ . response . setBody ( `deleted user with id [ ${ id } ]` ); } else { $ . response . setBody ( JSON . stringify ({ \"error\" : `Parameter id is missing` })); } break ; default : $ . response . setBody ( JSON . stringify ({ \"error\" : `Unsupported method [ ${ $ . request . method } ]` })); } Properties Name Description Type body The body of the request. $.web.Body contentType The content type of the entity. string cookies The cookies associated with the entity. $.web.TupelList entities The sub-entities of the entity. $.web.EntityList headers The headers of the entity. $.web.TupelList language Language of the request in IETF (BCP 47) format. string method The HTTP method of the incoming HTTP request. $.net.http parameters The parameters of the entity. $.web.TupelList path The URL path specified in the request. string queryPath The URL query path specified in the request. string Functions Function Description Returns setBody(body) Sets the body of the entity. -","title":"$.web.WebRequest"},{"location":"api/request/#request","text":"$.request object represents the client HTTP request currently being processed.","title":"$.request"},{"location":"api/request/#overview","text":"Definition: https://github.com/SAP/xsk/issues/12 Module: web/web.js Status: alpha","title":"Overview"},{"location":"api/request/#sample-usage","text":"// defined a hardcoded users array for the example let users = [ { id : '1' , name : 'John' }, { id : '2' , name : 'Ben' }, { id : '3' , name : 'George' } ] function getUser ( id ) { // retrieve user operation by id return users . find ( function ( user ) { return user . id === id ; }) } function createUser ( data ) { // create user operation which will update the users array only for the scope of the current request call as the users are hardcoded users . push ({ id : data . id , name : data . name }); } function deleteUser ( id ) { // delete user operation which will remove a user only for the current scope of the request as the users are hardcoded users = users . filter ( function ( user ) { return user . id !== id }) } function allUsers () { // retrieve all users operation return users ; } // get id query param const id = $ . request . parameters . get ( \"id\" ); // check the type of the request switch ( $ . request . method ) { case $ . net . http . PUT : if ( $ . request . contentType === \"application/json\" ) { createUser ( JSON . parse ( $ . request . body . asString ())); $ . response . setBody ( `created user [ ${ JSON . stringify ( $ . request . body . asString ()) } ]` ); } else { $ . response . setBody ( JSON . stringify ({ \"error\" : \"Unsupported content type.\" })); } break ; case $ . net . http . GET : if ( id ) { let user = getUser ( id ); $ . response . setBody ( JSON . stringify ({ user : user })); } else { let users = allUsers (); $ . response . setBody ( JSON . stringify ({ users : users })); } break ; case $ . net . http . DELETE : if ( id ) { deleteUser ( id ); $ . response . setBody ( `deleted user with id [ ${ id } ]` ); } else { $ . response . setBody ( JSON . stringify ({ \"error\" : `Parameter id is missing` })); } break ; default : $ . response . setBody ( JSON . stringify ({ \"error\" : `Unsupported method [ ${ $ . request . method } ]` })); }","title":"Sample Usage"},{"location":"api/request/#properties","text":"Name Description Type body The body of the request. $.web.Body contentType The content type of the entity. string cookies The cookies associated with the entity. $.web.TupelList entities The sub-entities of the entity. $.web.EntityList headers The headers of the entity. $.web.TupelList language Language of the request in IETF (BCP 47) format. string method The HTTP method of the incoming HTTP request. $.net.http parameters The parameters of the entity. $.web.TupelList path The URL path specified in the request. string queryPath The URL query path specified in the request. string","title":"Properties"},{"location":"api/request/#functions","text":"Function Description Returns setBody(body) Sets the body of the entity. -","title":"Functions"},{"location":"api/response/","text":"$.response $.response represents the HTTP response currently being populated. This API is used for returning a result response to the xsk HTTP service caller. Overview Definition: https://github.com/SAP/xsk/issues/13 Module: web/web.js Status: alpha Sample Usage // array of cars and their colors let cars = [ { make : \"mercedes\" , color : \"red\" }, { make : \"audi\" , color : \"blue\" }, { make : \"toyota\" , color : \"red\" }, { make : \"vw\" , color : \"blue\" } ] // filter by color function function filterCarsByColor ( color ) { return cars . filter ( function ( car ) { return car . color === color ; }) } if ( $ . request . method === $ . net . http . GET ) { // get query parameter color let color = $ . request . parameters . get ( \"color\" ); // handle some request operation if ( color ) { // filter by color if passed let filteredCars = filterCarsByColor ( color ); // send response with filtered cars by color $ . response . contentType = \"application/json\" ; $ . response . status = $ . net . http . OK ; $ . response . setBody ( JSON . stringify ({ \"cars\" : filteredCars })); } else { // send response with all cars as color param is missing $ . response . status = $ . net . http . BAD_REQUEST ; $ . response . setBody ( JSON . stringify ({ \"cars\" : cars })); } } else { // unsupported method $ . response . status = $ . net . http . NOT_FOUND ; $ . response . setBody ( JSON . stringify ({ \"error\" : \"not found\" })); } Properties Name Description Type body The body of the response. $.web.Body cacheControl Easy access to the cache control header of the entity. string contentType The content type of the entity. string cookies The cookies associated with the entity. $.web.TupelList entities The sub-entities of the entity. $.web.EntityList headers The headers of the entity. $.web.TupelList status The HTTP status code of the outgoing HTTP response. $.net.http Functions Function Description Returns followUp(object) Enable running a follow up job that executes in the background. - setBody(body) Sets the body of the entity. -","title":"$.web.WebResponse"},{"location":"api/response/#response","text":"$.response represents the HTTP response currently being populated. This API is used for returning a result response to the xsk HTTP service caller.","title":"$.response"},{"location":"api/response/#overview","text":"Definition: https://github.com/SAP/xsk/issues/13 Module: web/web.js Status: alpha","title":"Overview"},{"location":"api/response/#sample-usage","text":"// array of cars and their colors let cars = [ { make : \"mercedes\" , color : \"red\" }, { make : \"audi\" , color : \"blue\" }, { make : \"toyota\" , color : \"red\" }, { make : \"vw\" , color : \"blue\" } ] // filter by color function function filterCarsByColor ( color ) { return cars . filter ( function ( car ) { return car . color === color ; }) } if ( $ . request . method === $ . net . http . GET ) { // get query parameter color let color = $ . request . parameters . get ( \"color\" ); // handle some request operation if ( color ) { // filter by color if passed let filteredCars = filterCarsByColor ( color ); // send response with filtered cars by color $ . response . contentType = \"application/json\" ; $ . response . status = $ . net . http . OK ; $ . response . setBody ( JSON . stringify ({ \"cars\" : filteredCars })); } else { // send response with all cars as color param is missing $ . response . status = $ . net . http . BAD_REQUEST ; $ . response . setBody ( JSON . stringify ({ \"cars\" : cars })); } } else { // unsupported method $ . response . status = $ . net . http . NOT_FOUND ; $ . response . setBody ( JSON . stringify ({ \"error\" : \"not found\" })); }","title":"Sample Usage"},{"location":"api/response/#properties","text":"Name Description Type body The body of the response. $.web.Body cacheControl Easy access to the cache control header of the entity. string contentType The content type of the entity. string cookies The cookies associated with the entity. $.web.TupelList entities The sub-entities of the entity. $.web.EntityList headers The headers of the entity. $.web.TupelList status The HTTP status code of the outgoing HTTP response. $.net.http","title":"Properties"},{"location":"api/response/#functions","text":"Function Description Returns followUp(object) Enable running a follow up job that executes in the background. - setBody(body) Sets the body of the entity. -","title":"Functions"},{"location":"api/session/","text":"$.session $.session represents the Session with its fields and methods. Overview Definition: https://github.com/SAP/xsk/issues/11 Module: session/session.js Status: alpha Sample Usage var session = $ . session ; var username = session . getUsername () var timeout = session . getTimeout () var token = session . getSecurityToken () var authType = session . authType // Check the language of the session response . println ( \"Session language: \" + session . language ) // Check if a particular user has the \"Administrator\" role if ( username === \"dirigible\" && session . hasAppPrivilege ( \"Administrator\" )) { // Check a specific system privilege for that user if ( session . hasSystemPrivilege ( \"Dirigible\" )) { // Perform some operation with his session's information $ . response . setBody ( \"Username: \" + username + \" with session authentication type: \" + authType + \" token: \" + token + \" and timeout \" + timeout ); } } else { // Assert that the user is a Developer in all other cases try { session . assertAppPrivilege ( \"Developer\" ); // Check the authentification type if ( authType === \"BASIC\" ) { // Use the information from the current session $ . response . setBody ( \"Username: \" + username + \" with session authentication type: \" + authType + \" token: \" + token + \" and timeout \" + timeout ); } } catch ( error ) { //Display the missing role that was being asserted $ . response . setBody ( \"User does not have the role: \" + error . privilege ); } } // After all calls are complete, check the invocation count of the current session $ . response . setBody ( \"Invocation count: \" + session . getInvocationCount ()); Properties Name Description Type authType Authentication method that was used for the current session. string/null language Language of the session in IETF (BCP 47) format. string samlAttribute Provides the detailed content of the AttributeStatement tag which can be part of a SAML assertion. Array.<$.Session~SamlAttributeObject> samlUserInfo Provides the materialized content of the AttributeStatement tag which can be part of a SAML assertion. object Functions Function Description Returns assertAppPrivilege(privilegeName) Asserts that the logged-on user has a specified application privilege. - assertSystemPrivilege(privilegeName) Asserts that the logged-on user has a specified system privilege. - getInvocationCount() Returns the number of requests sent to the current session. Number getSecurityToken() Returns unique session-specific token that could be used for XSRF prevention. string getTimeout() The timeout of the XS session in seconds. integer getUsername() Returns the username of the logged-on database user. string hasAppPrivilege(privilegeName) Checks whether the logged-on user has a specified application privilege. boolean hasSystemPrivilege(privilegeName) Checks whether the logged-on user has a specified system privilege. boolean","title":"$.session"},{"location":"api/session/#session","text":"$.session represents the Session with its fields and methods.","title":"$.session"},{"location":"api/session/#overview","text":"Definition: https://github.com/SAP/xsk/issues/11 Module: session/session.js Status: alpha","title":"Overview"},{"location":"api/session/#sample-usage","text":"var session = $ . session ; var username = session . getUsername () var timeout = session . getTimeout () var token = session . getSecurityToken () var authType = session . authType // Check the language of the session response . println ( \"Session language: \" + session . language ) // Check if a particular user has the \"Administrator\" role if ( username === \"dirigible\" && session . hasAppPrivilege ( \"Administrator\" )) { // Check a specific system privilege for that user if ( session . hasSystemPrivilege ( \"Dirigible\" )) { // Perform some operation with his session's information $ . response . setBody ( \"Username: \" + username + \" with session authentication type: \" + authType + \" token: \" + token + \" and timeout \" + timeout ); } } else { // Assert that the user is a Developer in all other cases try { session . assertAppPrivilege ( \"Developer\" ); // Check the authentification type if ( authType === \"BASIC\" ) { // Use the information from the current session $ . response . setBody ( \"Username: \" + username + \" with session authentication type: \" + authType + \" token: \" + token + \" and timeout \" + timeout ); } } catch ( error ) { //Display the missing role that was being asserted $ . response . setBody ( \"User does not have the role: \" + error . privilege ); } } // After all calls are complete, check the invocation count of the current session $ . response . setBody ( \"Invocation count: \" + session . getInvocationCount ());","title":"Sample Usage"},{"location":"api/session/#properties","text":"Name Description Type authType Authentication method that was used for the current session. string/null language Language of the session in IETF (BCP 47) format. string samlAttribute Provides the detailed content of the AttributeStatement tag which can be part of a SAML assertion. Array.<$.Session~SamlAttributeObject> samlUserInfo Provides the materialized content of the AttributeStatement tag which can be part of a SAML assertion. object","title":"Properties"},{"location":"api/session/#functions","text":"Function Description Returns assertAppPrivilege(privilegeName) Asserts that the logged-on user has a specified application privilege. - assertSystemPrivilege(privilegeName) Asserts that the logged-on user has a specified system privilege. - getInvocationCount() Returns the number of requests sent to the current session. Number getSecurityToken() Returns unique session-specific token that could be used for XSRF prevention. string getTimeout() The timeout of the XS session in seconds. integer getUsername() Returns the username of the logged-on database user. string hasAppPrivilege(privilegeName) Checks whether the logged-on user has a specified application privilege. boolean hasSystemPrivilege(privilegeName) Checks whether the logged-on user has a specified system privilege. boolean","title":"Functions"},{"location":"api/trace/","text":"$.trace $.trace represents the trace namespace with its methods. Overview Definition: https://github.com/SAP/xsk/issues/17 Module: trace/trace.js Status: alpha Sample Usage let trace = $ . trace ; // Check trace methods availability in the \"Preview\" tab $ . response . setBody ( \"Debug logging enabled: \" + trace . isDebugEnabled () + \", Error logging enabled: \" + trace . isErrorEnabled () + \", Fatal logging enabled: \" + trace . isFatalEnabled () + \", Info logging enabled: \" + trace . isInfoEnabled () + \", Warning logging enabled: \" + trace . isWarningEnabled ()); // If the trace method is enabled, it will print the message in the \"Console\" tab trace . debug ( \"Debug message!\" ); trace . error ( \"Error message!\" ); trace . error ( \"Fatal message!\" ); trace . info ( \"Info message!\" ); trace . warning ( \"Warning message!\" ); Constants Name Description Type Default XSK_LOG_DEBUG_ENABLED Enables debug level logging. boolean true XSK_LOG_ERROR_ENABLED Enables error level logging. boolean true XSK_LOG_FATAL_ENABLED Enables fatal level logging. boolean true XSK_LOG_INFO_ENABLED Enables log level logging. boolean true XSK_LOG_WARNING_ENABLED Enables warning level logging. boolean true Functions Function Description Returns debug(message) Writes the given message with the trace-level debug to the application trace file. - error(message) Writes the given message with the trace-level error to the application trace file. - fatal(message) Writes the given message with the trace-level fatal to the application trace file. - info(message) Writes the given message with the trace-level info to the application trace file. - warning(message) Writes the given message with the trace-level warning to the application trace file. - isDebugEnabled() Returns true or false to show whether or not the tracer writes an entry in the application trace file for the trace-level debug. boolean isErrorEnabled() Returns true or false to show whether or not the tracer writes an entry in the application trace file for the trace-level error. boolean isFatalEnabled() Returns true or false to show whether or not the tracer writes an entry in the application trace file for the trace-level fatal. boolean isInfoEnabled() Returns true or false to show whether or not the tracer writes an entry in the application trace file for the trace-level info. boolean isWarningEnabled() Returns true or false to show whether or not the tracer writes an entry in the application trace file for the trace-level warning. boolean","title":"$.trace"},{"location":"api/trace/#trace","text":"$.trace represents the trace namespace with its methods.","title":"$.trace"},{"location":"api/trace/#overview","text":"Definition: https://github.com/SAP/xsk/issues/17 Module: trace/trace.js Status: alpha","title":"Overview"},{"location":"api/trace/#sample-usage","text":"let trace = $ . trace ; // Check trace methods availability in the \"Preview\" tab $ . response . setBody ( \"Debug logging enabled: \" + trace . isDebugEnabled () + \", Error logging enabled: \" + trace . isErrorEnabled () + \", Fatal logging enabled: \" + trace . isFatalEnabled () + \", Info logging enabled: \" + trace . isInfoEnabled () + \", Warning logging enabled: \" + trace . isWarningEnabled ()); // If the trace method is enabled, it will print the message in the \"Console\" tab trace . debug ( \"Debug message!\" ); trace . error ( \"Error message!\" ); trace . error ( \"Fatal message!\" ); trace . info ( \"Info message!\" ); trace . warning ( \"Warning message!\" );","title":"Sample Usage"},{"location":"api/trace/#constants","text":"Name Description Type Default XSK_LOG_DEBUG_ENABLED Enables debug level logging. boolean true XSK_LOG_ERROR_ENABLED Enables error level logging. boolean true XSK_LOG_FATAL_ENABLED Enables fatal level logging. boolean true XSK_LOG_INFO_ENABLED Enables log level logging. boolean true XSK_LOG_WARNING_ENABLED Enables warning level logging. boolean true","title":"Constants"},{"location":"api/trace/#functions","text":"Function Description Returns debug(message) Writes the given message with the trace-level debug to the application trace file. - error(message) Writes the given message with the trace-level error to the application trace file. - fatal(message) Writes the given message with the trace-level fatal to the application trace file. - info(message) Writes the given message with the trace-level info to the application trace file. - warning(message) Writes the given message with the trace-level warning to the application trace file. - isDebugEnabled() Returns true or false to show whether or not the tracer writes an entry in the application trace file for the trace-level debug. boolean isErrorEnabled() Returns true or false to show whether or not the tracer writes an entry in the application trace file for the trace-level error. boolean isFatalEnabled() Returns true or false to show whether or not the tracer writes an entry in the application trace file for the trace-level fatal. boolean isInfoEnabled() Returns true or false to show whether or not the tracer writes an entry in the application trace file for the trace-level info. boolean isWarningEnabled() Returns true or false to show whether or not the tracer writes an entry in the application trace file for the trace-level warning. boolean","title":"Functions"},{"location":"api/net/","text":"$.net $.net represents the network namespace with its fields. Overview Definition: https://github.com/SAP/xsk/issues/19 Module: net/net.js Status: alpha Sample Usage Note Requires a running mail server. If mailConfig is not set the api defaults to a local mail server. For more information please take a look here . let net = $ . net ; // Create a mail Object let mail = new net . Mail ({ sender : { address : \"sender@sap.com\" }, to : [{ name : \"John Doe\" , address : \"john.doe@sap.com\" }, { name : \"Jane Doe\" , address : \"jane.doe@sap.com\" }], cc : [{ address : \"cc1@sap.com\" }, { address : \"cc2@sap.com\" }], bcc : [{ name : \"Jonnie Doe\" , address : \"jonnie.doe@sap.com\" }], subject : \"subject\" , subjectEncoding : \"UTF-8\" , parts : [ new net . Mail . Part ({ type : net . Mail . Part . TYPE_TEXT , text : \"The body of the mail.\" , contentType : \"text/plain\" , encoding : \"UTF-8\" , })] }); // Set mail server configuration. let mailConfig = { \"mail.user\" : \"<your-user>\" , \"mail.password\" : \"<your-password>\" , \"mail.transport.protocol\" : \"smtps\" , \"mail.smtps.host\" : \"<your-mail-provider-host>\" , \"mail.smtps.port\" : \"465\" , \"mail.smtps.auth\" : \"true\" }; let smtp = new net . SMTPConnection ( mailConfig ); // Send the mail Object with SMPT smtp . send ( mail ); // Send the mail Object from the built-in mail send method. let returnValue = mail . send ( mailConfig ); $ . response . setBody ( JSON . stringify ( returnValue )); Classes Classes Description Mail Class for constructing and sending multipart emails. SMTPConnection Class for sending $.net.Mail objects via SMTP connection. Destination Contains metadata, for example, host name and port number. Properties Name Description Type http Provides access to the http API. $.net.http HTTP constants for methods Name Description Type Default OPTIONS HTTP Method OPTIONS. number 0 GET HTTP Method GET. number 1 HEAD HTTP Method HEAD. number 2 POST HTTP Method POST. number 3 PUT HTTP Method PUT. number 4 DEL HTTP Method DEL. number 5 TRACE HTTP Method TRACE. number 6 CONNECT HTTP Method CONNECT. number 7 PATCH HTTP Method PATCH. number 8 Example let constantVal = $ . net . http . OPTIONS ; HTTP constants for status codes Name Type Default CONTINUE number 100 SWITCH_PROTOCOL number 101 OK number 200 CREATED number 201 ACCEPTED number 202 NON_AUTHORITATIVE number 203 NO_CONTENT number 204 RESET_CONTENT number 205 PARTIAL_CONTENT number 206 MULTIPLE_CHOICES number 300 MOVED_PERMANENTLY number 301 FOUND number 302 SEE_OTHER number 303 NOT_MODIFIED number 304 USE_PROXY number 305 TEMPORARY_REDIRECT number 307 BAD_REQUEST number 400 UNAUTHORIZED number 401 PAYMENT_REQUIRED number 402 FORBIDDEN number 403 NOT_FOUND number 404 METHOD_NOT_ALLOWED number 405 NOT_ACCEPTABLE number 406 PROXY_AUTH_REQUIRED number 407 REQUEST_TIMEOUT number 408 CONFLICT number 409 GONE number 410 LENGTH_REQUIRED number 411 PRECONDITION_FAILED number 412 REQUEST_ENTITY_TOO_LARGE number 413 REQUEST_URI_TOO_LONG number 414 UNSUPPORTED_MEDIA_TYPE number 415 REQUESTED_RANGE_NOT_SATISFIABLE number 416 EXPECTATION_FAILED number 417 INTERNAL_SERVER_ERROR number 500 NOT_YET_IMPLEMENTED number 501 BAD_GATEWAY number 502 SERVICE_UNAVAILABLE number 503 GATEWAY_TIMEOUT number 504 HTTP_VERSION_NOT_SUPPORTED number 505 Example let statusCode = $ . net . http . CONTINUE ;","title":"$.net"},{"location":"api/net/#net","text":"$.net represents the network namespace with its fields.","title":"$.net"},{"location":"api/net/#overview","text":"Definition: https://github.com/SAP/xsk/issues/19 Module: net/net.js Status: alpha","title":"Overview"},{"location":"api/net/#sample-usage","text":"Note Requires a running mail server. If mailConfig is not set the api defaults to a local mail server. For more information please take a look here . let net = $ . net ; // Create a mail Object let mail = new net . Mail ({ sender : { address : \"sender@sap.com\" }, to : [{ name : \"John Doe\" , address : \"john.doe@sap.com\" }, { name : \"Jane Doe\" , address : \"jane.doe@sap.com\" }], cc : [{ address : \"cc1@sap.com\" }, { address : \"cc2@sap.com\" }], bcc : [{ name : \"Jonnie Doe\" , address : \"jonnie.doe@sap.com\" }], subject : \"subject\" , subjectEncoding : \"UTF-8\" , parts : [ new net . Mail . Part ({ type : net . Mail . Part . TYPE_TEXT , text : \"The body of the mail.\" , contentType : \"text/plain\" , encoding : \"UTF-8\" , })] }); // Set mail server configuration. let mailConfig = { \"mail.user\" : \"<your-user>\" , \"mail.password\" : \"<your-password>\" , \"mail.transport.protocol\" : \"smtps\" , \"mail.smtps.host\" : \"<your-mail-provider-host>\" , \"mail.smtps.port\" : \"465\" , \"mail.smtps.auth\" : \"true\" }; let smtp = new net . SMTPConnection ( mailConfig ); // Send the mail Object with SMPT smtp . send ( mail ); // Send the mail Object from the built-in mail send method. let returnValue = mail . send ( mailConfig ); $ . response . setBody ( JSON . stringify ( returnValue ));","title":"Sample Usage"},{"location":"api/net/#classes","text":"Classes Description Mail Class for constructing and sending multipart emails. SMTPConnection Class for sending $.net.Mail objects via SMTP connection. Destination Contains metadata, for example, host name and port number.","title":"Classes"},{"location":"api/net/#properties","text":"Name Description Type http Provides access to the http API. $.net.http","title":"Properties"},{"location":"api/net/#http-constants-for-methods","text":"Name Description Type Default OPTIONS HTTP Method OPTIONS. number 0 GET HTTP Method GET. number 1 HEAD HTTP Method HEAD. number 2 POST HTTP Method POST. number 3 PUT HTTP Method PUT. number 4 DEL HTTP Method DEL. number 5 TRACE HTTP Method TRACE. number 6 CONNECT HTTP Method CONNECT. number 7 PATCH HTTP Method PATCH. number 8","title":"HTTP constants for methods"},{"location":"api/net/#example","text":"let constantVal = $ . net . http . OPTIONS ;","title":"Example"},{"location":"api/net/#http-constants-for-status-codes","text":"Name Type Default CONTINUE number 100 SWITCH_PROTOCOL number 101 OK number 200 CREATED number 201 ACCEPTED number 202 NON_AUTHORITATIVE number 203 NO_CONTENT number 204 RESET_CONTENT number 205 PARTIAL_CONTENT number 206 MULTIPLE_CHOICES number 300 MOVED_PERMANENTLY number 301 FOUND number 302 SEE_OTHER number 303 NOT_MODIFIED number 304 USE_PROXY number 305 TEMPORARY_REDIRECT number 307 BAD_REQUEST number 400 UNAUTHORIZED number 401 PAYMENT_REQUIRED number 402 FORBIDDEN number 403 NOT_FOUND number 404 METHOD_NOT_ALLOWED number 405 NOT_ACCEPTABLE number 406 PROXY_AUTH_REQUIRED number 407 REQUEST_TIMEOUT number 408 CONFLICT number 409 GONE number 410 LENGTH_REQUIRED number 411 PRECONDITION_FAILED number 412 REQUEST_ENTITY_TOO_LARGE number 413 REQUEST_URI_TOO_LONG number 414 UNSUPPORTED_MEDIA_TYPE number 415 REQUESTED_RANGE_NOT_SATISFIABLE number 416 EXPECTATION_FAILED number 417 INTERNAL_SERVER_ERROR number 500 NOT_YET_IMPLEMENTED number 501 BAD_GATEWAY number 502 SERVICE_UNAVAILABLE number 503 GATEWAY_TIMEOUT number 504 HTTP_VERSION_NOT_SUPPORTED number 505","title":"HTTP constants for status codes"},{"location":"api/net/#example_1","text":"let statusCode = $ . net . http . CONTINUE ;","title":"Example"},{"location":"api/net/net.Destination/","text":"$.net.Destination $.net.Destination class returns the network destination with the given name. A network destination contains metadata (e.g., host name or port number). The network destination can also contain custom properties. Overview Definition: https://github.com/SAP/xsk/issues/19 Module: net/net.js Status: alpha API Changes Destinations in XSK make use of SAP BTP Destination service (see xshttpdest ). As such, destinations no longer live in the file tree, so the first parameter of Destination representing the package is no longer needed. If provided, it will be ignored. Lookup for destinations happens based on the name. Sample Usage destination-sample.xsjs let net = $ . net ; /* Read service.xshttpdest inside the Demo package that contains: host=http://localhost; port=8080; */ let dest = new net . Destination ( \"Demo\" , \"service\" ); // Check if the file has been read properly $ . response . setBody ( \"Host: \" + dest . host + \" Port: \" + dest . port ); Constructors new $ . net . Destination ( package , objectName ) Throws an error if no valid destination is found with the given name. Parameters Parameter Name Description Required Type package Ignored as lookup is done in Destination service optional String objectName The name of the destination in Destination service required String","title":"$.net.Destination"},{"location":"api/net/net.Destination/#netdestination","text":"$.net.Destination class returns the network destination with the given name. A network destination contains metadata (e.g., host name or port number). The network destination can also contain custom properties.","title":"$.net.Destination"},{"location":"api/net/net.Destination/#overview","text":"Definition: https://github.com/SAP/xsk/issues/19 Module: net/net.js Status: alpha API Changes Destinations in XSK make use of SAP BTP Destination service (see xshttpdest ). As such, destinations no longer live in the file tree, so the first parameter of Destination representing the package is no longer needed. If provided, it will be ignored. Lookup for destinations happens based on the name.","title":"Overview"},{"location":"api/net/net.Destination/#sample-usage","text":"destination-sample.xsjs let net = $ . net ; /* Read service.xshttpdest inside the Demo package that contains: host=http://localhost; port=8080; */ let dest = new net . Destination ( \"Demo\" , \"service\" ); // Check if the file has been read properly $ . response . setBody ( \"Host: \" + dest . host + \" Port: \" + dest . port );","title":"Sample Usage"},{"location":"api/net/net.Destination/#constructors","text":"new $ . net . Destination ( package , objectName ) Throws an error if no valid destination is found with the given name.","title":"Constructors"},{"location":"api/net/net.Destination/#parameters","text":"Parameter Name Description Required Type package Ignored as lookup is done in Destination service optional String objectName The name of the destination in Destination service required String","title":"Parameters"},{"location":"api/net/net.Mail.Part/","text":"$.net.Mail.Part $.net.Mail.Part class for constructing email parts. Overview Definition: https://github.com/SAP/xsk/issues/19 Module: net/net.js Status: alpha Sample Usage Note Requires a running mail server. If mailConfig is not set the api defaults to a local mail server. For more information please take a look here . var files = require ( \"io/v4/files\" ); // Getting the byte array of the attachment. var xskLogo = files . readBytes ( 'path-to-file/xsk-logo.png' ); // Create an attachment $.net.Mail.Part from JSObject. var attachmentPart = new $ . net . Mail . Part ({ type : $ . net . Mail . Part . TYPE_ATTACHMENT , data : xskLogo , contentType : \"image/png\" , fileName : \"xsk-logo.png\" , fileNameEncoding : \"UTF-8\" }); // Getting the byte array of the inline image. var sapLogo = files . readBytes ( 'path-to-file/sap-logo.png' ); // Create an inline $.net.Mail.Part from JSObject. var inlinePart = new $ . net . Mail . Part ({ type : $ . net . Mail . Part . TYPE_INLINE , data : sapLogo , contentType : \"image/png\" , contentId : \"IMAGE1_ID\" , // The content id is used in the text part to display the image in the mail body. fileName : \"sap-logo.png\" , fileNameEncoding : \"UTF-8\" }); // Create a text $.net.Mail.Part object. var textPart = new $ . net . Mail . Part ({ type : $ . net . Mail . Part . TYPE_TEXT , text : \"<html><head></head><body><h1>This is XSK</h1><br><img src=\\\"cid:IMAGE1_ID\\\"><br></body></html>\" , contentType : \"text/html\" , encoding : \"UTF-8\" }); // Create an $.net.Mail object. var mail = new $ . net . Mail ({ sender : { address : \"sender@sap.com\" }, to : [{ name : \"to1\" , address : \"to1@sap.com\" }, { name : \"to2\" , address : \"to2@sap.com\" }], cc : [{ name : \"cc1\" , address : \"cc1@sap.com\" }, { name : \"cc2\" , address : \"cc2@sap.com\" }], bcc : [{ name : \"bcc1\" , address : \"bcc1@sap.com\" }], subject : \"subject\" , subjectEncoding : \"UTF-8\" }); mail . parts . push ( attachmentPart , inlinePart , textPart ); // Set mail server configurations. let mailConfig = { \"mail.user\" : \"<your-user>\" , \"mail.password\" : \"<your-password>\" , \"mail.transport.protocol\" : \"smtps\" , \"mail.smtps.host\" : \"<your-mail-provider-host>\" , \"mail.smtps.port\" : \"465\" , \"mail.smtps.auth\" : \"true\" }; let returnValue = mail . send ( mailConfig ); $ . response . setBody ( JSON . stringify ( returnValue )); Constructors new $ . net . Mail . Part ( PartObject ) Parameters Parameter Name Description Required Type PartObject JS object containing elements of a Part in JSON format. optional object Properties Name Description Type alternative Property used for initializing \"alternative\" property of the text $.net.Mail.Part object. string alternativeContentType Property used for initializing \"alternativeContentType\" property of the text $.net.Mail.Part object. If this property is not set, the default value is \"text/plain\". string contentId Property used for initializing \"contentId\" property of the inline $.net.Mail.Part object. string contentType Property used for initializing \"contentType\" property of the $.net.Mail.Part object. string data Property used for initializing \"data\" property of the attachment and inline $.net.Mail.Part object. string/ArrayBuffer encoding Property used for initializing \"encoding\" property of the text $.net.Mail.Part object. It also applies to alternative text. If this property is not set, the default value is \"UTF-8\". string fileName Property used for initializing \"fileName\" property of the attachment and inline $.net.Mail.Part object. It contains the full name of the file with the extension, example \"file.txt\". string fileNameEncoding Property used for initializing \"fileNameEncoding\" property of the attachment and inline $.net.Mail.Part object. It is the encoding of the filename. If this property is not set, the default value is \"UTF-8\". string text Property used for initializing \"text\" property of the text $.net.Mail.Part object. string type Property used for initializing \"type\" property of the $.net.Mail.Part object. If this property is not set, the part will not be set. It should be one of the following: $.net.Mail.Part.TYPE_TEXT $.net.Mail.Part.TYPE_ATTACHMENT $.net.Mail.Part.TYPE_INLINE string See common content types here .","title":"$.net.Mail.Part"},{"location":"api/net/net.Mail.Part/#netmailpart","text":"$.net.Mail.Part class for constructing email parts.","title":"$.net.Mail.Part"},{"location":"api/net/net.Mail.Part/#overview","text":"Definition: https://github.com/SAP/xsk/issues/19 Module: net/net.js Status: alpha","title":"Overview"},{"location":"api/net/net.Mail.Part/#sample-usage","text":"Note Requires a running mail server. If mailConfig is not set the api defaults to a local mail server. For more information please take a look here . var files = require ( \"io/v4/files\" ); // Getting the byte array of the attachment. var xskLogo = files . readBytes ( 'path-to-file/xsk-logo.png' ); // Create an attachment $.net.Mail.Part from JSObject. var attachmentPart = new $ . net . Mail . Part ({ type : $ . net . Mail . Part . TYPE_ATTACHMENT , data : xskLogo , contentType : \"image/png\" , fileName : \"xsk-logo.png\" , fileNameEncoding : \"UTF-8\" }); // Getting the byte array of the inline image. var sapLogo = files . readBytes ( 'path-to-file/sap-logo.png' ); // Create an inline $.net.Mail.Part from JSObject. var inlinePart = new $ . net . Mail . Part ({ type : $ . net . Mail . Part . TYPE_INLINE , data : sapLogo , contentType : \"image/png\" , contentId : \"IMAGE1_ID\" , // The content id is used in the text part to display the image in the mail body. fileName : \"sap-logo.png\" , fileNameEncoding : \"UTF-8\" }); // Create a text $.net.Mail.Part object. var textPart = new $ . net . Mail . Part ({ type : $ . net . Mail . Part . TYPE_TEXT , text : \"<html><head></head><body><h1>This is XSK</h1><br><img src=\\\"cid:IMAGE1_ID\\\"><br></body></html>\" , contentType : \"text/html\" , encoding : \"UTF-8\" }); // Create an $.net.Mail object. var mail = new $ . net . Mail ({ sender : { address : \"sender@sap.com\" }, to : [{ name : \"to1\" , address : \"to1@sap.com\" }, { name : \"to2\" , address : \"to2@sap.com\" }], cc : [{ name : \"cc1\" , address : \"cc1@sap.com\" }, { name : \"cc2\" , address : \"cc2@sap.com\" }], bcc : [{ name : \"bcc1\" , address : \"bcc1@sap.com\" }], subject : \"subject\" , subjectEncoding : \"UTF-8\" }); mail . parts . push ( attachmentPart , inlinePart , textPart ); // Set mail server configurations. let mailConfig = { \"mail.user\" : \"<your-user>\" , \"mail.password\" : \"<your-password>\" , \"mail.transport.protocol\" : \"smtps\" , \"mail.smtps.host\" : \"<your-mail-provider-host>\" , \"mail.smtps.port\" : \"465\" , \"mail.smtps.auth\" : \"true\" }; let returnValue = mail . send ( mailConfig ); $ . response . setBody ( JSON . stringify ( returnValue ));","title":"Sample Usage"},{"location":"api/net/net.Mail.Part/#constructors","text":"new $ . net . Mail . Part ( PartObject )","title":"Constructors"},{"location":"api/net/net.Mail.Part/#parameters","text":"Parameter Name Description Required Type PartObject JS object containing elements of a Part in JSON format. optional object","title":"Parameters"},{"location":"api/net/net.Mail.Part/#properties","text":"Name Description Type alternative Property used for initializing \"alternative\" property of the text $.net.Mail.Part object. string alternativeContentType Property used for initializing \"alternativeContentType\" property of the text $.net.Mail.Part object. If this property is not set, the default value is \"text/plain\". string contentId Property used for initializing \"contentId\" property of the inline $.net.Mail.Part object. string contentType Property used for initializing \"contentType\" property of the $.net.Mail.Part object. string data Property used for initializing \"data\" property of the attachment and inline $.net.Mail.Part object. string/ArrayBuffer encoding Property used for initializing \"encoding\" property of the text $.net.Mail.Part object. It also applies to alternative text. If this property is not set, the default value is \"UTF-8\". string fileName Property used for initializing \"fileName\" property of the attachment and inline $.net.Mail.Part object. It contains the full name of the file with the extension, example \"file.txt\". string fileNameEncoding Property used for initializing \"fileNameEncoding\" property of the attachment and inline $.net.Mail.Part object. It is the encoding of the filename. If this property is not set, the default value is \"UTF-8\". string text Property used for initializing \"text\" property of the text $.net.Mail.Part object. string type Property used for initializing \"type\" property of the $.net.Mail.Part object. If this property is not set, the part will not be set. It should be one of the following: $.net.Mail.Part.TYPE_TEXT $.net.Mail.Part.TYPE_ATTACHMENT $.net.Mail.Part.TYPE_INLINE string See common content types here .","title":"Properties"},{"location":"api/net/net.Mail/","text":"$.net.Mail $.net.Mail class for constructing and sending multi-part emails. Overview Definition: https://github.com/SAP/xsk/issues/19 Module: net/net.js Status: alpha Sample Usage Note Requires a running mail server. If mailConfig is not set the api defaults to a local mail server. For more information please take a look here . let net = $ . net ; // Create email from JS Object. let mail = new $ . net . Mail ({ sender : { address : \"sender@sap.com\" }, to : [{ name : \"John Doe\" , address : \"john.doe@sap.com\" }, { name : \"Jane Doe\" , address : \"jane.doe@sap.com\" }], cc : [{ address : \"cc1@sap.com\" }, { address : \"cc2@sap.com\" }], bcc : [{ name : \"Jonnie Doe\" , address : \"jonnie.doe@sap.com\" }], subject : \"subject\" , subjectEncoding : \"UTF-8\" , parts : [ new $ . net . Mail . Part ({ type : $ . net . Mail . Part . TYPE_TEXT , text : \"The body of the mail.\" , contentType : \"text/plain\" , encoding : \"UTF-8\" , })] }); // Set mail server configurations. let mailConfig = { \"mail.user\" : \"<your-user>\" , \"mail.password\" : \"<your-password>\" , \"mail.transport.protocol\" : \"smtps\" , \"mail.smtps.host\" : \"<your-mail-provider-host>\" , \"mail.smtps.port\" : \"465\" , \"mail.smtps.auth\" : \"true\" }; let returnValue = mail . send ( mailConfig ); $ . response . setBody ( JSON . stringify ( returnValue )); Constructors new $ . net . Mail ( MailObject ) Parameters Parameter Name Description Required Type MailObject JS object containing different part of the email in JSON format. Supported properties are {'sender', 'to', 'cc', 'bcc', 'subject', 'subjectEncoding', 'parts'}. optional object Classes Classes Description Part Class for constructing email parts. Properties Name Description Type bcc Property used for initializing \"bcc\" property of the mail. It is an array containing objects with three properties - name, encoding and address with address being required. array cc Property used for initializing \"cc\" property of the mail. It is an array containing objects with three properties - name, encoding and address with address being required. array parts Property used for initializing \"parts\" property of the mail. It is an array containing $.net.Mail.Part() objects. array sender Property used for initializing \"sender\" property of the mail. It is an array containing objects with three properties - name, encoding and address with address being required. This property is required or the mail won't be sent. object subject Property used for initializing \"subject\" property of the mail. string subjectEncoding Property used for initializing \"subjectEncoding\" property of the mail. It is the encoding of the subject. If this property is not set, the default value is \"UTF-8\". string to Property used for initializing \"to\" property of the mail. It is an array containing objects with three properties - name, encoding and address with address being required. array Functions Function Description Returns send(mailConfig) method that returns an object containing two properties: 'messageId' and 'finalReply'. object mailConfig Properties Property Description Type mail.user The mailbox user string mail.password The mailbox password string mail.transport.protocol (optional) The mail transport protocol, default is smtps string mail.smtps.host The mail SMPTPS host string mail.smtps.port The mail SMPTPS port number as string mail.smtps.auth Enable/Disable mail SMPTPS authentication boolean as string mail.smtp.host The mail SMPTP host string mail.smtp.port The mail SMPTP port number as string mail.smtp.auth Enable/Disable mail SMPTP authentication boolean as string Addition mail client options can be found here: - SMTP/SMTPS - IMAP - POP3","title":"$.net.Mail"},{"location":"api/net/net.Mail/#netmail","text":"$.net.Mail class for constructing and sending multi-part emails.","title":"$.net.Mail"},{"location":"api/net/net.Mail/#overview","text":"Definition: https://github.com/SAP/xsk/issues/19 Module: net/net.js Status: alpha","title":"Overview"},{"location":"api/net/net.Mail/#sample-usage","text":"Note Requires a running mail server. If mailConfig is not set the api defaults to a local mail server. For more information please take a look here . let net = $ . net ; // Create email from JS Object. let mail = new $ . net . Mail ({ sender : { address : \"sender@sap.com\" }, to : [{ name : \"John Doe\" , address : \"john.doe@sap.com\" }, { name : \"Jane Doe\" , address : \"jane.doe@sap.com\" }], cc : [{ address : \"cc1@sap.com\" }, { address : \"cc2@sap.com\" }], bcc : [{ name : \"Jonnie Doe\" , address : \"jonnie.doe@sap.com\" }], subject : \"subject\" , subjectEncoding : \"UTF-8\" , parts : [ new $ . net . Mail . Part ({ type : $ . net . Mail . Part . TYPE_TEXT , text : \"The body of the mail.\" , contentType : \"text/plain\" , encoding : \"UTF-8\" , })] }); // Set mail server configurations. let mailConfig = { \"mail.user\" : \"<your-user>\" , \"mail.password\" : \"<your-password>\" , \"mail.transport.protocol\" : \"smtps\" , \"mail.smtps.host\" : \"<your-mail-provider-host>\" , \"mail.smtps.port\" : \"465\" , \"mail.smtps.auth\" : \"true\" }; let returnValue = mail . send ( mailConfig ); $ . response . setBody ( JSON . stringify ( returnValue ));","title":"Sample Usage"},{"location":"api/net/net.Mail/#constructors","text":"new $ . net . Mail ( MailObject )","title":"Constructors"},{"location":"api/net/net.Mail/#parameters","text":"Parameter Name Description Required Type MailObject JS object containing different part of the email in JSON format. Supported properties are {'sender', 'to', 'cc', 'bcc', 'subject', 'subjectEncoding', 'parts'}. optional object","title":"Parameters"},{"location":"api/net/net.Mail/#classes","text":"Classes Description Part Class for constructing email parts.","title":"Classes"},{"location":"api/net/net.Mail/#properties","text":"Name Description Type bcc Property used for initializing \"bcc\" property of the mail. It is an array containing objects with three properties - name, encoding and address with address being required. array cc Property used for initializing \"cc\" property of the mail. It is an array containing objects with three properties - name, encoding and address with address being required. array parts Property used for initializing \"parts\" property of the mail. It is an array containing $.net.Mail.Part() objects. array sender Property used for initializing \"sender\" property of the mail. It is an array containing objects with three properties - name, encoding and address with address being required. This property is required or the mail won't be sent. object subject Property used for initializing \"subject\" property of the mail. string subjectEncoding Property used for initializing \"subjectEncoding\" property of the mail. It is the encoding of the subject. If this property is not set, the default value is \"UTF-8\". string to Property used for initializing \"to\" property of the mail. It is an array containing objects with three properties - name, encoding and address with address being required. array","title":"Properties"},{"location":"api/net/net.Mail/#functions","text":"Function Description Returns send(mailConfig) method that returns an object containing two properties: 'messageId' and 'finalReply'. object","title":"Functions"},{"location":"api/net/net.Mail/#mailconfig-properties","text":"Property Description Type mail.user The mailbox user string mail.password The mailbox password string mail.transport.protocol (optional) The mail transport protocol, default is smtps string mail.smtps.host The mail SMPTPS host string mail.smtps.port The mail SMPTPS port number as string mail.smtps.auth Enable/Disable mail SMPTPS authentication boolean as string mail.smtp.host The mail SMPTP host string mail.smtp.port The mail SMPTP port number as string mail.smtp.auth Enable/Disable mail SMPTP authentication boolean as string Addition mail client options can be found here: - SMTP/SMTPS - IMAP - POP3","title":"mailConfig Properties"},{"location":"api/net/net.SMTPConnection/","text":"$.net.SMTPConnection $.net.SMTPConnection class for sending $.net.Mail objects via SMTP connection. Overview Definition: https://github.com/SAP/xsk/issues/19 Module: net/net.js Status: alpha Sample Usage Note Requires a running mail server. If mailConfig is not set the api defaults to a local mail server. For more information please take a look here . var net = $ . net // Create email from JS Object. var mail = new net . Mail ({ sender : { address : \"sender@sap.com\" }, to : [{ name : \"John Doe\" , address : \"john.doe@sap.com\" }, { name : \"Jane Doe\" , address : \"jane.doe@sap.com\" }], cc : [{ address : \"cc1@sap.com\" }, { address : \"cc2@sap.com\" }], bcc : [{ name : \"Jonnie Doe\" , address : \"jonnie.doe@sap.com\" }], subject : \"subject\" , subjectEncoding : \"UTF-8\" , parts : [ new net . Mail . Part ({ type : net . Mail . Part . TYPE_TEXT , text : \"The body of the mail.\" , contentType : \"text/plain\" , encoding : \"UTF-8\" , })] }); // Set mail server configurations. let mailConfig = { \"mail.user\" : \"<your-user>\" , \"mail.password\" : \"<your-password>\" , \"mail.transport.protocol\" : \"smtps\" , \"mail.smtps.host\" : \"<your-mail-provider-host>\" , \"mail.smtps.port\" : \"465\" , \"mail.smtps.auth\" : \"true\" }; var smtp = new net . SMTPConnection ( mailConfig ); let returnValue = smtp . send ( mail ); $ . response . setBody ( JSON . stringify ( returnValue )); Constructors new $ . net . SMTPConnection ( mailConfig ) Parameters Parameter Name Description Required Type mailConfig JS object containing mail server configuration properties. optional object mailConfig Properties Property Description Type mail.user The mailbox user string mail.password The mailbox password string mail.transport.protocol (optional) The mail transport protocol, default is smtps string mail.smtps.host The mail SMPTPS host string mail.smtps.port The mail SMPTPS port number as string mail.smtps.auth Enable/Disable mail SMPTPS authentication boolean as string mail.smtp.host The mail SMPTP host string mail.smtp.port The mail SMPTP port number as string mail.smtp.auth Enable/Disable mail SMPTP authentication boolean as string Addition mail client options can be found here: - SMTP/SMTPS - IMAP - POP3 Functions Function Description Returns close() Mocked. The SMTP Connection is now automatically closed after calling the send method. void isClosed() Mocked. The SMTP Connection is always closed. boolean send(Mail) Accepts and sends the net.Mail class. void","title":"$.net.SMTPConnection"},{"location":"api/net/net.SMTPConnection/#netsmtpconnection","text":"$.net.SMTPConnection class for sending $.net.Mail objects via SMTP connection.","title":"$.net.SMTPConnection"},{"location":"api/net/net.SMTPConnection/#overview","text":"Definition: https://github.com/SAP/xsk/issues/19 Module: net/net.js Status: alpha","title":"Overview"},{"location":"api/net/net.SMTPConnection/#sample-usage","text":"Note Requires a running mail server. If mailConfig is not set the api defaults to a local mail server. For more information please take a look here . var net = $ . net // Create email from JS Object. var mail = new net . Mail ({ sender : { address : \"sender@sap.com\" }, to : [{ name : \"John Doe\" , address : \"john.doe@sap.com\" }, { name : \"Jane Doe\" , address : \"jane.doe@sap.com\" }], cc : [{ address : \"cc1@sap.com\" }, { address : \"cc2@sap.com\" }], bcc : [{ name : \"Jonnie Doe\" , address : \"jonnie.doe@sap.com\" }], subject : \"subject\" , subjectEncoding : \"UTF-8\" , parts : [ new net . Mail . Part ({ type : net . Mail . Part . TYPE_TEXT , text : \"The body of the mail.\" , contentType : \"text/plain\" , encoding : \"UTF-8\" , })] }); // Set mail server configurations. let mailConfig = { \"mail.user\" : \"<your-user>\" , \"mail.password\" : \"<your-password>\" , \"mail.transport.protocol\" : \"smtps\" , \"mail.smtps.host\" : \"<your-mail-provider-host>\" , \"mail.smtps.port\" : \"465\" , \"mail.smtps.auth\" : \"true\" }; var smtp = new net . SMTPConnection ( mailConfig ); let returnValue = smtp . send ( mail ); $ . response . setBody ( JSON . stringify ( returnValue ));","title":"Sample Usage"},{"location":"api/net/net.SMTPConnection/#constructors","text":"new $ . net . SMTPConnection ( mailConfig )","title":"Constructors"},{"location":"api/net/net.SMTPConnection/#parameters","text":"Parameter Name Description Required Type mailConfig JS object containing mail server configuration properties. optional object","title":"Parameters"},{"location":"api/net/net.SMTPConnection/#mailconfig-properties","text":"Property Description Type mail.user The mailbox user string mail.password The mailbox password string mail.transport.protocol (optional) The mail transport protocol, default is smtps string mail.smtps.host The mail SMPTPS host string mail.smtps.port The mail SMPTPS port number as string mail.smtps.auth Enable/Disable mail SMPTPS authentication boolean as string mail.smtp.host The mail SMPTP host string mail.smtp.port The mail SMPTP port number as string mail.smtp.auth Enable/Disable mail SMPTP authentication boolean as string Addition mail client options can be found here: - SMTP/SMTPS - IMAP - POP3","title":"mailConfig Properties"},{"location":"api/net/net.SMTPConnection/#functions","text":"Function Description Returns close() Mocked. The SMTP Connection is now automatically closed after calling the send method. void isClosed() Mocked. The SMTP Connection is always closed. boolean send(Mail) Accepts and sends the net.Mail class. void","title":"Functions"},{"location":"api/net/http/","text":"$.net.http $.net.http represents the http namespace with its fields. Overview Definition: https://github.com/SAP/xsk/issues/20 Module: http/http.js Status: alpha Sample Usage service.xshttpdest service.xshttpdest let http = $ . net . http ; /* Read service.xshttpdest inside the Demo package that contains: host=https://services.odata.org; pathPrefix=/V4/Northwind/Northwind.svc/; */ let destination = http . readDestination ( \"Demo\" , \"service\" ); // create client let client = new http . Client (); let request = new http . Request ( http . GET , \"/\" ); // new Request(METHOD, PATH) // the PATH will be prefixed by destination's pathPrefix, e.g. \"/search?\" on the request // set the timeout in seconds client . setTimeout ( 10 ); // send the request and synchronously get the response client . request ( request , dest ); let response = client . getResponse (); // get all the cookies and headers from the response let cookies = [], headers = []; for ( let i = 0 ; i < response . cookies . length ; i ++ ) { cookies . push ( response . cookies [ i ]); } for ( let i = 0 ; i < response . headers . length ; i ++ ) { headers . push ( response . headers [ i ]); } // get the body let body ; if ( ! response . body ) body = \"\" ; else body = response . body ; // close the connection client . close (); // prevent socket leak - see xsengine.ini: [communication] - max_open_sockets_per_request // check the contents of the response $ . response . setBody ( \"status: \" + response . status + \" cookies: \" + JSON . stringify ( cookies ) + \" headers: \" + JSON . stringify ( headers ) + \" body: \" + body . asString ()); host = https : //services.odata.org; pathPrefix = /V4/Northwind/Northwind.svc/; Classes Classes Description Destination Contains metadata, for example, host name, port number and custom values. Client HTTP(s) Client for outbound connectivity. This client supports HTTP and HTTPs connections over HTTP or SOCKS proxy. Request Request class to be used with HTTP client. Functions Function Description Returns readDestination(package, objectName) Returns the HTTP destination with the given name as a Destination object. $.net.http. Destination HTTP constants for methods Name Description Type Default OPTIONS HTTP Method OPTIONS. number 0 GET HTTP Method GET. number 1 HEAD HTTP Method HEAD. number 2 POST HTTP Method POST. number 3 PUT HTTP Method PUT. number 4 DEL HTTP Method DEL. number 5 TRACE HTTP Method TRACE. number 6 CONNECT HTTP Method CONNECT. number 7 PATCH HTTP Method PATCH. number 8 HTTP constants for status codes Name Type Default CONTINUE number 100 SWITCH_PROTOCOL number 101 OK number 200 CREATED number 201 ACCEPTED number 202 NON_AUTHORITATIVE number 203 NO_CONTENT number 204 RESET_CONTENT number 205 PARTIAL_CONTENT number 206 MULTIPLE_CHOICES number 300 MOVED_PERMANENTLY number 301 FOUND number 302 SEE_OTHER number 303 NOT_MODIFIED number 304 USE_PROXY number 305 TEMPORARY_REDIRECT number 307 BAD_REQUEST number 400 UNAUTHORIZED number 401 PAYMENT_REQUIRED number 402 FORBIDDEN number 403 NOT_FOUND number 404 METHOD_NOT_ALLOWED number 405 NOT_ACCEPTABLE number 406 PROXY_AUTH_REQUIRED number 407 REQUEST_TIMEOUT number 408 CONFLICT number 409 GONE number 410 LENGTH_REQUIRED number 411 PRECONDITION_FAILED number 412 REQUEST_ENTITY_TOO_LARGE number 413 REQUEST_URI_TOO_LONG number 414 UNSUPPORTED_MEDIA_TYPE number 415 REQUESTED_RANGE_NOT_SATISFIABLE number 416 EXPECTATION_FAILED number 417 INTERNAL_SERVER_ERROR number 500 NOT_YET_IMPLEMENTED number 501 BAD_GATEWAY number 502 SERVICE_UNAVAILABLE number 503 GATEWAY_TIMEOUT number 504 HTTP_VERSION_NOT_SUPPORTED number 505","title":"$.net.http"},{"location":"api/net/http/#nethttp","text":"$.net.http represents the http namespace with its fields.","title":"$.net.http"},{"location":"api/net/http/#overview","text":"Definition: https://github.com/SAP/xsk/issues/20 Module: http/http.js Status: alpha","title":"Overview"},{"location":"api/net/http/#sample-usage","text":"service.xshttpdest service.xshttpdest let http = $ . net . http ; /* Read service.xshttpdest inside the Demo package that contains: host=https://services.odata.org; pathPrefix=/V4/Northwind/Northwind.svc/; */ let destination = http . readDestination ( \"Demo\" , \"service\" ); // create client let client = new http . Client (); let request = new http . Request ( http . GET , \"/\" ); // new Request(METHOD, PATH) // the PATH will be prefixed by destination's pathPrefix, e.g. \"/search?\" on the request // set the timeout in seconds client . setTimeout ( 10 ); // send the request and synchronously get the response client . request ( request , dest ); let response = client . getResponse (); // get all the cookies and headers from the response let cookies = [], headers = []; for ( let i = 0 ; i < response . cookies . length ; i ++ ) { cookies . push ( response . cookies [ i ]); } for ( let i = 0 ; i < response . headers . length ; i ++ ) { headers . push ( response . headers [ i ]); } // get the body let body ; if ( ! response . body ) body = \"\" ; else body = response . body ; // close the connection client . close (); // prevent socket leak - see xsengine.ini: [communication] - max_open_sockets_per_request // check the contents of the response $ . response . setBody ( \"status: \" + response . status + \" cookies: \" + JSON . stringify ( cookies ) + \" headers: \" + JSON . stringify ( headers ) + \" body: \" + body . asString ()); host = https : //services.odata.org; pathPrefix = /V4/Northwind/Northwind.svc/;","title":"Sample Usage"},{"location":"api/net/http/#classes","text":"Classes Description Destination Contains metadata, for example, host name, port number and custom values. Client HTTP(s) Client for outbound connectivity. This client supports HTTP and HTTPs connections over HTTP or SOCKS proxy. Request Request class to be used with HTTP client.","title":"Classes"},{"location":"api/net/http/#functions","text":"Function Description Returns readDestination(package, objectName) Returns the HTTP destination with the given name as a Destination object. $.net.http. Destination","title":"Functions"},{"location":"api/net/http/#http-constants-for-methods","text":"Name Description Type Default OPTIONS HTTP Method OPTIONS. number 0 GET HTTP Method GET. number 1 HEAD HTTP Method HEAD. number 2 POST HTTP Method POST. number 3 PUT HTTP Method PUT. number 4 DEL HTTP Method DEL. number 5 TRACE HTTP Method TRACE. number 6 CONNECT HTTP Method CONNECT. number 7 PATCH HTTP Method PATCH. number 8","title":"HTTP constants for methods"},{"location":"api/net/http/#http-constants-for-status-codes","text":"Name Type Default CONTINUE number 100 SWITCH_PROTOCOL number 101 OK number 200 CREATED number 201 ACCEPTED number 202 NON_AUTHORITATIVE number 203 NO_CONTENT number 204 RESET_CONTENT number 205 PARTIAL_CONTENT number 206 MULTIPLE_CHOICES number 300 MOVED_PERMANENTLY number 301 FOUND number 302 SEE_OTHER number 303 NOT_MODIFIED number 304 USE_PROXY number 305 TEMPORARY_REDIRECT number 307 BAD_REQUEST number 400 UNAUTHORIZED number 401 PAYMENT_REQUIRED number 402 FORBIDDEN number 403 NOT_FOUND number 404 METHOD_NOT_ALLOWED number 405 NOT_ACCEPTABLE number 406 PROXY_AUTH_REQUIRED number 407 REQUEST_TIMEOUT number 408 CONFLICT number 409 GONE number 410 LENGTH_REQUIRED number 411 PRECONDITION_FAILED number 412 REQUEST_ENTITY_TOO_LARGE number 413 REQUEST_URI_TOO_LONG number 414 UNSUPPORTED_MEDIA_TYPE number 415 REQUESTED_RANGE_NOT_SATISFIABLE number 416 EXPECTATION_FAILED number 417 INTERNAL_SERVER_ERROR number 500 NOT_YET_IMPLEMENTED number 501 BAD_GATEWAY number 502 SERVICE_UNAVAILABLE number 503 GATEWAY_TIMEOUT number 504 HTTP_VERSION_NOT_SUPPORTED number 505","title":"HTTP constants for status codes"},{"location":"api/net/http/net.http.Client/","text":"$.net.http.Client HTTP(s) client for outbound connectivity. This client supports HTTP and HTTPS connections over HTTP or SOCKS proxy. You can either use a destination (preferred way) or a URL as target. To use HTTPS you need to specify a trust store with the needed certificates (either in the destination or with setTrustStore ). To choose between HTTP and SOCKS proxy, the proxy URL starts with either http:// or socks:// . This HttpClient is equipped with a cookie database. If a previous response sent a set-cookie header, the cookie is stored for the relevant domain and path. Subsequent requests will be enriched with the stored cookies automatically. Overview Definition: https://github.com/SAP/xsk/issues/20 Module: http/http.js Status: alpha Sample Usage client-sample.xsjs let http = $ . net . http ; /* Read service.xshttpdest inside the Demo package that contains: host=https://services.odata.org; pathPrefix=/V4/Northwind/Northwind.svc/; */ let destination = http . readDestination ( \"Demo\" , \"service\" ); // create client let client = new http . Client (); let request = new http . Request ( http . GET , \"/\" ); // new Request(METHOD, PATH) // the PATH will be prefixed by destination's pathPrefix, e.g. \"/search?\" on the request // set the timeout in seconds client . setTimeout ( 10 ); // send the request and synchronously get the response client . request ( request , destination ); let response = client . getResponse (); // get all the cookies and headers from the response let cookies = [], headers = []; for ( let i = 0 ; i < response . cookies . length ; i ++ ) { cookies . push ( response . cookies [ i ]); } for ( let i = 0 ; i < response . headers . length ; i ++ ) { headers . push ( response . headers [ i ]); } // check the contents of the response $ . response . setBody ( \"status: \" + response . status + \" cookies: \" + JSON . stringify ( cookies ) + \" headers: \" + JSON . stringify ( headers ) + \" body: \" + response . body . asString ()); Functions Function Description Returns close() Close the connection. It is done automatically inside the HttpClientFacade. No need to call it explicitly! void getResponse() Retrieve the response from the previously sent request synchronously/blocking. Throws an error if there is no valid response to return $.web.WebResponse request($.net.http.Request, $.net.http.Destination) Send a new request object to the given destination. Throws an error if the request fails or the parameters are invalid. void request($.net.http.Request, url, proxy (optional)) Send a request object to the given URL. Throws an error if the request fails or the parameters are invalid. void request(WebMethod ($.net.http), url, proxy (optional)) Send a new request to the given URL, using the specified HTTP method. Throws an error if the request fails or the parameters are invalid. void setTimeout(timeout) Sets the timeout for communication with the server. Throws an error if the parameter is not a numeric value. void setTrustStore(trustStore) Sets the default trust store the will be used when issuing https:// requests via request(request, URI, ...)-syntax. void","title":"$.net.http.Client"},{"location":"api/net/http/net.http.Client/#nethttpclient","text":"HTTP(s) client for outbound connectivity. This client supports HTTP and HTTPS connections over HTTP or SOCKS proxy. You can either use a destination (preferred way) or a URL as target. To use HTTPS you need to specify a trust store with the needed certificates (either in the destination or with setTrustStore ). To choose between HTTP and SOCKS proxy, the proxy URL starts with either http:// or socks:// . This HttpClient is equipped with a cookie database. If a previous response sent a set-cookie header, the cookie is stored for the relevant domain and path. Subsequent requests will be enriched with the stored cookies automatically.","title":"$.net.http.Client"},{"location":"api/net/http/net.http.Client/#overview","text":"Definition: https://github.com/SAP/xsk/issues/20 Module: http/http.js Status: alpha","title":"Overview"},{"location":"api/net/http/net.http.Client/#sample-usage","text":"client-sample.xsjs let http = $ . net . http ; /* Read service.xshttpdest inside the Demo package that contains: host=https://services.odata.org; pathPrefix=/V4/Northwind/Northwind.svc/; */ let destination = http . readDestination ( \"Demo\" , \"service\" ); // create client let client = new http . Client (); let request = new http . Request ( http . GET , \"/\" ); // new Request(METHOD, PATH) // the PATH will be prefixed by destination's pathPrefix, e.g. \"/search?\" on the request // set the timeout in seconds client . setTimeout ( 10 ); // send the request and synchronously get the response client . request ( request , destination ); let response = client . getResponse (); // get all the cookies and headers from the response let cookies = [], headers = []; for ( let i = 0 ; i < response . cookies . length ; i ++ ) { cookies . push ( response . cookies [ i ]); } for ( let i = 0 ; i < response . headers . length ; i ++ ) { headers . push ( response . headers [ i ]); } // check the contents of the response $ . response . setBody ( \"status: \" + response . status + \" cookies: \" + JSON . stringify ( cookies ) + \" headers: \" + JSON . stringify ( headers ) + \" body: \" + response . body . asString ());","title":"Sample Usage"},{"location":"api/net/http/net.http.Client/#functions","text":"Function Description Returns close() Close the connection. It is done automatically inside the HttpClientFacade. No need to call it explicitly! void getResponse() Retrieve the response from the previously sent request synchronously/blocking. Throws an error if there is no valid response to return $.web.WebResponse request($.net.http.Request, $.net.http.Destination) Send a new request object to the given destination. Throws an error if the request fails or the parameters are invalid. void request($.net.http.Request, url, proxy (optional)) Send a request object to the given URL. Throws an error if the request fails or the parameters are invalid. void request(WebMethod ($.net.http), url, proxy (optional)) Send a new request to the given URL, using the specified HTTP method. Throws an error if the request fails or the parameters are invalid. void setTimeout(timeout) Sets the timeout for communication with the server. Throws an error if the parameter is not a numeric value. void setTrustStore(trustStore) Sets the default trust store the will be used when issuing https:// requests via request(request, URI, ...)-syntax. void","title":"Functions"},{"location":"api/net/http/net.http.Destination/","text":"$.net.http.Destination HTTP(s) destination class that holds metadata (e.g., host, port, useSSL). The destination can be retrieved from the database with $.net.http.readDestination . Overview Definition: https://github.com/SAP/xsk/issues/20 Module: http/http.js Status: alpha API Changes Destinations in XSK make use of SAP BTP Destination service (see xshttpdest ). As such, destinations no longer live in the file tree, so the first parameter of readDestination representing the package is no longer needed. If provided, it will be ignored. Lookup for destinations happens based on the name. Sample Usage destination-sample.xsjs let http = $ . net . http ; /* Read service.xshttpdest inside the Demo package that contains: host=https://services.odata.org; pathPrefix=/V4/Northwind/Northwind.svc/; */ let dest = http . readDestination ( \"Demo\" , \"service\" ); // Check if the file has been read properly $ . response . setBody ( \"Host: \" + dest . host + \" Path Prefix: \" + dest . pathPrefix );","title":"$.net.http.Destination"},{"location":"api/net/http/net.http.Destination/#nethttpdestination","text":"HTTP(s) destination class that holds metadata (e.g., host, port, useSSL). The destination can be retrieved from the database with $.net.http.readDestination .","title":"$.net.http.Destination"},{"location":"api/net/http/net.http.Destination/#overview","text":"Definition: https://github.com/SAP/xsk/issues/20 Module: http/http.js Status: alpha API Changes Destinations in XSK make use of SAP BTP Destination service (see xshttpdest ). As such, destinations no longer live in the file tree, so the first parameter of readDestination representing the package is no longer needed. If provided, it will be ignored. Lookup for destinations happens based on the name.","title":"Overview"},{"location":"api/net/http/net.http.Destination/#sample-usage","text":"destination-sample.xsjs let http = $ . net . http ; /* Read service.xshttpdest inside the Demo package that contains: host=https://services.odata.org; pathPrefix=/V4/Northwind/Northwind.svc/; */ let dest = http . readDestination ( \"Demo\" , \"service\" ); // Check if the file has been read properly $ . response . setBody ( \"Host: \" + dest . host + \" Path Prefix: \" + dest . pathPrefix );","title":"Sample Usage"},{"location":"api/net/http/net.http.Request/","text":"$.net.http.Request $.net.http.Request class to be used with HTTP client. It extends $.web.WebRequest . Overview Definition: https://github.com/SAP/xsk/issues/20 Module: http/http.js Status: alpha Sample Usage request-sample.xsjs let http = $ . net . http ; let dest = http . readDestination ( \"Demo\" , \"service\" ); // create client let client = new http . Client (); // create Request class with the HTTP method constants as a first argument and the path of the resource as a second let request = new http . Request ( http . GET , \"/\" ); // new Request(METHOD, PATH) // the PATH will be prefixed by destination's pathPrefix, e.g. \"/search?\" on the request // Use the Request class to send an http request with the net.http.Client class client . request ( request , dest ); Properties Name Description Type body The body of the request. The value is undefined when there is no body. Only available on $.request. $.web.Body contentType The content type of the entity. string cookies The cookies associated with the entity. $.web.TupelList entities The sub-entities of the entity. $.web.EntityList headers The headers of the entity. $.web.TupelList language Readonly. Language of the request in IETF (BCP 47) format. This property contains the language that is used for the request. Application code should rely on this property only. The value is a string in the format specified by the IETF (BCP 47) standard. Inherited From: $.web.WebRequest#language string method The HTTP method of the incoming HTTP request. Inherited From: $.web.WebRequest#method $.net.http parameters The parameters of the entity. $.web.TupelList path Readonly. The URL path specified in the request. string queryPath The URL query path specified in the request. Inherited From: $.web.WebRequest#queryPath string Functions Function Description Returns setBody(body, index(optional)) Sets the body of the entity; the method supports all elemental JavaScript types and ArrayBuffers as a body and numbers as an index. Throws an error if the parameters are invalid. void","title":"$.net.http.Request"},{"location":"api/net/http/net.http.Request/#nethttprequest","text":"$.net.http.Request class to be used with HTTP client. It extends $.web.WebRequest .","title":"$.net.http.Request"},{"location":"api/net/http/net.http.Request/#overview","text":"Definition: https://github.com/SAP/xsk/issues/20 Module: http/http.js Status: alpha","title":"Overview"},{"location":"api/net/http/net.http.Request/#sample-usage","text":"request-sample.xsjs let http = $ . net . http ; let dest = http . readDestination ( \"Demo\" , \"service\" ); // create client let client = new http . Client (); // create Request class with the HTTP method constants as a first argument and the path of the resource as a second let request = new http . Request ( http . GET , \"/\" ); // new Request(METHOD, PATH) // the PATH will be prefixed by destination's pathPrefix, e.g. \"/search?\" on the request // Use the Request class to send an http request with the net.http.Client class client . request ( request , dest );","title":"Sample Usage"},{"location":"api/net/http/net.http.Request/#properties","text":"Name Description Type body The body of the request. The value is undefined when there is no body. Only available on $.request. $.web.Body contentType The content type of the entity. string cookies The cookies associated with the entity. $.web.TupelList entities The sub-entities of the entity. $.web.EntityList headers The headers of the entity. $.web.TupelList language Readonly. Language of the request in IETF (BCP 47) format. This property contains the language that is used for the request. Application code should rely on this property only. The value is a string in the format specified by the IETF (BCP 47) standard. Inherited From: $.web.WebRequest#language string method The HTTP method of the incoming HTTP request. Inherited From: $.web.WebRequest#method $.net.http parameters The parameters of the entity. $.web.TupelList path Readonly. The URL path specified in the request. string queryPath The URL query path specified in the request. Inherited From: $.web.WebRequest#queryPath string","title":"Properties"},{"location":"api/net/http/net.http.Request/#functions","text":"Function Description Returns setBody(body, index(optional)) Sets the body of the entity; the method supports all elemental JavaScript types and ArrayBuffers as a body and numbers as an index. Throws an error if the parameters are invalid. void","title":"Functions"},{"location":"api/util/","text":"$.util Overview Definition: https://github.com/SAP/xsk/issues/16 Module: util/util.js Status: alpha Sample Usage const util = $ . util ; let randomID = util . createUuid (); // Uint8Array let arrayBuffer = [ 84 , 104 , 105 , 115 , 32 , 105 , 115 , 32 , 97 , 32 , 85 , 105 , ]; let convertedBuff = util . stringify ( arrayBuffer ); let result = `randomID is : ${ randomID } ` ; result += `\\nconvertedBuff is: ${ arrayBuffer } ` ; $ . response . setBody ( result ); Classes Classes Description SAXParser Class for parsing XML. It is based on expat. Zip Class for manipulation of zip archives. Functions Members Description Returns createUuid() Returns a unique UUID. string stringify(data) Recieves UintArray and return converted value. string","title":"$.util"},{"location":"api/util/#util","text":"","title":"$.util"},{"location":"api/util/#overview","text":"Definition: https://github.com/SAP/xsk/issues/16 Module: util/util.js Status: alpha","title":"Overview"},{"location":"api/util/#sample-usage","text":"const util = $ . util ; let randomID = util . createUuid (); // Uint8Array let arrayBuffer = [ 84 , 104 , 105 , 115 , 32 , 105 , 115 , 32 , 97 , 32 , 85 , 105 , ]; let convertedBuff = util . stringify ( arrayBuffer ); let result = `randomID is : ${ randomID } ` ; result += `\\nconvertedBuff is: ${ arrayBuffer } ` ; $ . response . setBody ( result );","title":"Sample Usage"},{"location":"api/util/#classes","text":"Classes Description SAXParser Class for parsing XML. It is based on expat. Zip Class for manipulation of zip archives.","title":"Classes"},{"location":"api/util/#functions","text":"Members Description Returns createUuid() Returns a unique UUID. string stringify(data) Recieves UintArray and return converted value. string","title":"Functions"},{"location":"api/util/util.Zip/","text":"$.util.Zip $.util.Zip is a class for manipulation of zip archives. It provides functionality for compressing, uncompressing, removal of entries and zip encryption. Overview Definition: https://github.com/SAP/xsk/issues/684 Module: util/util.js Status: alpha Sample Usage Create a new zip object. // Create a new zip object var zip = new $ . util . Zip (); // Set content to the zip object zip [ 'xsk.txt' ] = 'This is XSK' ; // Download the zip file $ . response . status = $ . net . http . OK ; $ . response . contentType = 'application/zip' ; $ . response . headers . set ( 'Content-Disposition' , 'attachment; filename = test.zip' ); $ . response . setBody ( zip . asArrayBuffer ()); Create a zip object from byte array source. // Zip byte array source var source = [ 123 , 34 , 120 , 115 , 107 , 46 , 116 , 120 , 116 , 34 , 58 , 34 , 84 , 104 , 105 , 115 , 32 , 105 , 115 , 32 , 88 , 83 , 75 , 34 , 125 ]; var zip = new $ . util . Zip ({ source : source }); for ( var entry in zip ) { // Loop through zip entries and modify if needed if ( entry === 'xsk.txt' ) { zip [ entry ] = 'XSK is great' } } // Download the zip file $ . response . status = $ . net . http . OK ; $ . response . contentType = 'application/zip' ; $ . response . headers . set ( 'Content-Disposition' , 'attachment; filename = test.zip' ); $ . response . setBody ( zip . asArrayBuffer ()); Constructors new $ . util . Zip ( config ) Parameters Zip object Name Description Type config Object containing new zip configuration parameters. object config object Name Description Type source Specifies the source for the compressed content. If no source is specified, an empty Zip object is created. byte array / $.db.ResultSet / $.web.Body index If the first argument is of type ResultSet, the number specifies the index of a Blob column and is mandatory. number settings Used to specify zip options. object settings object Name Description Type password The password is mandatory when creating a zip object from an existing encrypted archive. string maxUncompressedSizeInBytes A global restriction applies to the amount of data that can be uncompressed number Properties Name Description Type metadata Contains meta information about the current zip object. object password Setting a value to this property changes the password used for encryption of the zip object. Assigning an empty string disables encryption. Accessing this property will return undefined. string Functions Function Description Returns asArrayBuffer() Returns the zip archive as byte array byte array","title":"$.util.Zip"},{"location":"api/util/util.Zip/#utilzip","text":"$.util.Zip is a class for manipulation of zip archives. It provides functionality for compressing, uncompressing, removal of entries and zip encryption.","title":"$.util.Zip"},{"location":"api/util/util.Zip/#overview","text":"Definition: https://github.com/SAP/xsk/issues/684 Module: util/util.js Status: alpha","title":"Overview"},{"location":"api/util/util.Zip/#sample-usage","text":"Create a new zip object. // Create a new zip object var zip = new $ . util . Zip (); // Set content to the zip object zip [ 'xsk.txt' ] = 'This is XSK' ; // Download the zip file $ . response . status = $ . net . http . OK ; $ . response . contentType = 'application/zip' ; $ . response . headers . set ( 'Content-Disposition' , 'attachment; filename = test.zip' ); $ . response . setBody ( zip . asArrayBuffer ()); Create a zip object from byte array source. // Zip byte array source var source = [ 123 , 34 , 120 , 115 , 107 , 46 , 116 , 120 , 116 , 34 , 58 , 34 , 84 , 104 , 105 , 115 , 32 , 105 , 115 , 32 , 88 , 83 , 75 , 34 , 125 ]; var zip = new $ . util . Zip ({ source : source }); for ( var entry in zip ) { // Loop through zip entries and modify if needed if ( entry === 'xsk.txt' ) { zip [ entry ] = 'XSK is great' } } // Download the zip file $ . response . status = $ . net . http . OK ; $ . response . contentType = 'application/zip' ; $ . response . headers . set ( 'Content-Disposition' , 'attachment; filename = test.zip' ); $ . response . setBody ( zip . asArrayBuffer ());","title":"Sample Usage"},{"location":"api/util/util.Zip/#constructors","text":"new $ . util . Zip ( config )","title":"Constructors"},{"location":"api/util/util.Zip/#parameters","text":"","title":"Parameters"},{"location":"api/util/util.Zip/#zip-object","text":"Name Description Type config Object containing new zip configuration parameters. object","title":"Zip object"},{"location":"api/util/util.Zip/#config-object","text":"Name Description Type source Specifies the source for the compressed content. If no source is specified, an empty Zip object is created. byte array / $.db.ResultSet / $.web.Body index If the first argument is of type ResultSet, the number specifies the index of a Blob column and is mandatory. number settings Used to specify zip options. object","title":"config object"},{"location":"api/util/util.Zip/#settings-object","text":"Name Description Type password The password is mandatory when creating a zip object from an existing encrypted archive. string maxUncompressedSizeInBytes A global restriction applies to the amount of data that can be uncompressed number","title":"settings object"},{"location":"api/util/util.Zip/#properties","text":"Name Description Type metadata Contains meta information about the current zip object. object password Setting a value to this property changes the password used for encryption of the zip object. Assigning an empty string disables encryption. Accessing this property will return undefined. string","title":"Properties"},{"location":"api/util/util.Zip/#functions","text":"Function Description Returns asArrayBuffer() Returns the zip archive as byte array byte array","title":"Functions"},{"location":"api/util/util.codec/","text":"$.util.codec $.util.codec object represents the codec namespace with its fields. Overview Definition: https://github.com/SAP/xsk/issues/21 Module: util/codec/codec.js Status: alpha Sample Usage const codec = $ . util . codec ; const util = $ . util ; const text1 = \"Project XSK as Hex\" ; const text2 = \"Project XSK as Base64\" ; //Hex let result = \"\" ; let encodedHex = codec . encodeHex ( text1 ); result += `' ${ text1 } ' encoded to hex is ${ encodedHex } ` ; let decodedHex = codec . decodeHex ( encodedHex ); result += `\\n' ${ encodedHex } ' decoded to ArrayBuffer is: [ ${ decodedHex } ]` ; let valueFromHex = util . stringify ( decodedHex ); result += `\\n Array Buffer stringified is: ' ${ valueFromHex } '\\n` ; //Base64 let encodedToBase64 = codec . encodeBase64 ( text2 ); result += `\\n' ${ text2 } ' encoded to base64 is ${ encodedToBase64 } ` ; let decodedBase64 = codec . decodeBase64 ( encodedToBase64 ); result += `\\n' ${ encodedToBase64 } ' encoded to ArrayBuffer is: [ ${ decodedBase64 } ]` ; let valueFromBase64 = util . stringify ( decodedBase64 ); result += `\\n Array Buffer stringified is ' ${ valueFromBase64 } '` ; $ . response . setBody ( result ); Functions Function Description Returns decodeBase64(data) Decodes Base64 data. ArrayBuffer decodeHex(data) Decodes hexadecimal data. ArrayBuffer encodeBase64(data) Encodes data into Base64. string encodeHex(data) Encodes data into hexadecimal format. string","title":"$.util.codec"},{"location":"api/util/util.codec/#utilcodec","text":"$.util.codec object represents the codec namespace with its fields.","title":"$.util.codec"},{"location":"api/util/util.codec/#overview","text":"Definition: https://github.com/SAP/xsk/issues/21 Module: util/codec/codec.js Status: alpha","title":"Overview"},{"location":"api/util/util.codec/#sample-usage","text":"const codec = $ . util . codec ; const util = $ . util ; const text1 = \"Project XSK as Hex\" ; const text2 = \"Project XSK as Base64\" ; //Hex let result = \"\" ; let encodedHex = codec . encodeHex ( text1 ); result += `' ${ text1 } ' encoded to hex is ${ encodedHex } ` ; let decodedHex = codec . decodeHex ( encodedHex ); result += `\\n' ${ encodedHex } ' decoded to ArrayBuffer is: [ ${ decodedHex } ]` ; let valueFromHex = util . stringify ( decodedHex ); result += `\\n Array Buffer stringified is: ' ${ valueFromHex } '\\n` ; //Base64 let encodedToBase64 = codec . encodeBase64 ( text2 ); result += `\\n' ${ text2 } ' encoded to base64 is ${ encodedToBase64 } ` ; let decodedBase64 = codec . decodeBase64 ( encodedToBase64 ); result += `\\n' ${ encodedToBase64 } ' encoded to ArrayBuffer is: [ ${ decodedBase64 } ]` ; let valueFromBase64 = util . stringify ( decodedBase64 ); result += `\\n Array Buffer stringified is ' ${ valueFromBase64 } '` ; $ . response . setBody ( result );","title":"Sample Usage"},{"location":"api/util/util.codec/#functions","text":"Function Description Returns decodeBase64(data) Decodes Base64 data. ArrayBuffer decodeHex(data) Decodes hexadecimal data. ArrayBuffer encodeBase64(data) Encodes data into Base64. string encodeHex(data) Encodes data into hexadecimal format. string","title":"Functions"},{"location":"api/web/","text":"$.web $.web represents the web api namespace which is related to the $.request and $.response APIs. Overview Definition: https://github.com/SAP/xsk/issues/22 Module: web/web.js Status: alpha Classes Classes Description Body Class for representing the body of an HTTP request entity. EntityList Class representing a list of request or response entities. TupelList Class representing a list of name-value pairs. WebEntityRequest Class representing an HTTP request entity. WebEntityResponse Class representing an HTTP response entity. WebRequest Class representing the client HTTP request currently being processed. WebResponse Class representing the HTTP response currently being populated.","title":"$.web"},{"location":"api/web/#web","text":"$.web represents the web api namespace which is related to the $.request and $.response APIs.","title":"$.web"},{"location":"api/web/#overview","text":"Definition: https://github.com/SAP/xsk/issues/22 Module: web/web.js Status: alpha","title":"Overview"},{"location":"api/web/#classes","text":"Classes Description Body Class for representing the body of an HTTP request entity. EntityList Class representing a list of request or response entities. TupelList Class representing a list of name-value pairs. WebEntityRequest Class representing an HTTP request entity. WebEntityResponse Class representing an HTTP response entity. WebRequest Class representing the client HTTP request currently being processed. WebResponse Class representing the HTTP response currently being populated.","title":"Classes"},{"location":"api/web/web.Body/","text":"$.web.Body $.web.Body represents the body of an HTTP request entity. Overview Definition: https://github.com/SAP/xsk/issues/22 Module: web/web.js Status: alpha Functions Function Description Returns asArrayBuffer() Returns the content of an HTTP request entity body as ArrayBuffer. ArrayBuffer asArrayBuffer() Returns the content of an HTTP request entity body as ArrayBuffer. string asWebRequest() Returns the content of an HTTP request entity body as WebRequest. $.web.WebRequest","title":"$.web.Body"},{"location":"api/web/web.Body/#webbody","text":"$.web.Body represents the body of an HTTP request entity.","title":"$.web.Body"},{"location":"api/web/web.Body/#overview","text":"Definition: https://github.com/SAP/xsk/issues/22 Module: web/web.js Status: alpha","title":"Overview"},{"location":"api/web/web.Body/#functions","text":"Function Description Returns asArrayBuffer() Returns the content of an HTTP request entity body as ArrayBuffer. ArrayBuffer asArrayBuffer() Returns the content of an HTTP request entity body as ArrayBuffer. string asWebRequest() Returns the content of an HTTP request entity body as WebRequest. $.web.WebRequest","title":"Functions"},{"location":"api/web/web.EntityList/","text":"$.web.EntityList $.web.Entitylist represents a list of request or response entities. Overview Definition: https://github.com/SAP/xsk/issues/22 Module: web/web.js Status: alpha Properties Name Description Type length The size of the entity list. integer Functions Function Description Returns create() Creates a sub-entity in the current list of entities in EntityList. $.web.WebEntityResponse","title":"$.web.EntityList"},{"location":"api/web/web.EntityList/#webentitylist","text":"$.web.Entitylist represents a list of request or response entities.","title":"$.web.EntityList"},{"location":"api/web/web.EntityList/#overview","text":"Definition: https://github.com/SAP/xsk/issues/22 Module: web/web.js Status: alpha","title":"Overview"},{"location":"api/web/web.EntityList/#properties","text":"Name Description Type length The size of the entity list. integer","title":"Properties"},{"location":"api/web/web.EntityList/#functions","text":"Function Description Returns create() Creates a sub-entity in the current list of entities in EntityList. $.web.WebEntityResponse","title":"Functions"},{"location":"api/web/web.TupelList/","text":"$.web.TupelList $.web.TupelList represents a list of name-value pairs. Overview Definition: https://github.com/SAP/xsk/issues/22 Module: web/web.js Status: alpha Properties Name Description Type length The size of the tupel list. integer Functions Function Description Returns get(name) Returns the values for a given name. string remove(name) Removes the value for a given name. - set(name, value) Sets the value for a given name. boolean","title":"$.web.TupelList"},{"location":"api/web/web.TupelList/#webtupellist","text":"$.web.TupelList represents a list of name-value pairs.","title":"$.web.TupelList"},{"location":"api/web/web.TupelList/#overview","text":"Definition: https://github.com/SAP/xsk/issues/22 Module: web/web.js Status: alpha","title":"Overview"},{"location":"api/web/web.TupelList/#properties","text":"Name Description Type length The size of the tupel list. integer","title":"Properties"},{"location":"api/web/web.TupelList/#functions","text":"Function Description Returns get(name) Returns the values for a given name. string remove(name) Removes the value for a given name. - set(name, value) Sets the value for a given name. boolean","title":"Functions"},{"location":"api/web/web.WebEntityRequest/","text":"$.web.WebEntityRequest $.web.WebEntityRequest represents an HTTP request entity. Overview Definition: https://github.com/SAP/xsk/issues/22 Module: web/web.js Status: alpha Properties Name Description Type body The body of the request. $.web.Body contentType The content type of the entity. string entities The sub-entities of the entity. $.web.EntityList headers The headers of the entity. $.web.TupelList parameters The parameters of the entity. $.web.TupelList Functions Function Description Returns setBody(body, index) Sets the body of the entity. -","title":"$.web.WebEntityRequest"},{"location":"api/web/web.WebEntityRequest/#webwebentityrequest","text":"$.web.WebEntityRequest represents an HTTP request entity.","title":"$.web.WebEntityRequest"},{"location":"api/web/web.WebEntityRequest/#overview","text":"Definition: https://github.com/SAP/xsk/issues/22 Module: web/web.js Status: alpha","title":"Overview"},{"location":"api/web/web.WebEntityRequest/#properties","text":"Name Description Type body The body of the request. $.web.Body contentType The content type of the entity. string entities The sub-entities of the entity. $.web.EntityList headers The headers of the entity. $.web.TupelList parameters The parameters of the entity. $.web.TupelList","title":"Properties"},{"location":"api/web/web.WebEntityRequest/#functions","text":"Function Description Returns setBody(body, index) Sets the body of the entity. -","title":"Functions"},{"location":"api/web/web.WebEntityResponse/","text":"$.web.WebEntityResponse $.web.WebEntityResponse represents an HTTP response entity. Overview Definition: https://github.com/SAP/xsk/issues/22 Module: web/web.js Status: alpha Properties Name Description Type body The body of the response. $.web.Body contentType The content type of the entity. string entities The sub-entities of the entity. $.web.EntityList headers The headers of the entity. $.web.TupelList Functions Function Description Returns setBody(body, index) Sets the body of the entity. -","title":"$.web.WebEntityResponse"},{"location":"api/web/web.WebEntityResponse/#webwebentityresponse","text":"$.web.WebEntityResponse represents an HTTP response entity.","title":"$.web.WebEntityResponse"},{"location":"api/web/web.WebEntityResponse/#overview","text":"Definition: https://github.com/SAP/xsk/issues/22 Module: web/web.js Status: alpha","title":"Overview"},{"location":"api/web/web.WebEntityResponse/#properties","text":"Name Description Type body The body of the response. $.web.Body contentType The content type of the entity. string entities The sub-entities of the entity. $.web.EntityList headers The headers of the entity. $.web.TupelList","title":"Properties"},{"location":"api/web/web.WebEntityResponse/#functions","text":"Function Description Returns setBody(body, index) Sets the body of the entity. -","title":"Functions"},{"location":"artifacts/","text":"Artifacts Overview This page lists the HANA artifacts and whether they are supported by XSK. Reference SAP HANA Cloud HDI Artifact types For more information on the HDI artifacts in SAP HANA Cloud, see SAP Help Portal . Artifacts Object Type Supported analyticprivilege (SAP Help Portal) Yes (HDI-only) calculationview Yes (HDI-only) hdbafllangprocedure No (missing in HANA Cloud) hdbanalyticprivilege Yes (HDI-only) hdbapplicationtime Yes (HDI-only) hdbcalculationview Yes (HDI-only) hdbcds Yes hdbcollection Yes (HDI-only) hdbcollectionindex Yes (HDI-only) hdbconstraint Yes (HDI-only) hdbcopyonly Yes (HDI-only) hdbdropcreatetable Yes (HDI-only) hdbeshconfig Yes (HDI-only) hdbflowgraph Yes (HDI-only) hdbfulltextindex No (missing in HANA Cloud) hdbfunction Yes hdbgraphworkspace Yes (HDI-only) hdbindex Yes (HDI-only) hdblibrary Yes (HDI-only) hdblogicalschema Yes (HDI-only) hdbmigrationtable Yes (HDI-only) hdbprocedure Yes hdbprojectionview Yes (HDI-only) hdbremotetable No (missing in HANA Cloud) hdbreptask Yes (HDI-only) hdbresultcache Yes (HDI-only) hdbrmjob No (missing in HANA Cloud) hdbrole Yes hdbscalarfunction Yes hdbsearchruleset Yes (HDI-only) hdbsequence Yes hdbstatistics Yes (HDI-only) hdbstructuredprivilege Yes (HDI-only) hdbsynonym Yes hdbsystemversioning Yes (HDI-only) hdbtable Yes hdbtablefunction Yes hdbtabletype Yes hdbtextconfig No (missing in HANA Cloud) hdbti Yes hdbtextdict No (missing in HANA Cloud) hdbtextdictionary No (missing in HANA Cloud) hdbtextinclude No (missing in HANA Cloud) hdbtextlexicon No (missing in HANA Cloud) hdbtextminingconfig No (missing in HANA Cloud) hdbtextrule No (missing in HANA Cloud) hdbview Yes hdbvirtualfunction Yes (HDI-only) hdbvirtualfunctionpackage Yes (HDI-only) hdbvirtualpackage Yes (HDI-only) hdbvirtualprocedure Yes (HDI-only) hdbvirtualtable Yes (HDI-only) procedure Yes searchruleset Yes (HDI-only) tags Yes (HDI-only) textminingconfig No (missing in HANA Cloud) xsaccess Yes xsprivileges Yes xshttpdest Yes xsjob Yes xsjs Yes xsjslib Yes xsodata Yes","title":"Artifacts"},{"location":"artifacts/#artifacts","text":"","title":"Artifacts"},{"location":"artifacts/#overview","text":"This page lists the HANA artifacts and whether they are supported by XSK.","title":"Overview"},{"location":"artifacts/#reference","text":"SAP HANA Cloud HDI Artifact types For more information on the HDI artifacts in SAP HANA Cloud, see SAP Help Portal .","title":"Reference"},{"location":"artifacts/#artifacts_1","text":"Object Type Supported analyticprivilege (SAP Help Portal) Yes (HDI-only) calculationview Yes (HDI-only) hdbafllangprocedure No (missing in HANA Cloud) hdbanalyticprivilege Yes (HDI-only) hdbapplicationtime Yes (HDI-only) hdbcalculationview Yes (HDI-only) hdbcds Yes hdbcollection Yes (HDI-only) hdbcollectionindex Yes (HDI-only) hdbconstraint Yes (HDI-only) hdbcopyonly Yes (HDI-only) hdbdropcreatetable Yes (HDI-only) hdbeshconfig Yes (HDI-only) hdbflowgraph Yes (HDI-only) hdbfulltextindex No (missing in HANA Cloud) hdbfunction Yes hdbgraphworkspace Yes (HDI-only) hdbindex Yes (HDI-only) hdblibrary Yes (HDI-only) hdblogicalschema Yes (HDI-only) hdbmigrationtable Yes (HDI-only) hdbprocedure Yes hdbprojectionview Yes (HDI-only) hdbremotetable No (missing in HANA Cloud) hdbreptask Yes (HDI-only) hdbresultcache Yes (HDI-only) hdbrmjob No (missing in HANA Cloud) hdbrole Yes hdbscalarfunction Yes hdbsearchruleset Yes (HDI-only) hdbsequence Yes hdbstatistics Yes (HDI-only) hdbstructuredprivilege Yes (HDI-only) hdbsynonym Yes hdbsystemversioning Yes (HDI-only) hdbtable Yes hdbtablefunction Yes hdbtabletype Yes hdbtextconfig No (missing in HANA Cloud) hdbti Yes hdbtextdict No (missing in HANA Cloud) hdbtextdictionary No (missing in HANA Cloud) hdbtextinclude No (missing in HANA Cloud) hdbtextlexicon No (missing in HANA Cloud) hdbtextminingconfig No (missing in HANA Cloud) hdbtextrule No (missing in HANA Cloud) hdbview Yes hdbvirtualfunction Yes (HDI-only) hdbvirtualfunctionpackage Yes (HDI-only) hdbvirtualpackage Yes (HDI-only) hdbvirtualprocedure Yes (HDI-only) hdbvirtualtable Yes (HDI-only) procedure Yes searchruleset Yes (HDI-only) tags Yes (HDI-only) textminingconfig No (missing in HANA Cloud) xsaccess Yes xsprivileges Yes xshttpdest Yes xsjob Yes xsjs Yes xsjslib Yes xsodata Yes","title":"Artifacts"},{"location":"artifacts/hdbanalyticprivilege/","text":"HDBAnalyticPrivilege Overview The information on this page will help you learn how to continue using analytic privileges in your XS Classic applications running on XSK. Transition path All classical XML-based analytic privileges need to be SQL analytic privileges. The applyPrivilegeType attribute in the calculation views must be set to SQL_ANALYTIC_PRIVILEGE References to SESSION_USER are changed to SESSION_CONTEXT('APPLICATIONUSER') . This is automatically done during migration. Assignment of analytic privileges happens only through hdbroles. During migration, a default hdbrole is created which references the analytic privileges used in the project and is assigned to the technical XSK user. Reference SAP Help Portal For more information, see Analytic Privileges .","title":"hdbanalyticprivilege"},{"location":"artifacts/hdbanalyticprivilege/#hdbanalyticprivilege","text":"","title":"HDBAnalyticPrivilege"},{"location":"artifacts/hdbanalyticprivilege/#overview","text":"The information on this page will help you learn how to continue using analytic privileges in your XS Classic applications running on XSK.","title":"Overview"},{"location":"artifacts/hdbanalyticprivilege/#transition-path","text":"All classical XML-based analytic privileges need to be SQL analytic privileges. The applyPrivilegeType attribute in the calculation views must be set to SQL_ANALYTIC_PRIVILEGE References to SESSION_USER are changed to SESSION_CONTEXT('APPLICATIONUSER') . This is automatically done during migration. Assignment of analytic privileges happens only through hdbroles. During migration, a default hdbrole is created which references the analytic privileges used in the project and is assigned to the technical XSK user.","title":"Transition path"},{"location":"artifacts/hdbanalyticprivilege/#reference","text":"SAP Help Portal For more information, see Analytic Privileges .","title":"Reference"},{"location":"artifacts/hdbdd/","text":"HDBCDS Overview The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the HDBCDS syntax, also known as HDBDD. CDS file CDS documents are design-time source files that contain DDL code that describes a persistence model according to rules defined in Core Data Services. CDS documents have the file suffix .hdbdd. Each CDS document must contain the following basic elements: namespace The name space you define must be the first declaration in the CDS document and match the absolute package path to the location of the CDS document in the repository. schema definition The schema you specify is used to store the catalog objects that are defined in the CDS document, for example: entities, structured types, and views. The objects are generated in the catalog when the CDS document is synchronized by the xsk runtime. CDS artifact definitions The objects that make up your persistence model, for example: contexts, entities and structured types Each CDS document must contain one top-level artifact, for example: a context, a type, an entity, or a view. The name of the top-level artifact in the CDS document must match the file name of the CDS document, without the suffix. For example, if the top-level artifact is a context named MyModel, the name of the CDS document must be MyModel.hdbdd. CDS artifact Context If you want to define multiple CDS artifacts within a single CDS document (for example, multiple types, structured types, and entities), the top-level artifact must be a context . A CDS document can contain multiple contexts and any number and type of artifacts. A context can also contain nested sub-contexts, each of which can also contain any number and type of artifacts. Example na mespace com.acme.myapp 1 ; @Schema : 'MySchema' co nte x t MyCo nte x t { // Nes te d co nte x ts co nte x t I nner C t x { E nt i t y MyE nt i t y { \u2026 } ; Type C t xType { a : I nte ger; b : S tr i n g( 59 ); } ; } ; } ; Entity In the SAP HANA database, as in other relational databases, a CDS entity is a table with a set of data elements. Each element will correspond to a table column on synchronizing the .hdbdd file. Example e nt i t y MyTable { key Au t hor : S tr i n g( 100 ); key BookTi tle : S tr i n g( 100 ); ISBN : I nte ger n o t null ; Publisher : S tr i n g( 100 ); elem 2 : S tr i n g( 20 ) de fault 'Joh n Doe'; elem 3 : S tr i n g( 20 ) de fault 'Joh n Doe' null ; } ; Element na me : S tr i n g( 20 ); age : I nte ger; address : ha na .VARCHAR; Each element(field) of the entity definition has to contain at least a name and a type. You can expand the definition of an entity element beyond the element's name and type by using element modifiers. For example, you can specify if an entity element is the primary key or part of the primary key. The following entity element modifiers are available: key Defines if the specified element is the primary key or part of the primary key for the specified entity. null Defines if an entity element can (null) or cannot (not null) have the value NULL. If neither null nor not null is specified for the element, the default value null applies (except for the key element). default Defines the default value for an entity element in the event that no value is provided during an INSERT operation. The syntax for the literals is defined in the primitive data-type specification. Example of more literals wich could be used as default values for their corresponding scalar type. e nt i t y Wi t hDe faults { key id : I nte ger; f ield 1 : I nte ger de fault -42 ; f ield 2 : I nte ger 64 de fault 9223372036854775807 ; f ield 3 : Decimal( 5 , 3 ) de fault 12.345 ; f ield 4 : Bi nar yFloa t de fault 123.456e-1 ; f ield 5 : LocalDa te de fault da te ' 2013-04-29 '; f ield 6 : LocalTime de fault t ime' 17 : 04 : 03 '; f ield 7 : UTCDa te Time de fault t imes ta mp' 2013-05-01 01 : 02 : 03 '; f ield 8 : UTCTimes ta mp de fault t imes ta mp' 2013-05-01 01 : 02 : 03 '; f ield 9 : Bi nar y( 32 ) de fault x' 0102030405060708090 a 0 b 0 c 0 d 0e0 [ ... ] '; f ield 10 : S tr i n g( 10 ) de fault ' f oo'; } ; Structured User-Defined Types A structured type is a data type comprising a list of attributes, each of which has its own data type. The attributes of the structured type can be defined manually in the structured type itself and reused either by another structured type or an entity. In a structured user-defined type, you can define original types (aNumber in the following example) or reference existing types defined elsewhere in the same type definition or another, separate type definition (MyString80). If you define multiple types in a single CDS document, for example, in a parent context, each structure-type definition must be separated by a semi-colon (;). The type MyString80 is defined in the following CDS document: na mespace Package 1. Package 2 ; @Schema : 'MySchema' t ype MyS tr i n g 80 : S tr i n g( 80 ); A using directive is required to resolve the reference to the data type specified in otherText : MyString80;, as illustrated in the following example: na mespace Package 1. Package 2 ; usi n g Package 1. Package 2 :: MyS tr i n g 80 ; //co nta i ns de f i n i t io n o f MyS tr i n g 80 @Schema : 'MySchema' t ype MyS tru c t { aNumber : I nte ger; someTex t : S tr i n g( 80 ); o t herTex t : MyS tr i n g 80 ; // de f i ne d i n a separa te t ype } ; Nested Structured Types Since user-defined types can make use of other user-defined types, you can build nested structured types, as illustrated in the following example: na mespace com.sap.u n i; @Schema : 'MYSCHEMA' co nte x t Co nte x t A { t ype Address { s treet : S tr i n g( 50 ); nu mber : I nte ger; zipCode : I nte ger; } ; t ype S tu de nt { na me : S tr i n g( 50 ) age : I nte ger; address : Address; } ; } ; For each structured type, a SAP HANA table type is generated, whose name is built by concatenating the following elements of the CDS document containing the structured-type definition and separating the elements by a dot delimiter (.): the name space the names of all artifacts that enclose the type the name of the type itself The columns of the table type are built by flattening the elements of the type. Elements with structured types are mapped to one column per nested element, with the column names built by concatenating the element names and separating the names by dots \".\". Taking the above example the following will be generated in the database: crea te t ype \"com.sap.uni::ContextA.Address\" as ta ble ( s treet : varchar( 50 ); nu mber : i nte ger; zipCode : i nte ger; ); crea te t ype \"com.sap.uni::ContextA.Student\" as ta ble ( na me : varchar( 50 ); age : i nte ger; address.s treet : varchar( 50 ); address. nu mber : i nte ger; address.zipCode : i nte ger; ); The new SAP HANA table types are generated in the schema that is specified in the schema annotation of the respective top-level artifact in the CDS document containing the structured types. Table types are only generated for direct structure definitions; in the following example, this would include: MyStruct, MyNestedStruct, and MyDeepNestedStruct. No table types are generated for derived types that are based on structured types; in the following example, the derived types include: MyS, MyOtherInt, MyOtherStruct. na mespace Pack 1. \"pack-age2\" ; @Schema : 'MySchema' co nte x t MyModel { t ype MyI nte ger : I nte ger; t ype MyS tr i n g 80 : S tr i n g( 80 ); t ype MyDecimal : Decimal( 10 , 2 ); t ype MyS tru c t { aNumber : I nte ger; someTex t : S tr i n g( 80 ); o t herTex t : MyS tr i n g 80 ; // de f i ne d i n example above } ; t ype MyS : MyS tru c t ; t ype MyO t herI nt : t ype o f MyS tru c t .aNumber; t ype MyO t herS tru c t : t ype o f MyDeepNes te dS tru c t . neste d. neste d; t ype MyNes te dS tru c t { na me : MyS tr i n g 80 ; neste d : MyS; } ; t ype MyDeepNes te dS tru c t { te x t : LargeS tr i n g; neste d : MyNes te dS tru c t ; } ; } ; type of You can also define a type based on an existing type that is already defined in another user-defined structured type, for example, by using the 'type of' keyword, as illustrated in the following example: t ype MyO t herI nt : t ype o f Address. nu mber; // => I nte ger t ype MyS tr i n g : t ype o f S tu de nt .address.s treet ; // => S tr i n g( 50 ) The following code example shows how to use the type of keyword to define an element using the definition specified in another user-defined data-type field. For example, field4 : type of field3; indicates that, like field3, field4 is a LocalDate data type. e nt i t y MyE nt i t y 1 { key id : I nte ger; f ield 1 : MyType 3 ; f ield 2 : S tr i n g( 24 ); f ield 3 : LocalDa te ; f ield 4 : t ype o f f ield 3 ; f ield 5 : t ype o f MyType 1. f ield 2 ; f ield 6 : t ype o f I nner C t x.C t xType.b; // co nte x t re feren ce } ; Associations Associations define relationships between entities. Associations are specified by adding an element to a source entity with an association type that points to a target entity, complemented by optional information defining cardinality and which keys to use. There are two kinds of associations available: Managed Associations Unmanaged Associations Association Syntax Association cardinality to targetEntity managed / unmanaged cardinality When using an association to define a relationship between entities in a CDS; you use the cardinality to specify the type of relation, for example: - one-to-one (to-one) - one-to-many (to-n) na mespace samples; @Schema : 'MYSCHEMA' // XS classic *o nl y* co nte x t Associa t io n Cardi nal i t y { e nt i t y Associa t io ns { // To - o ne associa t io ns assoc 1 : Associa t io n [ 0..1 ] t o tar ge t ; assoc 2 : Associa t io n t o tar ge t ; assoc 3 : Associa t io n [ 1 ] t o tar ge t ; assoc 4 : Associa t io n [ 1..1 ] t o tar ge t ; // associa t io n has o ne tar ge t i nstan ce // To - ma n y associa t io ns assoc 5 : Associa t io n [ 0.. * ] t o tar ge t { id 1 } ; assoc 6 : Associa t io n [] t o tar ge t { id 1 } ; // as assoc 4 , [] is shor t f or [ 0.. * ] assoc 7 : Associa t io n [ 2..7 ] t o tar ge t { id 1 } ; // a n y nu mbers are possible; user provides assoc 8 : Associa t io n [ 1 , 0.. * ] t o tar ge t { id 1 } ; // addi t io nal i nf o. abou t source cardi nal i t y } ; // Required t o make t he example above work e nt i t y tar ge t { key id 1 : I nte ger; key id 2 : I nte ger; } ; } ; Association Cardinality Syntax Examples: Association Cardinality Explanation assoc1 [0..1] The association has no or one target instance assoc2 [0..1] Like assoc1, this association has no or one target instance and uses the default [0..1] assoc3 [1] Like assoc1, this association has no or one target instance; the default for min is 0 assoc4 [1..1] The association has one target instance. No validation process will occur, so not specifing a target instance is still valid. assoc5 [0..*] The association has no, one, or multiple target instances assoc6 [] Like assoc4, [] is short for [0..*] (the association has no, one, or multiple target instances) assoc7 [2..7] Any numbers are possible; the user provides. No validation will occur and unlimited number of target instances will be possible. assoc8 [1, 0..*] The association has no, one, or multiple target instances and includes additional information about the source cardinality managed In the relational model, associations are mapped to foreign-key relationships. For managed associations, the relation between source and target entity is defined by specifying a set of elements of the target entity that are used as a foreign key. If no foreign keys are specified explicitly, the elements of the target entity\u2019s designated primary key are used. Elements of the target entity that reside inside substructures can be addressed by means of the respective path. If the chosen elements do not form a unique key of the target entity, the association has cardinality to-many. The following examples show how to express foreign keys in an association. e nt i t y Perso n { key id : I nte ger; // address 1 , 2 , 3 are t o - o ne associa t io ns address 1 : Associa t io n t o Address; address 2 : Associa t io n t o Address { id } ; address 3 : Associa t io n [ 1 ] t o Address { zipCode , s treet , cou ntr y } ; // address 4 , 5 , 6 are t o - ma n y associa t io ns address 4 : Associa t io n [ 0.. * ] t o Address { zipCode } ; address 5 : Associa t io n [ * ] t o Address { s treet . na me } ; address 6 : Associa t io n [ * ] t o Address { s treet . na me AS s treet Name , cou ntr y. na me AS cou ntr yName } ; } ; Association Keys Explanation address1 No foreign keys are specified: the target entity's primary key (the element id) is used as foreign key. Currently not a supported feature. address2 { id } Explicitly specifies the foreign key (the element id); this definition is identical to address1. address3 { zipCode, street, country } The foreign key elements to be used for the association are explicitly specified, namely: zipcode and the structured elements street and country. address4 { zipCode } Uses only zipcode as the foreign key. Since zipcode is not a unique key for entity Address, this association has cardinality \u201cto-many\u201d. (No validation present and \"to-one\" relation is till possible. It should throw error!) address5 { street.name } Uses the sub-element name of the structured element street as a foreign key. This is not a unique key and, as a result, address4 has cardinality \u201cto-many\u201d. address6 { street.name AS streetName, country.name AS countryName } Currently not suported syntax. It will be included in future releases. unmanaged Unmanaged associations are based on existing elements of the source and target entity; no fields are generated. In the ON condition, only elements of the source or the target entity can be used; it is not possible to use other associations. The ON condition may contain only comparison between target and source via the \"=\" sign. In the following example, the association inhabitants relates the element id of the source entity Room with the element officeId in the target entity Employee. The target element officeId is accessed through the name of the association itself. na mespace samples; @Schema : 'MYSCHEMA' // XS classic *o nl y* co nte x t U n ma na gedAssocia t io ns { e nt i t y Employee { key id : I nte ger; o ff iceId : I nte ger; } ; e nt i t y Room { key id : I nte ger; i n habi tants : Associa t io n [ * ] t o Employee o n i n habi tants .o ff iceId = id; } ; e nt i t y Thi n g { key id : I nte ger; pare nt Id : I nte ger; pare nt : Associa t io n [ 1 ] t o Thi n g o n pare nt .id = pare nt Id; childre n : Associa t io n [ * ] t o Thi n g o n childre n .pare nt Id = id; } ; } ; The following example defines two related unmanaged associations: parent The unmanaged association parent uses a cardinality of [1] to create a relation between the element parentId and the target element id. The target element id is accessed through the name of the association itself. children The unmanaged association children creates a relation between the element id and the target element parentId. The target element parentId is accessed through the name of the association itself. e nt i t y Thi n g { key id : I nte ger; pare nt Id : I nte ger; pare nt : Associa t io n [ 1 ] t o Thi n g o n pare nt .id = pare nt Id; childre n : Associa t io n [ * ] t o Thi n g o n childre n .pare nt Id = id; ... } ; Naming conventions Rules and restrictions apply to the names of CDS documents and the package in which the CDS document resides. The rules that apply for naming CDS documents are the same as the rules for naming the packages in which the CDS document is located. When specifying the name of a package or a CDS document (or referencing the name of an existing CDS object, for example, within a CDS document), bear in mind the following rules: File suffix .hdbdd, for example, MyModel.hdbdd. Permitted characters CDS object and package names can include the following characters: Lower or upper case letters(aA-zZ), the underscore character(_) and dash(-) Digits(0-9) Forbidden characters You cannot use the dot (.) in the name of a CDS document. You cannot use a digit (0-9) as the first character of the name of either a CDS document or a package, for example, 2CDSobjectname.hdbdd (XS classic) or acme.com.1package.hdbcds (XS advanced). The CDS parser does not recognize either CDS document names or package names that consist exclusively of digits, for example, 1234.hdbdd (XS classic) or acme.com.999.hdbcds. Note: Although it is possible to use quotation marks (\"\") to wrap a name that includes forbidden characters, as a general rule, it is recommended to follow the naming conventions for CDS documents specified here in order to avoid problems during activation in the repository. External Artifacts in CDS You can define an artifact in one CDS document by referring to an artifact that is defined in another CDS document. The CDS syntax enables you to define a CDS artifact in one document by basing it on an \u201cexternal\u201d artifact - an artifact that is defined in a separate CDS document. Each external artifact must be explicitly declared in the source CDS document with the 'using' keyword, which specifies the location of the external artifact, its name, and where appropriate its CDS context. The using declarations must be located in the header of the CDS document between the namespace declaration and the beginning of the top-level artifact, for example, the context. The external artifact can be either a single object (for example, a type, an entity, or a view) or a context. You can also include an optional alias in the using declaration, for example, ContextA.ContextA1 as ic. The alias (ic) can then be used in subsequent type definitions in the source CDS document. na mespace Pack 1. Dis tr ibu te d; usi n g Pack 1. Dis tr ibu te d :: Co nte x t A.T 1 ; usi n g Pack 1. Dis tr ibu te d :: Co nte x t A.Co nte x t AI as ic; usi n g Pack 1. Dis tr ibu te d :: Co nte x t A.Co nte x t AI.T 3 as ic t 3 ; usi n g Pack 1. Dis tr ibu te d :: Co nte x t A.Co nte x t AI.T 3. a as a; // error , is n o t a n ar t i fa c t co nte x t Co nte x t B { t ype T 10 { a : T 1 ; // I nte ger b : ic.T 2 ; // S tr i n g( 20 ) c : ic.T 3 ; // s tru c ture d d : t ype o f ic.T 3. b; // S tr i n g( 88 ) e : ic t 3 ; // s tru c ture d x : Pack 1. Dis tr ibu te d :: Co nte x t A.T 1 ; // error , direc t re feren ce n o t allowed } ; co nte x t Co nte x t BI { t ype T 1 : S tr i n g( 7 ); // hides t he T 1 comi n g fr om t he f irs t usi n g declara t io n t ype T 2 : T 1 ; // S tr i n g( 7 ) } ; } ; The CDS document ContextB.hdbdd shown above uses external artifacts (data types T1 and T3) that are defined in the \u201ctarget\u201d CDS document ContextA.hdbdd shown below. Two using declarations are present in the CDS document ContextB.hdbdd; one with no alias and one with an explictly specified alias (ic). The first using declaration introduces the scalar type Pack1.Distributed::ContextA.T1. The second using declaration introduces the context Pack1.Distributed::ContextA.ContextAI and makes it accessible by means of the explicitly specified alias ic. If no explicit alias is specified, the last part of the fully qualified name is assumed as the alias, for example T1. CDS Primitive Data Types In the Data Definition Language (DDL), primitive (or core) data types are the basic building blocks that you use to define entities or structure types with DDL. When you are specifying a design-time table (entity) using the CDS syntax, you use data types such as String, Binary, or Integer to specify the type of content in the entity columns. Here are the supported types supports the use of the following primitive data types: - DDL data types - Native SAP HANA data types DDL data types Name Description SQL Literal Syntax SQL Name String (n) Variable-length Unicode string with a specified maximum length of n=1-1333 characters (5000 for SAP HANA specific objects). Default = maximum length. String length (n) is mandatory. 'text with \u201cquote\u201d' VARCHAR LargeString Variable length string of up to 2 GB (no comparison) 'text with \u201cquote\u201d' NCLOB Binary(n) Variable length byte string with user-defined length limit of up to 4000 bytes. Binary length (n) is mandatory. x'01Cafe', X'01Cafe' VARBINARY LargeBinary Variable length byte string of up to 2 GB (no comparison) x'01Cafe', X'01Cafe' BLOB Integer Respective container's standard signed integer. Signed 32 bit integers in 2's complement, -2 31 .. 2 31-1. Default=NULL 13, -1234567 INTEGER Integer64 Signed 64-bit integer with a value range of -2^63 to 2^63-1. Default=NULL. 13, -1234567 BIGINT Decimal( p, s ) Decimal number with fixed precision (p) in range of 1 to 34 and fixed scale (s) in range of 0 to p. Values for precision and scale are mandatory. 12.345, -9.8767 DECIMAL( p, s ) DecimalFloat Decimal floating-point number (IEEE 754-2008) with 34 mantissa digits; range is roughly \u00b11e-6143 through \u00b19.99e+6144 12.345, -9.876 DECIMAL BinaryFloat Binary floating-point number (IEEE 754), 8 bytes (roughly 16 decimal digits precision); range is roughly \u00b12.2207e-308 through \u00b11.7977e+308 1.2, -3.4, 5.6e+7 DOUBLE LocalDate Local date with values ranging from 0001-01-01 through 9999-12-31 date'1234-12-31' DATE LocalTime Time values (with seconds precision) and values ranging from 00:00:00 through 24:00:00 time'23:59:59', time'12:15' TIME UTCDateTime UTC date and time (with seconds precision) and values ranging from 0001-01-01 00:00:00 through 9999-12-31 23:59:59 timestamp'2011-12-31 23:59:59' SECONDDATE UTCTimestamp UTC date and time (with a precision of 0.1 microseconds) and values ranging from 0001-01-01 00:00:00 through 9999-12-31 23:59:59.9999999, and a special initial value timestamp'2011-12-31 23:59:59.7654321' TIMESTAMP Boolean Represents the concept of binary-valued logic true, false BOOLEAN In CDS, the name of SAP HANA data types are prefixed with the word \u201chana\u201d, for example, hana.ALPHANUM, or hana.SMALLINT, or hana.TINYINT. Native SAP HANA data types Data Type Description SQL Name ALPHANUM Variable-length character string with special comparison. ALPHANUMERIC SMALLINT Signed 16-bit integer SMALLINT TINYINT Unsigned 8-bit integer TINYINT REAL 32-bit binary floating-point number REAL SMALLDECIMAL 64-bit decimal floating-point number SMALLDECIMAL VARCHAR Variable-length ASCII character string with user-definable length limit n VARCHAR CLOB Large variable-length ASCII character string, no comparison CLOB BINARY Byte string of fixed length n BINARY Reference SAP Help Portal For more information, see Core Data Services (.hdbcds) . Sample na mespace produc ts .db; @Schema : 'DBADMIN' co nte x t Produc ts { e nt i t y Orders { key Id : S tr i n g( 32 ); Cus t omerName : S tr i n g( 500 ); Cus t omerSur na me : S tr i n g( 500 ); S tatus : S tr i n g( 100 ); Crea te dA t : UTCTimes ta mp; Crea te dBy : S tr i n g( 5000 ); Descrip t io n : S tr i n g( 100 ); Address : S tr i n g( 5000 ); Pho ne : S tr i n g( 200 ); Email : S tr i n g( 300 ); Cou ntr y : associa t io n t o Produc ts .Cou ntr y { Id } ; i te ms : Associa t io n [ * ] t o I te m o n i te ms.OrderId = Id; } ; e nt i t y I te m { key I te mId : S tr i n g( 32 ); OrderId : S tr i n g( 32 ); Name : S tr i n g( 500 ); Type : S tr i n g( 100 ); Price : S tr i n g( 100 ); Curre n cy : S tr i n g( 100 ); Qua nt i t y : S tr i n g( 100 ); Comme nt : S tr i n g( 1000 ); } ; e nt i t y Cou ntr y { key Id : S tr i n g( 32 ); Name : S tr i n g( 32 ); } ; } ;","title":"hdbcds"},{"location":"artifacts/hdbdd/#hdbcds","text":"","title":"HDBCDS"},{"location":"artifacts/hdbdd/#overview","text":"The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the HDBCDS syntax, also known as HDBDD.","title":"Overview"},{"location":"artifacts/hdbdd/#cds-file","text":"CDS documents are design-time source files that contain DDL code that describes a persistence model according to rules defined in Core Data Services. CDS documents have the file suffix .hdbdd. Each CDS document must contain the following basic elements: namespace The name space you define must be the first declaration in the CDS document and match the absolute package path to the location of the CDS document in the repository. schema definition The schema you specify is used to store the catalog objects that are defined in the CDS document, for example: entities, structured types, and views. The objects are generated in the catalog when the CDS document is synchronized by the xsk runtime. CDS artifact definitions The objects that make up your persistence model, for example: contexts, entities and structured types Each CDS document must contain one top-level artifact, for example: a context, a type, an entity, or a view. The name of the top-level artifact in the CDS document must match the file name of the CDS document, without the suffix. For example, if the top-level artifact is a context named MyModel, the name of the CDS document must be MyModel.hdbdd.","title":"CDS file"},{"location":"artifacts/hdbdd/#cds-artifact","text":"","title":"CDS artifact"},{"location":"artifacts/hdbdd/#naming-conventions","text":"Rules and restrictions apply to the names of CDS documents and the package in which the CDS document resides. The rules that apply for naming CDS documents are the same as the rules for naming the packages in which the CDS document is located. When specifying the name of a package or a CDS document (or referencing the name of an existing CDS object, for example, within a CDS document), bear in mind the following rules: File suffix .hdbdd, for example, MyModel.hdbdd. Permitted characters CDS object and package names can include the following characters: Lower or upper case letters(aA-zZ), the underscore character(_) and dash(-) Digits(0-9) Forbidden characters You cannot use the dot (.) in the name of a CDS document. You cannot use a digit (0-9) as the first character of the name of either a CDS document or a package, for example, 2CDSobjectname.hdbdd (XS classic) or acme.com.1package.hdbcds (XS advanced). The CDS parser does not recognize either CDS document names or package names that consist exclusively of digits, for example, 1234.hdbdd (XS classic) or acme.com.999.hdbcds. Note: Although it is possible to use quotation marks (\"\") to wrap a name that includes forbidden characters, as a general rule, it is recommended to follow the naming conventions for CDS documents specified here in order to avoid problems during activation in the repository.","title":"Naming conventions"},{"location":"artifacts/hdbdd/#external-artifacts-in-cds","text":"You can define an artifact in one CDS document by referring to an artifact that is defined in another CDS document. The CDS syntax enables you to define a CDS artifact in one document by basing it on an \u201cexternal\u201d artifact - an artifact that is defined in a separate CDS document. Each external artifact must be explicitly declared in the source CDS document with the 'using' keyword, which specifies the location of the external artifact, its name, and where appropriate its CDS context. The using declarations must be located in the header of the CDS document between the namespace declaration and the beginning of the top-level artifact, for example, the context. The external artifact can be either a single object (for example, a type, an entity, or a view) or a context. You can also include an optional alias in the using declaration, for example, ContextA.ContextA1 as ic. The alias (ic) can then be used in subsequent type definitions in the source CDS document. na mespace Pack 1. Dis tr ibu te d; usi n g Pack 1. Dis tr ibu te d :: Co nte x t A.T 1 ; usi n g Pack 1. Dis tr ibu te d :: Co nte x t A.Co nte x t AI as ic; usi n g Pack 1. Dis tr ibu te d :: Co nte x t A.Co nte x t AI.T 3 as ic t 3 ; usi n g Pack 1. Dis tr ibu te d :: Co nte x t A.Co nte x t AI.T 3. a as a; // error , is n o t a n ar t i fa c t co nte x t Co nte x t B { t ype T 10 { a : T 1 ; // I nte ger b : ic.T 2 ; // S tr i n g( 20 ) c : ic.T 3 ; // s tru c ture d d : t ype o f ic.T 3. b; // S tr i n g( 88 ) e : ic t 3 ; // s tru c ture d x : Pack 1. Dis tr ibu te d :: Co nte x t A.T 1 ; // error , direc t re feren ce n o t allowed } ; co nte x t Co nte x t BI { t ype T 1 : S tr i n g( 7 ); // hides t he T 1 comi n g fr om t he f irs t usi n g declara t io n t ype T 2 : T 1 ; // S tr i n g( 7 ) } ; } ; The CDS document ContextB.hdbdd shown above uses external artifacts (data types T1 and T3) that are defined in the \u201ctarget\u201d CDS document ContextA.hdbdd shown below. Two using declarations are present in the CDS document ContextB.hdbdd; one with no alias and one with an explictly specified alias (ic). The first using declaration introduces the scalar type Pack1.Distributed::ContextA.T1. The second using declaration introduces the context Pack1.Distributed::ContextA.ContextAI and makes it accessible by means of the explicitly specified alias ic. If no explicit alias is specified, the last part of the fully qualified name is assumed as the alias, for example T1.","title":"External Artifacts in CDS"},{"location":"artifacts/hdbdd/#cds-primitive-data-types","text":"In the Data Definition Language (DDL), primitive (or core) data types are the basic building blocks that you use to define entities or structure types with DDL. When you are specifying a design-time table (entity) using the CDS syntax, you use data types such as String, Binary, or Integer to specify the type of content in the entity columns. Here are the supported types supports the use of the following primitive data types: - DDL data types - Native SAP HANA data types","title":"CDS Primitive Data Types"},{"location":"artifacts/hdbdd/#reference","text":"SAP Help Portal For more information, see Core Data Services (.hdbcds) .","title":"Reference"},{"location":"artifacts/hdbdd/#sample","text":"na mespace produc ts .db; @Schema : 'DBADMIN' co nte x t Produc ts { e nt i t y Orders { key Id : S tr i n g( 32 ); Cus t omerName : S tr i n g( 500 ); Cus t omerSur na me : S tr i n g( 500 ); S tatus : S tr i n g( 100 ); Crea te dA t : UTCTimes ta mp; Crea te dBy : S tr i n g( 5000 ); Descrip t io n : S tr i n g( 100 ); Address : S tr i n g( 5000 ); Pho ne : S tr i n g( 200 ); Email : S tr i n g( 300 ); Cou ntr y : associa t io n t o Produc ts .Cou ntr y { Id } ; i te ms : Associa t io n [ * ] t o I te m o n i te ms.OrderId = Id; } ; e nt i t y I te m { key I te mId : S tr i n g( 32 ); OrderId : S tr i n g( 32 ); Name : S tr i n g( 500 ); Type : S tr i n g( 100 ); Price : S tr i n g( 100 ); Curre n cy : S tr i n g( 100 ); Qua nt i t y : S tr i n g( 100 ); Comme nt : S tr i n g( 1000 ); } ; e nt i t y Cou ntr y { key Id : S tr i n g( 32 ); Name : S tr i n g( 32 ); } ; } ;","title":"Sample"},{"location":"artifacts/hdbprocedure/","text":"HDBProcedure Overview The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the HDBProcedure syntax. Reference SAP Help Portal For more information, see Procedures (.hdbprocedure) . Sample PROCEDURE \"MYSCHEMA\" . \"hdb_view::OrderProcedure\" () LANGUAGE SQLSCRIPT SQL SECURITY INVOKER --DEFAULT SCHEMA <default_schema_name> READS SQL DATA AS BEGIN /************************************* Write your procedure logic *************************************/ SELECT * FROM \"hdb_view::Item\" ; END Caution Reserved keywords , used as table or column names, must be escaped.","title":"hdbprocedure"},{"location":"artifacts/hdbprocedure/#hdbprocedure","text":"","title":"HDBProcedure"},{"location":"artifacts/hdbprocedure/#overview","text":"The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the HDBProcedure syntax.","title":"Overview"},{"location":"artifacts/hdbprocedure/#reference","text":"SAP Help Portal For more information, see Procedures (.hdbprocedure) .","title":"Reference"},{"location":"artifacts/hdbprocedure/#sample","text":"PROCEDURE \"MYSCHEMA\" . \"hdb_view::OrderProcedure\" () LANGUAGE SQLSCRIPT SQL SECURITY INVOKER --DEFAULT SCHEMA <default_schema_name> READS SQL DATA AS BEGIN /************************************* Write your procedure logic *************************************/ SELECT * FROM \"hdb_view::Item\" ; END Caution Reserved keywords , used as table or column names, must be escaped.","title":"Sample"},{"location":"artifacts/hdbschema/","text":"HDBSchema Overview The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the HDBSchema syntax. Reference SAP Help Portal For more information, see Create a Schema . Sample schema_name = \"MYSCHEMA\" ;","title":"hdbschema"},{"location":"artifacts/hdbschema/#hdbschema","text":"","title":"HDBSchema"},{"location":"artifacts/hdbschema/#overview","text":"The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the HDBSchema syntax.","title":"Overview"},{"location":"artifacts/hdbschema/#reference","text":"SAP Help Portal For more information, see Create a Schema .","title":"Reference"},{"location":"artifacts/hdbschema/#sample","text":"schema_name = \"MYSCHEMA\" ;","title":"Sample"},{"location":"artifacts/hdbsequence/","text":"HDBSequence Overview The information on this page will help you lesrn how to develop the design-time data-persistence model for an XSK application using the HDBSequence syntax. Reference SAP Help Portal SAP HANA XS Classic: For more information, see Create a Sequence . SAP HANA XS Advanced: For more information, see CREATE SEQUENCE Statement (Data Definition) . Sample HANA XS Classic syntax HANA XS Advanced syntax schema= \"TEST_DUMMY\" ; s tart _wi t h= 10 ; maxvalue= 30 ; n omaxvalue= false ; mi n value= 1 ; n omi n value= true ; cycles= false ; rese t _by= \"SELECT T1.\\\"Column2\\\" FROM \\\"MYSCHEMA\\\".\\\"com.acme.test.tables::MY_TABLE1\\\" AS T1 LEFT JOIN \\\"MYSCHEMA\\\".\\\"com.acme.test.tables::MY_TABLE2\\\" AS T2 ON T1.\\\"Column1\\\" = T2.\\\"Column1\\\"\" ; depe n ds_o n = [ \"com.acme.test.tables::MY_TABLE1\" , \"com.acme.test.tables::MY_TABLE2\" ] ; SEQUENCE \"com.sap.hana.example::CUSTOMER_ID\" RESET BY SELECT IFNULL ( MAX ( ID ), 0 ) + 1 FROM \"com.sap.hana.example::CUSTOMERS\" Configuration Schema Name Description Type Default value Required schema Name of the schema that contains the sequence you are defining. String None Yes increment_by Specifies that the sequence increments by a defined value. Integer 1 No start_with Specifies that the sequence starts with a specific value. Cannot be less than the minimum value. Integer 1 No maxvalue Specifies that the sequence stops at a specific maximum value. Integer Different for each DB No nomaxvalue Specifies that the sequence does not stop at any specific maximum value. Boolean False No minvalue Specifies that the sequence stops at a specific minimum value. Integer 1 No nominvalue Specifies that the sequence does not stop at any specific minimum value. Boolean False No cycles Enables you to specify whether the sequence number will be restarted after it reaches its maximum or minimum value. Boolean None No reset_by Enables you to reset the sequence using a query on any view, table or even table function. However, any dependency must be declared explicitly, for example, with the depends_on_view or depends_on_table keyword. If the table or view specified in the dependency does not exist, the activation of the sequence object in the repository fails. String None No public Specifies if it is public or not. Boolean False No depends_on_table Enables you to define a dependency to one or more specific tables. List(String) None No depends_on_view Enables you to define a dependency to one or more specific views. List(String) None No depends_on Enables you to define a dependency to one or more specific tables or views, for example, when using the reset_by option to specify the query to use when resetting the sequence. List(String) None No Caution Reserved keywords , used as table or column names in queries, must be escaped.","title":"hdbsequence"},{"location":"artifacts/hdbsequence/#hdbsequence","text":"","title":"HDBSequence"},{"location":"artifacts/hdbsequence/#overview","text":"The information on this page will help you lesrn how to develop the design-time data-persistence model for an XSK application using the HDBSequence syntax.","title":"Overview"},{"location":"artifacts/hdbsequence/#reference","text":"SAP Help Portal SAP HANA XS Classic: For more information, see Create a Sequence . SAP HANA XS Advanced: For more information, see CREATE SEQUENCE Statement (Data Definition) .","title":"Reference"},{"location":"artifacts/hdbsequence/#sample","text":"HANA XS Classic syntax HANA XS Advanced syntax schema= \"TEST_DUMMY\" ; s tart _wi t h= 10 ; maxvalue= 30 ; n omaxvalue= false ; mi n value= 1 ; n omi n value= true ; cycles= false ; rese t _by= \"SELECT T1.\\\"Column2\\\" FROM \\\"MYSCHEMA\\\".\\\"com.acme.test.tables::MY_TABLE1\\\" AS T1 LEFT JOIN \\\"MYSCHEMA\\\".\\\"com.acme.test.tables::MY_TABLE2\\\" AS T2 ON T1.\\\"Column1\\\" = T2.\\\"Column1\\\"\" ; depe n ds_o n = [ \"com.acme.test.tables::MY_TABLE1\" , \"com.acme.test.tables::MY_TABLE2\" ] ; SEQUENCE \"com.sap.hana.example::CUSTOMER_ID\" RESET BY SELECT IFNULL ( MAX ( ID ), 0 ) + 1 FROM \"com.sap.hana.example::CUSTOMERS\" Configuration Schema Name Description Type Default value Required schema Name of the schema that contains the sequence you are defining. String None Yes increment_by Specifies that the sequence increments by a defined value. Integer 1 No start_with Specifies that the sequence starts with a specific value. Cannot be less than the minimum value. Integer 1 No maxvalue Specifies that the sequence stops at a specific maximum value. Integer Different for each DB No nomaxvalue Specifies that the sequence does not stop at any specific maximum value. Boolean False No minvalue Specifies that the sequence stops at a specific minimum value. Integer 1 No nominvalue Specifies that the sequence does not stop at any specific minimum value. Boolean False No cycles Enables you to specify whether the sequence number will be restarted after it reaches its maximum or minimum value. Boolean None No reset_by Enables you to reset the sequence using a query on any view, table or even table function. However, any dependency must be declared explicitly, for example, with the depends_on_view or depends_on_table keyword. If the table or view specified in the dependency does not exist, the activation of the sequence object in the repository fails. String None No public Specifies if it is public or not. Boolean False No depends_on_table Enables you to define a dependency to one or more specific tables. List(String) None No depends_on_view Enables you to define a dependency to one or more specific views. List(String) None No depends_on Enables you to define a dependency to one or more specific tables or views, for example, when using the reset_by option to specify the query to use when resetting the sequence. List(String) None No Caution Reserved keywords , used as table or column names in queries, must be escaped.","title":"Sample"},{"location":"artifacts/hdbsynonym/","text":"HDBSynonym Overview The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the HDBSynonym syntax. Reference SAP Help Portal For more information, see Create a Synonym . Sample { \"acme.com.app1::MySynonym1\" : { \"target\" : { \"schema\" : \"DEFAULT_SCHEMA\" , \"object\" : \"MY_ERP_TABLE_1\" }, \"schema\" : \"SCHEMA_2\" } } Which syntax does the parser support? HANA XS Classic syntax HANA XS Advanced syntax Comments \" :: \" location \"target\" : targetSchema \"target\" : targetObject \"schema\" synonymSchema","title":"hdbsynonym"},{"location":"artifacts/hdbsynonym/#hdbsynonym","text":"","title":"HDBSynonym"},{"location":"artifacts/hdbsynonym/#overview","text":"The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the HDBSynonym syntax.","title":"Overview"},{"location":"artifacts/hdbsynonym/#reference","text":"SAP Help Portal For more information, see Create a Synonym .","title":"Reference"},{"location":"artifacts/hdbsynonym/#sample","text":"{ \"acme.com.app1::MySynonym1\" : { \"target\" : { \"schema\" : \"DEFAULT_SCHEMA\" , \"object\" : \"MY_ERP_TABLE_1\" }, \"schema\" : \"SCHEMA_2\" } } Which syntax does the parser support? HANA XS Classic syntax HANA XS Advanced syntax Comments \" :: \" location \"target\" : targetSchema \"target\" : targetObject \"schema\" synonymSchema","title":"Sample"},{"location":"artifacts/hdbtable/","text":"HDBTable Overview The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the HDBTable syntax. Details About the Parser Caution The parser does not allow duplicate properties. The order of the table's, column's and index's properties is not taken into account when the table definition is parsed. An exception will be thrown if a property is defined more than once in the *.hdbtable file. An additional exception will be thrown if a mandatory field is missing. Reference SAP Help Portal For more information, see Create a Table . Sample HANA XS Classic syntax HANA XS Advanced syntax ta ble.schemaName = \"MYSCHEMA\" ; ta ble. ta bleType = COLUMNSTORE; ta ble.colum ns = [ { na me = \"Col1\" ; sqlType = VARCHAR; nulla ble = false ; le n g t h = 20 ; comme nt = \"dummy comment\" ; }, { na me = \"Col2\" ; sqlType = INTEGER; nulla ble = false ; }, { na me = \"Col3\" ; sqlType = NVARCHAR; nulla ble = true ; le n g t h = 20 ; de fault Value = \"Defaultvalue\" ; }, { na me = \"Col4\" ; sqlType = DECIMAL; nulla ble = false ; precisio n = 2 ; scale = 3 ; } ] ; ta ble.i n dexes = [ { na me = \"MYINDEX1\" ; u n ique = true ; i n dexColum ns = [ \"Col2\" ] ; }, { na me = \"MYINDEX2\" ; u n ique = true ; i n dexColum ns = [ \"Col1\" , \"Col4\" ] ; } ] ; ta ble.primaryKey.pkcolum ns = [ \"Col1\" , \"Col2\" ] ; COLUMN TABLE \"MYSCHEMA::MYTABLE\" ( \"ID\" INTEGER DEFAULT 555 , \"NAME\" NVARCHAR ( 256 ), \"ACTIVE\" TINYINT , \"COUNTRY\" NVARCHAR ( 256 ), PRIMARY KEY ( \"ID\" ) )","title":"hdbtable"},{"location":"artifacts/hdbtable/#hdbtable","text":"","title":"HDBTable"},{"location":"artifacts/hdbtable/#overview","text":"The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the HDBTable syntax.","title":"Overview"},{"location":"artifacts/hdbtable/#details-about-the-parser","text":"Caution The parser does not allow duplicate properties. The order of the table's, column's and index's properties is not taken into account when the table definition is parsed. An exception will be thrown if a property is defined more than once in the *.hdbtable file. An additional exception will be thrown if a mandatory field is missing.","title":"Details About the Parser"},{"location":"artifacts/hdbtable/#reference","text":"SAP Help Portal For more information, see Create a Table .","title":"Reference"},{"location":"artifacts/hdbtable/#sample","text":"HANA XS Classic syntax HANA XS Advanced syntax ta ble.schemaName = \"MYSCHEMA\" ; ta ble. ta bleType = COLUMNSTORE; ta ble.colum ns = [ { na me = \"Col1\" ; sqlType = VARCHAR; nulla ble = false ; le n g t h = 20 ; comme nt = \"dummy comment\" ; }, { na me = \"Col2\" ; sqlType = INTEGER; nulla ble = false ; }, { na me = \"Col3\" ; sqlType = NVARCHAR; nulla ble = true ; le n g t h = 20 ; de fault Value = \"Defaultvalue\" ; }, { na me = \"Col4\" ; sqlType = DECIMAL; nulla ble = false ; precisio n = 2 ; scale = 3 ; } ] ; ta ble.i n dexes = [ { na me = \"MYINDEX1\" ; u n ique = true ; i n dexColum ns = [ \"Col2\" ] ; }, { na me = \"MYINDEX2\" ; u n ique = true ; i n dexColum ns = [ \"Col1\" , \"Col4\" ] ; } ] ; ta ble.primaryKey.pkcolum ns = [ \"Col1\" , \"Col2\" ] ; COLUMN TABLE \"MYSCHEMA::MYTABLE\" ( \"ID\" INTEGER DEFAULT 555 , \"NAME\" NVARCHAR ( 256 ), \"ACTIVE\" TINYINT , \"COUNTRY\" NVARCHAR ( 256 ), PRIMARY KEY ( \"ID\" ) )","title":"Sample"},{"location":"artifacts/hdbtablefunction/","text":"HDBTableFunction Overview The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the HDBTableFunction syntax. Reference SAP Help Portal For more information, see Create a Table User-Defined Function Sample FUNCTION \"MYSCHEMA\" . \"hdb_view::OrderTableFunction\" () RETURNS TABLE ( \"Id\" NVARCHAR ( 32 ), \"CustomerName\" NVARCHAR ( 500 ) ) LANGUAGE SQLSCRIPT SQL SECURITY INVOKER AS BEGIN RETURN SELECT \"Id\" , \"CustomerName\" FROM \"hdb_view::Item\" ; END ; Caution Reserved keywords , used as table or column names, must be escaped.","title":"hdbtablefunction"},{"location":"artifacts/hdbtablefunction/#hdbtablefunction","text":"","title":"HDBTableFunction"},{"location":"artifacts/hdbtablefunction/#overview","text":"The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the HDBTableFunction syntax.","title":"Overview"},{"location":"artifacts/hdbtablefunction/#reference","text":"SAP Help Portal For more information, see Create a Table User-Defined Function","title":"Reference"},{"location":"artifacts/hdbtablefunction/#sample","text":"FUNCTION \"MYSCHEMA\" . \"hdb_view::OrderTableFunction\" () RETURNS TABLE ( \"Id\" NVARCHAR ( 32 ), \"CustomerName\" NVARCHAR ( 500 ) ) LANGUAGE SQLSCRIPT SQL SECURITY INVOKER AS BEGIN RETURN SELECT \"Id\" , \"CustomerName\" FROM \"hdb_view::Item\" ; END ; Caution Reserved keywords , used as table or column names, must be escaped.","title":"Sample"},{"location":"artifacts/hdbview/","text":"HDBView Overview The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the HDBView syntax. Details About the Parser Caution There are currently some issues in the behavior of the HANA version 1.x of the parser: Currently, the parser takes into accou\u0446nt if a given property is mandatory. If the property order is misplaced, the parser will still parse the values. If more than one value of one property is provided, then only the last one is taken. Reference SAP Help Portal For more information, see Create an SQL View . Sample Caution Reserved keywords , used as table or column names in queries, must be escaped. HANA XS Classic syntax HANA XS Advanced syntax schema = \"MYSCHEMA\" ; query = \"SELECT T1.\\\" Column2 \\ \" FROM \\\" MYSCHEMA \\ \".\\\" acme . com . test . views :: MY_VIEW1 \\ \" AS T1 LEFT JOIN \\\" MYSCHEMA \\ \".\\\" acme . com . test . views :: MY_VIEW2 \\ \" AS T2 ON T1.\\\" Column1 \\ \" = T2.\\\" Column1 \\ \"\" ; depends_on = [ \"acme.com.test.views::MY_VIEW1\" , \"acme.com.test.views::MY_VIEW2\" ]; VIEW \"hdb_view.db::ItemsByOrderHANAv2\" AS SELECT \"Id\" FROM \"hdb_view::Item\" ; Which syntax does the parser support? HANA XS Classic syntax HANA XS Advanced syntax Comments schema schema query query public public default=true depends_on depends_on depends_on_table depends_on_table depends_on_view depends_on_view Caution Reserved keywords , used as table or column names in queries, must be escaped.","title":"hdbview"},{"location":"artifacts/hdbview/#hdbview","text":"","title":"HDBView"},{"location":"artifacts/hdbview/#overview","text":"The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the HDBView syntax.","title":"Overview"},{"location":"artifacts/hdbview/#details-about-the-parser","text":"Caution There are currently some issues in the behavior of the HANA version 1.x of the parser: Currently, the parser takes into accou\u0446nt if a given property is mandatory. If the property order is misplaced, the parser will still parse the values. If more than one value of one property is provided, then only the last one is taken.","title":"Details About the Parser"},{"location":"artifacts/hdbview/#reference","text":"SAP Help Portal For more information, see Create an SQL View .","title":"Reference"},{"location":"artifacts/hdbview/#sample","text":"Caution Reserved keywords , used as table or column names in queries, must be escaped. HANA XS Classic syntax HANA XS Advanced syntax schema = \"MYSCHEMA\" ; query = \"SELECT T1.\\\" Column2 \\ \" FROM \\\" MYSCHEMA \\ \".\\\" acme . com . test . views :: MY_VIEW1 \\ \" AS T1 LEFT JOIN \\\" MYSCHEMA \\ \".\\\" acme . com . test . views :: MY_VIEW2 \\ \" AS T2 ON T1.\\\" Column1 \\ \" = T2.\\\" Column1 \\ \"\" ; depends_on = [ \"acme.com.test.views::MY_VIEW1\" , \"acme.com.test.views::MY_VIEW2\" ]; VIEW \"hdb_view.db::ItemsByOrderHANAv2\" AS SELECT \"Id\" FROM \"hdb_view::Item\" ; Which syntax does the parser support? HANA XS Classic syntax HANA XS Advanced syntax Comments schema schema query query public public default=true depends_on depends_on depends_on_table depends_on_table depends_on_view depends_on_view Caution Reserved keywords , used as table or column names in queries, must be escaped.","title":"Sample"},{"location":"artifacts/xshttpdest/","text":"XSHTTPDest Overview In SAP HANA XS Classic the concept of destinations is represented with a declarative definition in an .xshttpdest file and optional OAuth configurations. Administrative tasks are available in the XS Admin UI and require special privileges. XSK leverages the SAP BTP Destination service with which these configurations are externalized from the application, thus separating their lifecycle. Transition path Below are all artifacts from XS Classic related to destination configuration and how to move them to SAP BTP Destination service. xshttpdest Warning Artifact not supported. Destinations can be created in the SAP BTP Destination service . SAP HANA XS Classic SAP BTP Destination service host set explicitly as part of URL port set explicitly as part of URL useSSL set protocol explicitly as part of URL description availabe sslAuth available when using client certificate authentication sslHostCheck available as TrustAll pathPrefix set explicitly as part of URL authType changed to Authentication - see options samlProvider not available samlACS not available samlAttributes not available samlNameId availabe as nameIdFormat when using SAML Assertion or OAuth SAML Bearer Assertion proxyType use Internet when connecting to services on the Internet and OnPremise when accessing systems through Cloud Connector proxyHost not needed proxyPort not needed timeout not available - configured explicitly on client level remoteSID available as RecipientSID using SAP Assertion SSO Authentication remoteClient available as RecipientClient using SAP Assertion SSO Authentication oAuthAppConfig mandatoryScopes can be set when using any of the OAuth flows - ie see OAuth Client Credentials Authentication xsoauthappconfig Documentation in SAP Help Portal Warning Artifact not supported. Scopes can still be defined - use any of the OAuth flows and set the scope property in order to achieve the same as with mandatoryScopes ie see OAuth Client Credentials Authentication SAP HANA XS Classic SAP BTP Destination service description description can be set on destination level clientConfig not available - configuration specific for each destination mandatoryScopes if scope list is set on destination level they will be mandatory optionalScopes not available - if scope list is set on destination level they will be mandatory modifies not available xsoauthclientconfig Documentation in SAP Help Portal Warning Artifact not supported. Some of the properties are available as explicit configuration in the SAP BTP Destination service. SAP HANA XS Classic SAP BTP Destination service clientFlavor see xsoauthclientflavor on how to configure properties for each destination clientID set per destination when using any of the OAuth flows clientAuthType use tokenServiceUser and tokenServicePassword for basic . See OAuth with X.509 Client Certificates for cert authorizationEndpointURL not available tokenEndpointURL available as tokenServiceURL when using any of the OAuth flows revocationEndpointURL not available flow saml2Bearer - see other types here description available on destination level samlIssuer available as assertionIssuer when using SAML Assertion redirectURL not available - handle authCode flow in code scopeReq not available shared not available modifies not available xsoauthclientflavor Documentation in SAP Help Portal Warning Artifact not supported. Headers and query parameters can be defined as described in the SAP BTP Destination service documentation Reference SAP Help Portal For more information, see Destination Administration . Usage To use destinations in your project, an instance of Destination service must be created and bound to the XSK environment - see Using Services in the Kyma Environment After an instance of SAP BTP Destination service is bound to XSK, all destinations will be read from it when using $.net.http.readDestination Importing destinations Destinations can be imported directly in SAP BTP Destination service, but as the fields are different, some preprocessing is needed HANA XS Classic syntax SAP BTP Destination Service description = \"My Destination\"; host = \"example.com\"; port = 443; proxyType = none; proxyHost = \"proxy\"; proxyPort = 8080; authType = basic; useSSL = true; timeout = 30000; sslHostCheck = false; sslAuth = anonymous; Description = My Destination Name = My Destination Type = HTTP URL = https://example.com:443 ProxyType = Internet Authentication = BasicAuthentication","title":"xshttpdest"},{"location":"artifacts/xshttpdest/#xshttpdest","text":"","title":"XSHTTPDest"},{"location":"artifacts/xshttpdest/#overview","text":"In SAP HANA XS Classic the concept of destinations is represented with a declarative definition in an .xshttpdest file and optional OAuth configurations. Administrative tasks are available in the XS Admin UI and require special privileges. XSK leverages the SAP BTP Destination service with which these configurations are externalized from the application, thus separating their lifecycle.","title":"Overview"},{"location":"artifacts/xshttpdest/#transition-path","text":"Below are all artifacts from XS Classic related to destination configuration and how to move them to SAP BTP Destination service.","title":"Transition path"},{"location":"artifacts/xshttpdest/#xshttpdest_1","text":"Warning Artifact not supported. Destinations can be created in the SAP BTP Destination service . SAP HANA XS Classic SAP BTP Destination service host set explicitly as part of URL port set explicitly as part of URL useSSL set protocol explicitly as part of URL description availabe sslAuth available when using client certificate authentication sslHostCheck available as TrustAll pathPrefix set explicitly as part of URL authType changed to Authentication - see options samlProvider not available samlACS not available samlAttributes not available samlNameId availabe as nameIdFormat when using SAML Assertion or OAuth SAML Bearer Assertion proxyType use Internet when connecting to services on the Internet and OnPremise when accessing systems through Cloud Connector proxyHost not needed proxyPort not needed timeout not available - configured explicitly on client level remoteSID available as RecipientSID using SAP Assertion SSO Authentication remoteClient available as RecipientClient using SAP Assertion SSO Authentication oAuthAppConfig mandatoryScopes can be set when using any of the OAuth flows - ie see OAuth Client Credentials Authentication","title":"xshttpdest"},{"location":"artifacts/xshttpdest/#xsoauthappconfig","text":"Documentation in SAP Help Portal Warning Artifact not supported. Scopes can still be defined - use any of the OAuth flows and set the scope property in order to achieve the same as with mandatoryScopes ie see OAuth Client Credentials Authentication SAP HANA XS Classic SAP BTP Destination service description description can be set on destination level clientConfig not available - configuration specific for each destination mandatoryScopes if scope list is set on destination level they will be mandatory optionalScopes not available - if scope list is set on destination level they will be mandatory modifies not available","title":"xsoauthappconfig"},{"location":"artifacts/xshttpdest/#xsoauthclientconfig","text":"Documentation in SAP Help Portal Warning Artifact not supported. Some of the properties are available as explicit configuration in the SAP BTP Destination service. SAP HANA XS Classic SAP BTP Destination service clientFlavor see xsoauthclientflavor on how to configure properties for each destination clientID set per destination when using any of the OAuth flows clientAuthType use tokenServiceUser and tokenServicePassword for basic . See OAuth with X.509 Client Certificates for cert authorizationEndpointURL not available tokenEndpointURL available as tokenServiceURL when using any of the OAuth flows revocationEndpointURL not available flow saml2Bearer - see other types here description available on destination level samlIssuer available as assertionIssuer when using SAML Assertion redirectURL not available - handle authCode flow in code scopeReq not available shared not available modifies not available","title":"xsoauthclientconfig"},{"location":"artifacts/xshttpdest/#xsoauthclientflavor","text":"Documentation in SAP Help Portal Warning Artifact not supported. Headers and query parameters can be defined as described in the SAP BTP Destination service documentation","title":"xsoauthclientflavor"},{"location":"artifacts/xshttpdest/#reference","text":"SAP Help Portal For more information, see Destination Administration .","title":"Reference"},{"location":"artifacts/xshttpdest/#usage","text":"To use destinations in your project, an instance of Destination service must be created and bound to the XSK environment - see Using Services in the Kyma Environment After an instance of SAP BTP Destination service is bound to XSK, all destinations will be read from it when using $.net.http.readDestination","title":"Usage"},{"location":"artifacts/xshttpdest/#importing-destinations","text":"Destinations can be imported directly in SAP BTP Destination service, but as the fields are different, some preprocessing is needed HANA XS Classic syntax SAP BTP Destination Service description = \"My Destination\"; host = \"example.com\"; port = 443; proxyType = none; proxyHost = \"proxy\"; proxyPort = 8080; authType = basic; useSSL = true; timeout = 30000; sslHostCheck = false; sslAuth = anonymous; Description = My Destination Name = My Destination Type = HTTP URL = https://example.com:443 ProxyType = Internet Authentication = BasicAuthentication","title":"Importing destinations"},{"location":"artifacts/xsjs/","text":"XS Javascript (XSJS) Overview SAP HANA XS Javascript (XSJS) is a programming language that can be used by application developers to create server-side business logic as *.xsjs files. You can import libraries in XSJS services as separate files with the *.xsjslib extension. Reference SAP Help Portal For more information, see Getting Started with XS JavaScript . Sample Sample XSJS service ( *.xsjs ) Sample XSJS library ( *.xsjslib ) var ProductsService = $ . import ( \"products.xsjs\" , \"ProductsLib\" ). Products ; var connection = $ . hdb . getConnection ({ treatDateAsUTC : true }); function error ( msg , statusCode ) { $ . response . status = statusCode ; $ . response . contentType = \"text/plain\" ; $ . response . setBody ( msg ); } /** * respond with a result with content type 'application/json' with the status code 'OK' (200) and specified message */ function positiveResult ( oResponse ) { $ . response . status = $ . net . http . OK ; $ . response . contentType = \"application/json\" ; var sResponse = JSON . stringify ( oResponse ); $ . response . setBody ( sResponse ); } /** * Handle the post-request. * * See above for the expected format of a request-entity */ function doPost () { var request = JSON . parse ( $ . request . body . asString ()); var productsService = new ProductsService ( connection , \"DBADMIN\" ); var response = productsService . handlePostRequest ( request ); connection . close (); positiveResult ( response ); } function doGet () { var response ; var productsService = new ProductsService ( connection , \"DBADMIN\" ); response = productsService . handleGetRequest (); connection . close (); positiveResult ( response ); } ( function doService () { var method = $ . request . method ; if ( method === $ . net . http . GET ) { doGet (); } else if ( method === $ . net . http . POST ) { doPost (); } else { $ . response . status = $ . net . http . BAD_REQUEST ; } }()); var hdbConnection = $ . hdb . getConnection ({ treatDateAsUTC : true }); var schema = \"DBADMIN\" ; var PRODUCTS_TABLE = \"products.db::Products.Orders\" ; var ITEMS_TABLE = \"products.db::Products.Item\" ; function Products ( connection , schema ) { connection = connection || $ . hdb . getConnection ({ treatDateAsUTC : true }); schema = schema || \"DBADMIN\" ; /** Create a new UUID */ function createUUID () { return $ . util . createUuid (); } this . handlePostRequest = function ( oData ) { try { connection . setAutoCommit ( 0 ); var OrderId = createUUID (); var oRs = connection . executeUpdate ( 'INSERT INTO \"' + schema + '\".\"' + PRODUCTS_TABLE + '\" (\"Id\", \"CustomerName\", \"CustomerSurname\", \"Status\", \"CreatedAt\", \"CreatedBy\", \"Description\", \"Address\", \"Phone\", \"Email\") values (?,?,?,?, CURRENT_UTCTIMESTAMP, SESSION_CONTEXT(\\'APPLICATIONUSER\\'), ?, ?, ?, ?)' , OrderId , oData . CustomerName , oData . CustomerSurname , oData . Status , oData . Description , oData . Address , oData . Phone , oData . Email ); connection . commit (); return oRs ; } catch ( e ) { connection . rollback (); } }; this . handleGetRequest = function () { try { var res = connection . executeQuery ( 'select * from \"' + schema + '\".\"' + PRODUCTS_TABLE + '\"' ); connection . commit (); return res ; } catch ( e ) { connection . rollback (); } }; } function deleteOrder ( paramObject ) { try { var oConnection = paramObject . connection ; var sQuery = 'delete from \"DBADMIN\".\"products.db::Products.Orders\" where \"Id\" = (select \"Id\" from \"' + paramObject . beforeTableName + '\")' ; var pstmt = oConnection . prepareStatement ( sQuery ); pstmt . executeUpdate (); pstmt . close (); } catch ( e ) { oConnection . rollback (); } }","title":"xsjslib"},{"location":"artifacts/xsjs/#xs-javascript-xsjs","text":"","title":"XS Javascript (XSJS)"},{"location":"artifacts/xsjs/#overview","text":"SAP HANA XS Javascript (XSJS) is a programming language that can be used by application developers to create server-side business logic as *.xsjs files. You can import libraries in XSJS services as separate files with the *.xsjslib extension.","title":"Overview"},{"location":"artifacts/xsjs/#reference","text":"SAP Help Portal For more information, see Getting Started with XS JavaScript .","title":"Reference"},{"location":"artifacts/xsjs/#sample","text":"Sample XSJS service ( *.xsjs ) Sample XSJS library ( *.xsjslib ) var ProductsService = $ . import ( \"products.xsjs\" , \"ProductsLib\" ). Products ; var connection = $ . hdb . getConnection ({ treatDateAsUTC : true }); function error ( msg , statusCode ) { $ . response . status = statusCode ; $ . response . contentType = \"text/plain\" ; $ . response . setBody ( msg ); } /** * respond with a result with content type 'application/json' with the status code 'OK' (200) and specified message */ function positiveResult ( oResponse ) { $ . response . status = $ . net . http . OK ; $ . response . contentType = \"application/json\" ; var sResponse = JSON . stringify ( oResponse ); $ . response . setBody ( sResponse ); } /** * Handle the post-request. * * See above for the expected format of a request-entity */ function doPost () { var request = JSON . parse ( $ . request . body . asString ()); var productsService = new ProductsService ( connection , \"DBADMIN\" ); var response = productsService . handlePostRequest ( request ); connection . close (); positiveResult ( response ); } function doGet () { var response ; var productsService = new ProductsService ( connection , \"DBADMIN\" ); response = productsService . handleGetRequest (); connection . close (); positiveResult ( response ); } ( function doService () { var method = $ . request . method ; if ( method === $ . net . http . GET ) { doGet (); } else if ( method === $ . net . http . POST ) { doPost (); } else { $ . response . status = $ . net . http . BAD_REQUEST ; } }()); var hdbConnection = $ . hdb . getConnection ({ treatDateAsUTC : true }); var schema = \"DBADMIN\" ; var PRODUCTS_TABLE = \"products.db::Products.Orders\" ; var ITEMS_TABLE = \"products.db::Products.Item\" ; function Products ( connection , schema ) { connection = connection || $ . hdb . getConnection ({ treatDateAsUTC : true }); schema = schema || \"DBADMIN\" ; /** Create a new UUID */ function createUUID () { return $ . util . createUuid (); } this . handlePostRequest = function ( oData ) { try { connection . setAutoCommit ( 0 ); var OrderId = createUUID (); var oRs = connection . executeUpdate ( 'INSERT INTO \"' + schema + '\".\"' + PRODUCTS_TABLE + '\" (\"Id\", \"CustomerName\", \"CustomerSurname\", \"Status\", \"CreatedAt\", \"CreatedBy\", \"Description\", \"Address\", \"Phone\", \"Email\") values (?,?,?,?, CURRENT_UTCTIMESTAMP, SESSION_CONTEXT(\\'APPLICATIONUSER\\'), ?, ?, ?, ?)' , OrderId , oData . CustomerName , oData . CustomerSurname , oData . Status , oData . Description , oData . Address , oData . Phone , oData . Email ); connection . commit (); return oRs ; } catch ( e ) { connection . rollback (); } }; this . handleGetRequest = function () { try { var res = connection . executeQuery ( 'select * from \"' + schema + '\".\"' + PRODUCTS_TABLE + '\"' ); connection . commit (); return res ; } catch ( e ) { connection . rollback (); } }; } function deleteOrder ( paramObject ) { try { var oConnection = paramObject . connection ; var sQuery = 'delete from \"DBADMIN\".\"products.db::Products.Orders\" where \"Id\" = (select \"Id\" from \"' + paramObject . beforeTableName + '\")' ; var pstmt = oConnection . prepareStatement ( sQuery ); pstmt . executeUpdate (); pstmt . close (); } catch ( e ) { oConnection . rollback (); } }","title":"Sample"},{"location":"artifacts/xsodata/","text":"XSOData Overview The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the XSODATA syntax. Reference SAP Help Portal Tutorial: Use the SAP HANA OData Interface OData Service-Definition Examples (XS Advanced) Sample service namespace \"products.odata\" { \"products.db::Products.Orders\" as \"Orders\" navigates ( \"Items4Orders\" as \"Items\" ) create events ( before \"products.xsjs:ProductsLib.xsjslib::beforeCreateOrder\" ) delete using \"products.xsjs:ProductsLib.xsjslib::deleteOrder\" ; \"products.db::Products.Item\" as \"Items\" create events ( before \"products.xsjs:ProductsLib.xsjslib::beforeCreateItem\" ) update forbidden ; association \"Items4Orders\" principal \"Orders\" ( \"Id\" ) multiplicity \"1\" dependent \"Items\" ( \"OrderId\" ) multiplicity \"*\" ; } annotations { enable OData4SAP ; } More Details Inside an *.xsodata file we can specify which properties can be exposed using the 'with' and 'without' section: service namespace \"np\" { \"sample.odata::table1\" as \"Table1\" without ( \"COLUMN1\" ); \"sample.odata::table2\" as \"Table2\" with ( \"COLUMN1\" , \"COLUMN2\" ); } XSK XSODATA Annotations Support SAP ODATA Annotations for XSOData XS2 SAP Annotations for OData Version 2.0 Annotation Element Annotation Supportability Element edm:Schema Element edm:EntityContainer Element edm:EntitySet Element edm:EntityType Element edm:Property Element edm:NavigationProperty Element edm:FunctionImport Element sap:value-constraint Element edm:Parameter Element edm:AssociationSet If you want to check the whole list of annotations, visit the official SAP OData Annotations v2.X documentation. Supportable OData Service-Definition Features FEATURES SUPPORTED IN XSK REMARKS Aggregation Association DONE Key Specification DONE Parameter Entity Sets Projection DONE HANA TableType Supported type for OData CALC VIEW GLOBAL TEMPORARARY SHARED TEMPORARARY NO LOGGING TEMPORARY SYNONYM SYSTEM TABLE TABLE USER DEFINED COLUMN VIEW VIEW JOIN VIEW OLAP VIEW HIERARCHY VIEW","title":"xsodata"},{"location":"artifacts/xsodata/#xsodata","text":"","title":"XSOData"},{"location":"artifacts/xsodata/#overview","text":"The information on this page will help you learn how to develop the design-time data-persistence model for an XSK application using the XSODATA syntax.","title":"Overview"},{"location":"artifacts/xsodata/#reference","text":"SAP Help Portal Tutorial: Use the SAP HANA OData Interface OData Service-Definition Examples (XS Advanced)","title":"Reference"},{"location":"artifacts/xsodata/#sample","text":"service namespace \"products.odata\" { \"products.db::Products.Orders\" as \"Orders\" navigates ( \"Items4Orders\" as \"Items\" ) create events ( before \"products.xsjs:ProductsLib.xsjslib::beforeCreateOrder\" ) delete using \"products.xsjs:ProductsLib.xsjslib::deleteOrder\" ; \"products.db::Products.Item\" as \"Items\" create events ( before \"products.xsjs:ProductsLib.xsjslib::beforeCreateItem\" ) update forbidden ; association \"Items4Orders\" principal \"Orders\" ( \"Id\" ) multiplicity \"1\" dependent \"Items\" ( \"OrderId\" ) multiplicity \"*\" ; } annotations { enable OData4SAP ; } More Details Inside an *.xsodata file we can specify which properties can be exposed using the 'with' and 'without' section: service namespace \"np\" { \"sample.odata::table1\" as \"Table1\" without ( \"COLUMN1\" ); \"sample.odata::table2\" as \"Table2\" with ( \"COLUMN1\" , \"COLUMN2\" ); }","title":"Sample"},{"location":"artifacts/xsodata/#xsk-xsodata-annotations-support","text":"SAP ODATA Annotations for XSOData XS2 SAP Annotations for OData Version 2.0 Annotation Element Annotation Supportability Element edm:Schema Element edm:EntityContainer Element edm:EntitySet Element edm:EntityType Element edm:Property Element edm:NavigationProperty Element edm:FunctionImport Element sap:value-constraint Element edm:Parameter Element edm:AssociationSet If you want to check the whole list of annotations, visit the official SAP OData Annotations v2.X documentation. Supportable OData Service-Definition Features FEATURES SUPPORTED IN XSK REMARKS Aggregation Association DONE Key Specification DONE Parameter Entity Sets Projection DONE HANA TableType Supported type for OData CALC VIEW GLOBAL TEMPORARARY SHARED TEMPORARARY NO LOGGING TEMPORARY SYNONYM SYSTEM TABLE TABLE USER DEFINED COLUMN VIEW VIEW JOIN VIEW OLAP VIEW HIERARCHY VIEW","title":"XSK XSODATA Annotations Support"},{"location":"cheatsheet/hdi/","text":"HDI - HANA Deployment Infrastructure SAP HANA Deployment Infrastructure (HDI) is a service that enables you to deploy database development artifacts to so-called containers. HDI is supported in XSK via the *.hdi and *.hdiconfig files. SAP Help Portal For more information, see SAP HANA Deployment Infrastructure Reference (SAP HANA Cloud) . HDI SQL API - Return Codes HDI SQL API - Make Operation Overview To support the deployment of database development artifacts via HDI, create *.hdi and *.hdiconfig files in your project: *.hdi *.hdiconfig { \"configuration\" : \"/hdi-ext/config.hdiconfig\" , \"users\" : [ \"XSK_SAMPLES_HDI_EXT\" ], \"group\" : \"XSK_HDI_EXT_GROUP\" , \"container\" : \"XSK_HDI_EXT\" , \"deploy\" : [ \"/hdi-ext/Customers.hdbsynonym\" , \"/hdi-ext/CustomersCalcView.hdbcalculationview\" ], \"undeploy\" : [] } { \"file_suffixes\" :{ \"hdbsynonym\" :{ \"plugin_name\" : \"com.sap.hana.di.synonym\" }, \"hdbpublicsynonym\" :{ \"plugin_name\" : \"com.sap.hana.di.publicsynonym\" }, \"hdbcalculationview\" :{ \"plugin_name\" : \"com.sap.hana.di.calculationview\" } } } HDI Plugins List of HDI supported database development artifacts: Application Time-Period Table Plug-in (.hdbapplicationtime) \"hdbapplicationtime\" : { \"plugin_name\" : \"com.sap.hana.di.applicationtime\" } Analytic Privileges (.hdbanalyticprivilege) \"hdbanalyticprivilege\" : { \"plugin_name\" : \"com.sap.hana.di.analyticprivilege\" } Calculation Views (.hdbcalculationview) \"hdbcalculationview\" : { \"plugin_name\" : \"com.sap.hana.di.calculationview\" } Constraints (.hdbconstraint) \"hdbconstraint\" : { \"plugin_name\" : \"com.sap.hana.di.constraint\" } Copy Only (.txt) \"txt\" : { \"plugin_name\" : \"com.sap.hana.di.copyonly\" } Document Store Collections (.hdbcollection) \"hdbcollection\" : { \"plugin_name\" : \"com.sap.hana.di.collection\" } Document Store Collection Index (.hdbcollectionindex) Flowgraph (.hdbflowgraph) \"hdbflowgraph\" : { \"plugin_name\" : \"com.sap.hana.di.flowgraph\" } Functions (.hdbfunction) \"hdbfunction\" : { \"plugin_name\" : \"com.sap.hana.di.function\" } Graph Workspaces (.hdbgraphworkspace) \"hdbgraphworkspace\" : { \"plugin_name\" : \"com.sap.hana.di.graphworkspace\" } Indexes (.hdbindex) \"hdbindex\" : { \"plugin_name\" : \"com.sap.hana.di.index\" } Libraries (.hdblibrary) \"hdblibrary\" : { \"plugin_name\" : \"com.sap.hana.di.library\" } Logical Schema Definition (.hdblogicalschema) \"hdblogicalschema\" : { \"plugin_name\" : \"com.sap.hana.di.logicalschema\" } Migration Tables (.hdbmigrationtable) \"hdbmigrationtable\" : { \"plugin_name\" : \"com.sap.hana.di.table.migration\" } Procedures (.hdbprocedure) \"hdbprocedure\" : { \"plugin_name\" : \"com.sap.hana.di.procedure\" } Projection Views (.hdbprojectionview) \"hdbprojectionview\" : { \"plugin_name\" : \"com.sap.hana.di.projectionview\" }, \"hdbprojectionviewconfig\" : { \"plugin_name\" : \"com.sap.hana.di.projectionview.config\" } Public Synonym (.hdbpublicsynonym) \"hdbpublicsynonym\" : { \"plugin_name\" : \"com.sap.hana.di.publicsynonym\" } Replication Task (.hdbreptask) \"hdbreptask\" : { \"plugin_name\" : \"com.sap.hana.di.reptask\" } Result Cache (.hdbresultcache) \"hdbresultcache\" : { \"plugin_name\" : \"com.sap.hana.di.resultcache\" } Roles (.hdbrole) \"hdbrole\" : { \"plugin_name\" : \"com.sap.hana.di.role\" }, \"hdbroleconfig\" : { \"plugin_name\" : \"com.sap.hana.di.role.config\" } Search Rule Set (.hdbsearchruleset) \"hdbsearchruleset\" : { \"plugin_name\" : \"com.sap.hana.di.searchruleset\" } Sequence (.hdbsequence) \"hdbsequence\" : { \"plugin_name\" : \"com.sap.hana.di.sequence\" } SQL Views (.hdbview) \"hdbview\" : { \"plugin_name\" : \"com.sap.hana.di.view\" } Statistics (.hdbstatistics) \"hdbstatistics\" : { \"plugin_name\" : \"com.sap.hana.di.statistics\" } Structured Privilege (.hdbstructuredprivilege) \"hdbstructuredprivilege\" : { \"plugin_name\" : \"com.sap.hana.di.structuredprivilege\" } Synonyms (.hdbsynonym and .hdbsynonymconfig) \"hdbsynonym\" : { \"plugin_name\" : \"com.sap.hana.di.synonym\" }, \"hdbsynonymconfig\" : { \"plugin_name\" : \"com.sap.hana.di.synonym.config\" } System Versioning Table (.hdbsystemversioning) \"hdbsystemversioning\" : { \"plugin_name\" : \"com.sap.hana.di.systemversioning\" } Tables (.hdbtable and .hdbdropcreatetable) \"hdbtable\" : { \"plugin_name\" : \"com.sap.hana.di.table\" }, \"hdbdropcreatetable\" : { \"plugin_name\" : \"com.sap.hana.di.dropcreatetable\" } Table Data (.hdbtabledata) \"hdbtabledata\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" }, \"csv\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" } Table Data Properties (.properties) \"properties\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" }, \"tags\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" } Table Type (.hdbtabletype) \"hdbtabletype\" : { \"plugin_name\" : \"com.sap.hana.di.tabletype\" } Triggers (.hdbtrigger) \"hdbtrigger\" : { \"plugin_name\" : \"com.sap.hana.di.trigger\" } Virtual Functions (.hdbvirtualfunction) \"hdbvirtualfunction\" : { \"plugin_name\" : \"com.sap.hana.di.virtualfunction\" } \"hdbvirtualfunctionconfig\" : { \"plugin_name\" : \"com.sap.hana.di.virtualfunction.config\" } Virtual Procedures (.hdbvirtualprocedure) \"hdbvirtualprocedure\" : { \"plugin_name\" : \"com.sap.hana.di.virtualprocedure\" }, \"hdbprojectionviewconfig\" : { \"plugin_name\" : \"com.sap.hana.di.virtualprocedure.config\" } Virtual Tables (.hdbvirtualtable) \"hdbvirtualtable\" : { \"plugin_name\" : \"com.sap.hana.di.virtualtable\" }, \"hdbvirtualtableconfig\" : { \"plugin_name\" : \"com.sap.hana.di.virtualtable.config\" } Virtual Packages (.hdbvirtualpackage) \"hdbvirtualpackagehadoop\" : { \"plugin_name\" : \"com.sap.hana.di.virtualpackage.hadoop\" }, \"hdbvirtualpackagesparksql\" : { \"plugin_name\" : \"com.sap.hana.di.virtualpackage.sparksql\" }","title":"HDI - HANA Deployment Infrastructure"},{"location":"cheatsheet/hdi/#hdi-hana-deployment-infrastructure","text":"SAP HANA Deployment Infrastructure (HDI) is a service that enables you to deploy database development artifacts to so-called containers. HDI is supported in XSK via the *.hdi and *.hdiconfig files. SAP Help Portal For more information, see SAP HANA Deployment Infrastructure Reference (SAP HANA Cloud) . HDI SQL API - Return Codes HDI SQL API - Make Operation","title":"HDI - HANA Deployment Infrastructure"},{"location":"cheatsheet/hdi/#overview","text":"To support the deployment of database development artifacts via HDI, create *.hdi and *.hdiconfig files in your project: *.hdi *.hdiconfig { \"configuration\" : \"/hdi-ext/config.hdiconfig\" , \"users\" : [ \"XSK_SAMPLES_HDI_EXT\" ], \"group\" : \"XSK_HDI_EXT_GROUP\" , \"container\" : \"XSK_HDI_EXT\" , \"deploy\" : [ \"/hdi-ext/Customers.hdbsynonym\" , \"/hdi-ext/CustomersCalcView.hdbcalculationview\" ], \"undeploy\" : [] } { \"file_suffixes\" :{ \"hdbsynonym\" :{ \"plugin_name\" : \"com.sap.hana.di.synonym\" }, \"hdbpublicsynonym\" :{ \"plugin_name\" : \"com.sap.hana.di.publicsynonym\" }, \"hdbcalculationview\" :{ \"plugin_name\" : \"com.sap.hana.di.calculationview\" } } }","title":"Overview"},{"location":"cheatsheet/hdi/#hdi-plugins","text":"List of HDI supported database development artifacts:","title":"HDI Plugins"},{"location":"cheatsheet/hdi/#application-time-period-table-plug-in-hdbapplicationtime","text":"\"hdbapplicationtime\" : { \"plugin_name\" : \"com.sap.hana.di.applicationtime\" }","title":"Application Time-Period Table Plug-in (.hdbapplicationtime)"},{"location":"cheatsheet/hdi/#analytic-privileges-hdbanalyticprivilege","text":"\"hdbanalyticprivilege\" : { \"plugin_name\" : \"com.sap.hana.di.analyticprivilege\" }","title":"Analytic Privileges (.hdbanalyticprivilege)"},{"location":"cheatsheet/hdi/#calculation-views-hdbcalculationview","text":"\"hdbcalculationview\" : { \"plugin_name\" : \"com.sap.hana.di.calculationview\" }","title":"Calculation Views (.hdbcalculationview)"},{"location":"cheatsheet/hdi/#constraints-hdbconstraint","text":"\"hdbconstraint\" : { \"plugin_name\" : \"com.sap.hana.di.constraint\" }","title":"Constraints (.hdbconstraint)"},{"location":"cheatsheet/hdi/#copy-only-txt","text":"\"txt\" : { \"plugin_name\" : \"com.sap.hana.di.copyonly\" }","title":"Copy Only (.txt)"},{"location":"cheatsheet/hdi/#document-store-collections-hdbcollection","text":"\"hdbcollection\" : { \"plugin_name\" : \"com.sap.hana.di.collection\" }","title":"Document Store Collections (.hdbcollection)"},{"location":"cheatsheet/hdi/#document-store-collection-index-hdbcollectionindex","text":"","title":"Document Store Collection Index (.hdbcollectionindex)"},{"location":"cheatsheet/hdi/#flowgraph-hdbflowgraph","text":"\"hdbflowgraph\" : { \"plugin_name\" : \"com.sap.hana.di.flowgraph\" }","title":"Flowgraph (.hdbflowgraph)"},{"location":"cheatsheet/hdi/#functions-hdbfunction","text":"\"hdbfunction\" : { \"plugin_name\" : \"com.sap.hana.di.function\" }","title":"Functions (.hdbfunction)"},{"location":"cheatsheet/hdi/#graph-workspaces-hdbgraphworkspace","text":"\"hdbgraphworkspace\" : { \"plugin_name\" : \"com.sap.hana.di.graphworkspace\" }","title":"Graph Workspaces (.hdbgraphworkspace)"},{"location":"cheatsheet/hdi/#indexes-hdbindex","text":"\"hdbindex\" : { \"plugin_name\" : \"com.sap.hana.di.index\" }","title":"Indexes (.hdbindex)"},{"location":"cheatsheet/hdi/#libraries-hdblibrary","text":"\"hdblibrary\" : { \"plugin_name\" : \"com.sap.hana.di.library\" }","title":"Libraries (.hdblibrary)"},{"location":"cheatsheet/hdi/#logical-schema-definition-hdblogicalschema","text":"\"hdblogicalschema\" : { \"plugin_name\" : \"com.sap.hana.di.logicalschema\" }","title":"Logical Schema Definition (.hdblogicalschema)"},{"location":"cheatsheet/hdi/#migration-tables-hdbmigrationtable","text":"\"hdbmigrationtable\" : { \"plugin_name\" : \"com.sap.hana.di.table.migration\" }","title":"Migration Tables (.hdbmigrationtable)"},{"location":"cheatsheet/hdi/#procedures-hdbprocedure","text":"\"hdbprocedure\" : { \"plugin_name\" : \"com.sap.hana.di.procedure\" }","title":"Procedures (.hdbprocedure)"},{"location":"cheatsheet/hdi/#projection-views-hdbprojectionview","text":"\"hdbprojectionview\" : { \"plugin_name\" : \"com.sap.hana.di.projectionview\" }, \"hdbprojectionviewconfig\" : { \"plugin_name\" : \"com.sap.hana.di.projectionview.config\" }","title":"Projection Views (.hdbprojectionview)"},{"location":"cheatsheet/hdi/#public-synonym-hdbpublicsynonym","text":"\"hdbpublicsynonym\" : { \"plugin_name\" : \"com.sap.hana.di.publicsynonym\" }","title":"Public Synonym (.hdbpublicsynonym)"},{"location":"cheatsheet/hdi/#replication-task-hdbreptask","text":"\"hdbreptask\" : { \"plugin_name\" : \"com.sap.hana.di.reptask\" }","title":"Replication Task (.hdbreptask)"},{"location":"cheatsheet/hdi/#result-cache-hdbresultcache","text":"\"hdbresultcache\" : { \"plugin_name\" : \"com.sap.hana.di.resultcache\" }","title":"Result Cache (.hdbresultcache)"},{"location":"cheatsheet/hdi/#roles-hdbrole","text":"\"hdbrole\" : { \"plugin_name\" : \"com.sap.hana.di.role\" }, \"hdbroleconfig\" : { \"plugin_name\" : \"com.sap.hana.di.role.config\" }","title":"Roles (.hdbrole)"},{"location":"cheatsheet/hdi/#search-rule-set-hdbsearchruleset","text":"\"hdbsearchruleset\" : { \"plugin_name\" : \"com.sap.hana.di.searchruleset\" }","title":"Search Rule Set (.hdbsearchruleset)"},{"location":"cheatsheet/hdi/#sequence-hdbsequence","text":"\"hdbsequence\" : { \"plugin_name\" : \"com.sap.hana.di.sequence\" }","title":"Sequence (.hdbsequence)"},{"location":"cheatsheet/hdi/#sql-views-hdbview","text":"\"hdbview\" : { \"plugin_name\" : \"com.sap.hana.di.view\" }","title":"SQL Views (.hdbview)"},{"location":"cheatsheet/hdi/#statistics-hdbstatistics","text":"\"hdbstatistics\" : { \"plugin_name\" : \"com.sap.hana.di.statistics\" }","title":"Statistics (.hdbstatistics)"},{"location":"cheatsheet/hdi/#structured-privilege-hdbstructuredprivilege","text":"\"hdbstructuredprivilege\" : { \"plugin_name\" : \"com.sap.hana.di.structuredprivilege\" }","title":"Structured Privilege (.hdbstructuredprivilege)"},{"location":"cheatsheet/hdi/#synonyms-hdbsynonym-and-hdbsynonymconfig","text":"\"hdbsynonym\" : { \"plugin_name\" : \"com.sap.hana.di.synonym\" }, \"hdbsynonymconfig\" : { \"plugin_name\" : \"com.sap.hana.di.synonym.config\" }","title":"Synonyms (.hdbsynonym and .hdbsynonymconfig)"},{"location":"cheatsheet/hdi/#system-versioning-table-hdbsystemversioning","text":"\"hdbsystemversioning\" : { \"plugin_name\" : \"com.sap.hana.di.systemversioning\" }","title":"System Versioning Table (.hdbsystemversioning)"},{"location":"cheatsheet/hdi/#tables-hdbtable-and-hdbdropcreatetable","text":"\"hdbtable\" : { \"plugin_name\" : \"com.sap.hana.di.table\" }, \"hdbdropcreatetable\" : { \"plugin_name\" : \"com.sap.hana.di.dropcreatetable\" }","title":"Tables (.hdbtable and .hdbdropcreatetable)"},{"location":"cheatsheet/hdi/#table-data-hdbtabledata","text":"\"hdbtabledata\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" }, \"csv\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" }","title":"Table Data (.hdbtabledata)"},{"location":"cheatsheet/hdi/#table-data-properties-properties","text":"\"properties\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" }, \"tags\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" }","title":"Table Data Properties (.properties)"},{"location":"cheatsheet/hdi/#table-type-hdbtabletype","text":"\"hdbtabletype\" : { \"plugin_name\" : \"com.sap.hana.di.tabletype\" }","title":"Table Type (.hdbtabletype)"},{"location":"cheatsheet/hdi/#triggers-hdbtrigger","text":"\"hdbtrigger\" : { \"plugin_name\" : \"com.sap.hana.di.trigger\" }","title":"Triggers (.hdbtrigger)"},{"location":"cheatsheet/hdi/#virtual-functions-hdbvirtualfunction","text":"\"hdbvirtualfunction\" : { \"plugin_name\" : \"com.sap.hana.di.virtualfunction\" } \"hdbvirtualfunctionconfig\" : { \"plugin_name\" : \"com.sap.hana.di.virtualfunction.config\" }","title":"Virtual Functions (.hdbvirtualfunction)"},{"location":"cheatsheet/hdi/#virtual-procedures-hdbvirtualprocedure","text":"\"hdbvirtualprocedure\" : { \"plugin_name\" : \"com.sap.hana.di.virtualprocedure\" }, \"hdbprojectionviewconfig\" : { \"plugin_name\" : \"com.sap.hana.di.virtualprocedure.config\" }","title":"Virtual Procedures (.hdbvirtualprocedure)"},{"location":"cheatsheet/hdi/#virtual-tables-hdbvirtualtable","text":"\"hdbvirtualtable\" : { \"plugin_name\" : \"com.sap.hana.di.virtualtable\" }, \"hdbvirtualtableconfig\" : { \"plugin_name\" : \"com.sap.hana.di.virtualtable.config\" }","title":"Virtual Tables (.hdbvirtualtable)"},{"location":"cheatsheet/hdi/#virtual-packages-hdbvirtualpackage","text":"\"hdbvirtualpackagehadoop\" : { \"plugin_name\" : \"com.sap.hana.di.virtualpackage.hadoop\" }, \"hdbvirtualpackagesparksql\" : { \"plugin_name\" : \"com.sap.hana.di.virtualpackage.sparksql\" }","title":"Virtual Packages (.hdbvirtualpackage)"},{"location":"cheatsheet/troubleshooting/","text":"Troubleshooting Insufficient Privileges The bellow error message is related to insufficient privileges: Error message Insufficient privilege: Detailed info for this error can be found with guid 'D59E64...' To check the error code, execute the following script: call SYS . GET_INSUFFICIENT_PRIVILEGE_ERROR_DETAILS ( '<GUID>' , ? ) Two-Factor Authentication If the migration fails to load Delivery Units and you are sure that you've provide correct information, please check whether your account has Two-Factor Authentication (2FA/MFA) enabled. Two-Factor Authentication is currently not supported, more info could be found here . You can use technical user without Two-Factor Authentication (2FA/MFA) enabled to complete the migration.","title":"Troubleshooting"},{"location":"cheatsheet/troubleshooting/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"cheatsheet/troubleshooting/#insufficient-privileges","text":"The bellow error message is related to insufficient privileges: Error message Insufficient privilege: Detailed info for this error can be found with guid 'D59E64...' To check the error code, execute the following script: call SYS . GET_INSUFFICIENT_PRIVILEGE_ERROR_DETAILS ( '<GUID>' , ? )","title":"Insufficient Privileges"},{"location":"cheatsheet/troubleshooting/#two-factor-authentication","text":"If the migration fails to load Delivery Units and you are sure that you've provide correct information, please check whether your account has Two-Factor Authentication (2FA/MFA) enabled. Two-Factor Authentication is currently not supported, more info could be found here . You can use technical user without Two-Factor Authentication (2FA/MFA) enabled to complete the migration.","title":"Two-Factor Authentication"},{"location":"lifecycle/cicd/","text":"CI/CD with GitHub Actions Overview The current setup is leveraging GitHub Actions and Kyma to create a CI/CD pipeline for building, releasing and deploying Docker image with XSK packaged with your application content. Prerequisites Create Service Account in Kyma for the CI/CD pipeline, as described bellow: Navigate to your Kyma cluster. Select your namespace (e.g. default ) . Go to Configuration \u2192 Service Accounts . Click the Create Service Account button. Enter the service account name (e.g. xsk ) . Create Cluster Role in Kyma for the CI/CD pipeline, as described bellow: Navigate to your Kyma cluster. Go to Configuration \u2192 Cluster Roles . Click the Create Cluster Role button. Enter the cluster role name (e.g. xsk ) . Add the following API Groups : (core) apps servicecatalog.k8s.io networking.istio.io servicecatalog.kyma-project.io gateway.kyma-project.io Select * in the Resources dropdown, to match all resources. Select * in the Verbs dropdown, to match all verbs. Click the Create button. Create Cluster Role Binding of the Cluster Role to the Service Account : Navigate to your Kyma cluster. Go to Cluster Role Bindings \u2192 Cluster Roles . Enter the cluster role binding name (e.g. xsk-default , note that the name is not namespace specific and should be unique for the whole cluster) . Select the Cluster Role (e.g. xsk ) . Switch the Kind to ServiceAccount . Select the desired namespace (e.g. default ) . Select the service account (e.g. xsk ) . Copy the Service Account token as later will be needed for the KYMA_TOKEN secret: Navigate to your Kyma cluster. Go to Configuration \u2192 Service Accounts . Select the Service Account (e.g. xsk ) . Select the secret for more details (e.g. xsk-token-wf6jk ) . Click the Decode button to decode the secret. Copy the token value (e.g. eyJhbGciOiJS... ) . Setup Navigate to your GitHub repository. Create .github/workflows/<pipeline-name>.yaml file with the following content: Build ( build.yaml ) Deployment ( deploy.yaml ) Info The following GitHub Action builds XSK based Docker image for your application and push it to your Docker registry. Note: Replace the <your-organization>/<your-repository> placeholder with a default organization and repository where the Docker image will be pushed (can be changed when triggering the GitHub Action) . name : Build Application Image on : workflow_dispatch : inputs : xskRepository : description : XSK Repository required : true type : choice options : - 'dirigiblelabs/xsk-kyma' - 'dirigiblelabs/xsk-cf' - 'dirigiblelabs/xsk' xskVersion : description : XSK Version required : true default : 'latest' applicationRepository : description : Application Repository required : true default : '<your-organization>/<your-repository>' applicationReleaseVersion : description : Application Release Version required : true jobs : build : runs-on : ubuntu-latest steps : - name : Release Input Parameters run : | echo \"Release Type: ${{ github.event.inputs.releaseType }}\" echo \"Application Repository: ${{ github.event.inputs.applicationRepository }}\" echo \"Application Release Version: ${{ github.event.inputs.applicationReleaseVersion }}\" - uses : actions/checkout@v2 with : fetch-depth : 0 - name : Build Dockerfile run : | DOCKERFILE_CONTENT=$(cat << EOF FROM ${{ github.event.inputs.xskRepository }}:${{ github.event.inputs.xskVersion }} RUN mkdir -p /usr/local/tomcat/target/dirigible/repository/root/registry/public/ COPY . /usr/local/tomcat/target/dirigible/repository/root/registry/public/ RUN rm -rf /usr/local/tomcat/target/dirigible/repository/root/registry/public/Dockerfile RUN rm -rf /usr/local/tomcat/target/dirigible/repository/root/registry/public/.github/ EOF ) echo \"$DOCKERFILE_CONTENT\" >> Dockerfile echo \"$DOCKERFILE_CONTENT\" - name : Docker Login run : docker login ${{secrets.DOCKER_REGISTRY}} -u ${{secrets.DOCKER_USERNAME}} -p ${{secrets.DOCKER_PASSWORD}} - name : Build Application Image run : | docker build . -t ${{secrets.DOCKER_REGISTRY}}/${{ github.event.inputs.applicationRepository }}:${{ github.event.inputs.applicationReleaseVersion }} docker tag ${{secrets.DOCKER_REGISTRY}}/${{ github.event.inputs.applicationRepository }}:${{ github.event.inputs.applicationReleaseVersion }} ${{secrets.DOCKER_REGISTRY}}/${{ github.event.inputs.applicationRepository }}:latest docker push ${{secrets.DOCKER_REGISTRY}}/${{ github.event.inputs.applicationRepository }}:${{ github.event.inputs.applicationReleaseVersion }} docker push ${{secrets.DOCKER_REGISTRY}}/${{ github.event.inputs.applicationRepository }}:latest Info The following GitHub Action deploys your XSK based Docker image to your Kyma cluster via Helm. Note: Replace the <your-organization>/<your-repository> placeholder with a default organization and repository where the Docker image will be pushed (can be changed when triggering the GitHub Action) . name : Deploy Application Image on : workflow_dispatch : inputs : applicationRepository : description : Application Repository required : true default : '<your-organization>/<your-repository>' applicationReleaseVersion : description : Application Release Version required : true jobs : deploy : runs-on : ubuntu-latest steps : - name : Setup Kube Config File env : KYMA_CERTIFICATE : ${{ secrets.KYMA_CERTIFICATE }} KYMA_SERVER : ${{ secrets.KYMA_SERVER }} KYMA_TOKEN : ${{ secrets.KYMA_TOKEN }} run : | mkdir $HOME/.kube echo \" apiVersion: v1 kind: Config current-context: xsk clusters: - name: xsk cluster: certificate-authority-data: $KYMA_CERTIFICATE server: $KYMA_SERVER contexts: - name: xsk context: cluster: xsk user: xsk users: - name: xsk user: token: $KYMA_TOKEN\" > $HOME/.kube/config - name : Export Kyma Host run : | export KYMA_API_SERVER=${{ secrets.KYMA_SERVER }} echo \"KYMA_HOST=${KYMA_API_SERVER:12}\" >> $GITHUB_ENV - name : Helm Upgrade Application Instance run : | helm repo add xsk https://www.xsk.io helm repo update helm upgrade --install xsk xsk/xsk \\ --set kyma.enabled=true \\ --set kyma.host=$KYMA_HOST \\ --set hana.enabled=true \\ --set hana.url='jdbc:sap://${{ secrets.HANA_URL }}/?encrypt=true&validateCertificate=false`' \\ --set hana.username=${{ secrets.HANA_USERNAME }} \\ --set hana.password='${{ secrets.HANA_PASSWORD }}' \\ --set persistentVolumeClaim.enabled=false \\ --set deployment.strategyType=RollingUpdate \\ --set application.privateDockerRegistry=true \\ --set application.dockerServer=${{secrets.DOCKER_REGISTRY}} \\ --set application.dockerUsername=${{secrets.DOCKER_USERNAME}} \\ --set application.dockerPassword=${{secrets.DOCKER_PASSWORD}} \\ --set application.dockerEmail=${{secrets.DOCKER_EMAIL}} \\ --set application.image=${{secrets.DOCKER_REGISTRY}}/${{ github.event.inputs.applicationRepository }}:${{ github.event.inputs.applicationReleaseVersion }} GitHub Secrets The following GitHub Secrets are required in order to successfully run the previously created GitHub Actions. To create GitHub secret: Navigate to your GitHub repository. Open the Settings tab. Go to Secrets \u2192 Actions . Click the New Repository Secret button. Name Description Required for DOCKER_REGISTRY The Docker Registry (e.g. docker.io , ghcr.io , etc.) Build DOCKER_USERNAME The Docker Username ( <your-docker-username> ) Build DOCKER_PASSWORD The Docker Password ( <your-docker-password> ) Build DOCKER_EMAIL The Docker Email ( <your-docker-email> ) Deploy HANA_URL The HANA Cloud URL (e.g. 7512c2q1-...:443 ) Deploy HANA_USERNAME The HANA Cloud Username ( <your-hana-cloud-username> ) Deploy HANA_PASSWORD The HANA Cloud Password ( <your-hana-cloud-password> ) Deploy KYMA_CERTIFICATE The Kyma Certificate (e.g. LS0tLS1CRUdJTiBDRVJUS... ) Deploy KYMA_SERVER The Kyma Server (e.g. https://api.c-a7b1c6...ondemand.com ) Deploy KYMA_TOKEN The Kyma Token (e.g. eyJhbGciOiJSUzI1NiIsImtpZCI6In... ) Deploy","title":"CI/CD"},{"location":"lifecycle/cicd/#cicd-with-github-actions","text":"","title":"CI/CD with GitHub Actions"},{"location":"lifecycle/cicd/#overview","text":"The current setup is leveraging GitHub Actions and Kyma to create a CI/CD pipeline for building, releasing and deploying Docker image with XSK packaged with your application content. Prerequisites Create Service Account in Kyma for the CI/CD pipeline, as described bellow: Navigate to your Kyma cluster. Select your namespace (e.g. default ) . Go to Configuration \u2192 Service Accounts . Click the Create Service Account button. Enter the service account name (e.g. xsk ) . Create Cluster Role in Kyma for the CI/CD pipeline, as described bellow: Navigate to your Kyma cluster. Go to Configuration \u2192 Cluster Roles . Click the Create Cluster Role button. Enter the cluster role name (e.g. xsk ) . Add the following API Groups : (core) apps servicecatalog.k8s.io networking.istio.io servicecatalog.kyma-project.io gateway.kyma-project.io Select * in the Resources dropdown, to match all resources. Select * in the Verbs dropdown, to match all verbs. Click the Create button. Create Cluster Role Binding of the Cluster Role to the Service Account : Navigate to your Kyma cluster. Go to Cluster Role Bindings \u2192 Cluster Roles . Enter the cluster role binding name (e.g. xsk-default , note that the name is not namespace specific and should be unique for the whole cluster) . Select the Cluster Role (e.g. xsk ) . Switch the Kind to ServiceAccount . Select the desired namespace (e.g. default ) . Select the service account (e.g. xsk ) . Copy the Service Account token as later will be needed for the KYMA_TOKEN secret: Navigate to your Kyma cluster. Go to Configuration \u2192 Service Accounts . Select the Service Account (e.g. xsk ) . Select the secret for more details (e.g. xsk-token-wf6jk ) . Click the Decode button to decode the secret. Copy the token value (e.g. eyJhbGciOiJS... ) .","title":"Overview"},{"location":"lifecycle/cicd/#setup","text":"Navigate to your GitHub repository. Create .github/workflows/<pipeline-name>.yaml file with the following content: Build ( build.yaml ) Deployment ( deploy.yaml ) Info The following GitHub Action builds XSK based Docker image for your application and push it to your Docker registry. Note: Replace the <your-organization>/<your-repository> placeholder with a default organization and repository where the Docker image will be pushed (can be changed when triggering the GitHub Action) . name : Build Application Image on : workflow_dispatch : inputs : xskRepository : description : XSK Repository required : true type : choice options : - 'dirigiblelabs/xsk-kyma' - 'dirigiblelabs/xsk-cf' - 'dirigiblelabs/xsk' xskVersion : description : XSK Version required : true default : 'latest' applicationRepository : description : Application Repository required : true default : '<your-organization>/<your-repository>' applicationReleaseVersion : description : Application Release Version required : true jobs : build : runs-on : ubuntu-latest steps : - name : Release Input Parameters run : | echo \"Release Type: ${{ github.event.inputs.releaseType }}\" echo \"Application Repository: ${{ github.event.inputs.applicationRepository }}\" echo \"Application Release Version: ${{ github.event.inputs.applicationReleaseVersion }}\" - uses : actions/checkout@v2 with : fetch-depth : 0 - name : Build Dockerfile run : | DOCKERFILE_CONTENT=$(cat << EOF FROM ${{ github.event.inputs.xskRepository }}:${{ github.event.inputs.xskVersion }} RUN mkdir -p /usr/local/tomcat/target/dirigible/repository/root/registry/public/ COPY . /usr/local/tomcat/target/dirigible/repository/root/registry/public/ RUN rm -rf /usr/local/tomcat/target/dirigible/repository/root/registry/public/Dockerfile RUN rm -rf /usr/local/tomcat/target/dirigible/repository/root/registry/public/.github/ EOF ) echo \"$DOCKERFILE_CONTENT\" >> Dockerfile echo \"$DOCKERFILE_CONTENT\" - name : Docker Login run : docker login ${{secrets.DOCKER_REGISTRY}} -u ${{secrets.DOCKER_USERNAME}} -p ${{secrets.DOCKER_PASSWORD}} - name : Build Application Image run : | docker build . -t ${{secrets.DOCKER_REGISTRY}}/${{ github.event.inputs.applicationRepository }}:${{ github.event.inputs.applicationReleaseVersion }} docker tag ${{secrets.DOCKER_REGISTRY}}/${{ github.event.inputs.applicationRepository }}:${{ github.event.inputs.applicationReleaseVersion }} ${{secrets.DOCKER_REGISTRY}}/${{ github.event.inputs.applicationRepository }}:latest docker push ${{secrets.DOCKER_REGISTRY}}/${{ github.event.inputs.applicationRepository }}:${{ github.event.inputs.applicationReleaseVersion }} docker push ${{secrets.DOCKER_REGISTRY}}/${{ github.event.inputs.applicationRepository }}:latest Info The following GitHub Action deploys your XSK based Docker image to your Kyma cluster via Helm. Note: Replace the <your-organization>/<your-repository> placeholder with a default organization and repository where the Docker image will be pushed (can be changed when triggering the GitHub Action) . name : Deploy Application Image on : workflow_dispatch : inputs : applicationRepository : description : Application Repository required : true default : '<your-organization>/<your-repository>' applicationReleaseVersion : description : Application Release Version required : true jobs : deploy : runs-on : ubuntu-latest steps : - name : Setup Kube Config File env : KYMA_CERTIFICATE : ${{ secrets.KYMA_CERTIFICATE }} KYMA_SERVER : ${{ secrets.KYMA_SERVER }} KYMA_TOKEN : ${{ secrets.KYMA_TOKEN }} run : | mkdir $HOME/.kube echo \" apiVersion: v1 kind: Config current-context: xsk clusters: - name: xsk cluster: certificate-authority-data: $KYMA_CERTIFICATE server: $KYMA_SERVER contexts: - name: xsk context: cluster: xsk user: xsk users: - name: xsk user: token: $KYMA_TOKEN\" > $HOME/.kube/config - name : Export Kyma Host run : | export KYMA_API_SERVER=${{ secrets.KYMA_SERVER }} echo \"KYMA_HOST=${KYMA_API_SERVER:12}\" >> $GITHUB_ENV - name : Helm Upgrade Application Instance run : | helm repo add xsk https://www.xsk.io helm repo update helm upgrade --install xsk xsk/xsk \\ --set kyma.enabled=true \\ --set kyma.host=$KYMA_HOST \\ --set hana.enabled=true \\ --set hana.url='jdbc:sap://${{ secrets.HANA_URL }}/?encrypt=true&validateCertificate=false`' \\ --set hana.username=${{ secrets.HANA_USERNAME }} \\ --set hana.password='${{ secrets.HANA_PASSWORD }}' \\ --set persistentVolumeClaim.enabled=false \\ --set deployment.strategyType=RollingUpdate \\ --set application.privateDockerRegistry=true \\ --set application.dockerServer=${{secrets.DOCKER_REGISTRY}} \\ --set application.dockerUsername=${{secrets.DOCKER_USERNAME}} \\ --set application.dockerPassword=${{secrets.DOCKER_PASSWORD}} \\ --set application.dockerEmail=${{secrets.DOCKER_EMAIL}} \\ --set application.image=${{secrets.DOCKER_REGISTRY}}/${{ github.event.inputs.applicationRepository }}:${{ github.event.inputs.applicationReleaseVersion }} GitHub Secrets The following GitHub Secrets are required in order to successfully run the previously created GitHub Actions. To create GitHub secret: Navigate to your GitHub repository. Open the Settings tab. Go to Secrets \u2192 Actions . Click the New Repository Secret button. Name Description Required for DOCKER_REGISTRY The Docker Registry (e.g. docker.io , ghcr.io , etc.) Build DOCKER_USERNAME The Docker Username ( <your-docker-username> ) Build DOCKER_PASSWORD The Docker Password ( <your-docker-password> ) Build DOCKER_EMAIL The Docker Email ( <your-docker-email> ) Deploy HANA_URL The HANA Cloud URL (e.g. 7512c2q1-...:443 ) Deploy HANA_USERNAME The HANA Cloud Username ( <your-hana-cloud-username> ) Deploy HANA_PASSWORD The HANA Cloud Password ( <your-hana-cloud-password> ) Deploy KYMA_CERTIFICATE The Kyma Certificate (e.g. LS0tLS1CRUdJTiBDRVJUS... ) Deploy KYMA_SERVER The Kyma Server (e.g. https://api.c-a7b1c6...ondemand.com ) Deploy KYMA_TOKEN The Kyma Token (e.g. eyJhbGciOiJSUzI1NiIsImtpZCI6In... ) Deploy","title":"Setup"},{"location":"migration/changes/","text":"Changes Overview Due to the changes between HANA Cloud and HANA on Neo, XSK performs modification to existing artifacts and introduces new artifacts in an attempt to keep application functionality. Below are List of changes HDI Container In HANA Cloud, calculation views can live only in an HDI container. This is why XSK is creating an HDI container and puts the calculation views in it. See below for changes on calculation views. A new file is introduced to model the HDI container. { \"configuration\" : \"path/to/hdiconfig\" , \"users\" : [ \"HDI_CONTAINER_USER\" ], \"group\" : \"CONTAINER_GROUP_NAME\" , \"container\" : \"CONTAINER_NAME\" , \"deploy\" : [ \"path/to/artifact/to/be/deployed1\" , \"path/to/artifact/to/be/deployed2\" ], \"undeploy\" : [ \"path/to/artifact/to/be/undeployed\" ] } If you'd like to deploy new artifacts to the HDI container add them to the deploy section. If you'd like to undeploy existing artifacts from the HDI container move them to the undeploy section. A default hdiconfig file is created which contains all plugins as described here Syonyms - as calculation views live in an HDI container visibility to objects outside the container is managed via synonyms. This is why a new file hdi-synonyms.hdbsynonym is created which contains synonyms pointing to objects outside the HDI container. Public synonyms - in order to make artifacts in the HDI container accessible to XSOdata and XSJS services, public synonyms are created for them. Artifact Changes Calculation Views Only graphical calulation views are supported. Follow the migration steps in SAP HANA Studio to convert scripted calculation views to Default schema is not supported in HDI and is removed during migration. ColumnObject attribute is changed to resourceUri pointing to a synonym Analytic Privileges SESION_USER variable is changed to SESSION_CONTEXT('APPLICATIONUSER') which is the named user accessing the application, whereas the session user is the technical user used by XSK to establish connection. XML based analytic privileges must be converted to SQL analytic privileges HDB Role As database communication happens with a technical user, hdbroles are not applicable for restricting access to database resources within XSK. Thest must be migrated to application-level roles/xsprivileges. Table functions HDB Table functions now live in the HDI container and access data from the outside via synonyms. Destinations The following artifacts are not supported and must be moved to SAP BTP Destination service: .xshttpdest , .xsoauthappconfig , .xsoauthclientflavor . See more details here SQL syntax UPDATE FROM statements are automatically converted to MERGE INTO statements Reserved keywords such as row will be modified to row1 _SYS_REPO is not available and any code using must be adjusted API Changes $.repo is undocumented as is not supported $.net.http.readDestination now uses SAP BTP Destination service and requires a service instance bound to XSK $.text API is not available $.net.Mail requires a destination of type Mail in SAP BTP Destination service pointing to a dedicated mail server","title":"Changes"},{"location":"migration/changes/#changes","text":"","title":"Changes"},{"location":"migration/changes/#overview","text":"Due to the changes between HANA Cloud and HANA on Neo, XSK performs modification to existing artifacts and introduces new artifacts in an attempt to keep application functionality. Below are","title":"Overview"},{"location":"migration/changes/#list-of-changes","text":"","title":"List of changes"},{"location":"migration/changes/#hdi-container","text":"In HANA Cloud, calculation views can live only in an HDI container. This is why XSK is creating an HDI container and puts the calculation views in it. See below for changes on calculation views. A new file is introduced to model the HDI container. { \"configuration\" : \"path/to/hdiconfig\" , \"users\" : [ \"HDI_CONTAINER_USER\" ], \"group\" : \"CONTAINER_GROUP_NAME\" , \"container\" : \"CONTAINER_NAME\" , \"deploy\" : [ \"path/to/artifact/to/be/deployed1\" , \"path/to/artifact/to/be/deployed2\" ], \"undeploy\" : [ \"path/to/artifact/to/be/undeployed\" ] } If you'd like to deploy new artifacts to the HDI container add them to the deploy section. If you'd like to undeploy existing artifacts from the HDI container move them to the undeploy section. A default hdiconfig file is created which contains all plugins as described here Syonyms - as calculation views live in an HDI container visibility to objects outside the container is managed via synonyms. This is why a new file hdi-synonyms.hdbsynonym is created which contains synonyms pointing to objects outside the HDI container. Public synonyms - in order to make artifacts in the HDI container accessible to XSOdata and XSJS services, public synonyms are created for them.","title":"HDI Container"},{"location":"migration/changes/#artifact-changes","text":"","title":"Artifact Changes"},{"location":"migration/changes/#calculation-views","text":"Only graphical calulation views are supported. Follow the migration steps in SAP HANA Studio to convert scripted calculation views to Default schema is not supported in HDI and is removed during migration. ColumnObject attribute is changed to resourceUri pointing to a synonym","title":"Calculation Views"},{"location":"migration/changes/#analytic-privileges","text":"SESION_USER variable is changed to SESSION_CONTEXT('APPLICATIONUSER') which is the named user accessing the application, whereas the session user is the technical user used by XSK to establish connection. XML based analytic privileges must be converted to SQL analytic privileges","title":"Analytic Privileges"},{"location":"migration/changes/#hdb-role","text":"As database communication happens with a technical user, hdbroles are not applicable for restricting access to database resources within XSK. Thest must be migrated to application-level roles/xsprivileges.","title":"HDB Role"},{"location":"migration/changes/#table-functions","text":"HDB Table functions now live in the HDI container and access data from the outside via synonyms.","title":"Table functions"},{"location":"migration/changes/#destinations","text":"The following artifacts are not supported and must be moved to SAP BTP Destination service: .xshttpdest , .xsoauthappconfig , .xsoauthclientflavor . See more details here","title":"Destinations"},{"location":"migration/changes/#sql-syntax","text":"UPDATE FROM statements are automatically converted to MERGE INTO statements Reserved keywords such as row will be modified to row1 _SYS_REPO is not available and any code using must be adjusted","title":"SQL syntax"},{"location":"migration/changes/#api-changes","text":"$.repo is undocumented as is not supported $.net.http.readDestination now uses SAP BTP Destination service and requires a service instance bound to XSK $.text API is not available $.net.Mail requires a destination of type Mail in SAP BTP Destination service pointing to a dedicated mail server","title":"API Changes"},{"location":"migration/guide/","text":"Migration guide Overview Follow this guide for steps how to migrate an SAP HANA XS Classic application to SAP HANA Cloud. Supported artifacts and APIs Check out the APIs page for a list of APIs and their compatibility status. Checkout the Artifacts page for a list of artifacts and their compatibility status. Preparation Before starting the migration process, make sure to follow the steps in the Prerequisites section . Next, make sure to setup XSK on Kyma . Steps Catalog migration Some applications use tables which were not created via the standard XS means (ie. hdbdd, hdbtable). These tables need to be created in HANA Cloud before proceeding with the migration of XS artifacts. Note: Access to objects in these schemas must be manually granted to the XSK technical user. If there are no such artifacts, proceed to XS artifacts migration XS artifacts migration After the necessary objects are created in the target HANA Cloud database, migration of the XS artifacts that use these objects can be executed. Open XSK Navigate to the Migration perspective in the left vertical menu Choose Migrate live project(s) Follow the wizard Enter your SAP BTP credentials Choose the HANA Database in which the Delivery Unit resides Select the workspace in which the sources will be copied and the delivery unit for migration Review the changed made by XSK - see this page for more details Click migrate and open the workspace Publish the project - this will activate all artifacts (HANA artifacts, xsjs and xsodata services) Validate the functionality of the application Data migration Next, you can stop the old HANA database and proceed with migration of the data. Following this order of execution can minimize the downtime of the application.","title":"Guide"},{"location":"migration/guide/#migration-guide","text":"","title":"Migration guide"},{"location":"migration/guide/#overview","text":"Follow this guide for steps how to migrate an SAP HANA XS Classic application to SAP HANA Cloud.","title":"Overview"},{"location":"migration/guide/#supported-artifacts-and-apis","text":"Check out the APIs page for a list of APIs and their compatibility status. Checkout the Artifacts page for a list of artifacts and their compatibility status.","title":"Supported artifacts and APIs"},{"location":"migration/guide/#preparation","text":"Before starting the migration process, make sure to follow the steps in the Prerequisites section . Next, make sure to setup XSK on Kyma .","title":"Preparation"},{"location":"migration/guide/#steps","text":"","title":"Steps"},{"location":"migration/guide/#catalog-migration","text":"Some applications use tables which were not created via the standard XS means (ie. hdbdd, hdbtable). These tables need to be created in HANA Cloud before proceeding with the migration of XS artifacts. Note: Access to objects in these schemas must be manually granted to the XSK technical user. If there are no such artifacts, proceed to XS artifacts migration","title":"Catalog migration"},{"location":"migration/guide/#xs-artifacts-migration","text":"After the necessary objects are created in the target HANA Cloud database, migration of the XS artifacts that use these objects can be executed. Open XSK Navigate to the Migration perspective in the left vertical menu Choose Migrate live project(s) Follow the wizard Enter your SAP BTP credentials Choose the HANA Database in which the Delivery Unit resides Select the workspace in which the sources will be copied and the delivery unit for migration Review the changed made by XSK - see this page for more details Click migrate and open the workspace Publish the project - this will activate all artifacts (HANA artifacts, xsjs and xsodata services) Validate the functionality of the application","title":"XS artifacts migration"},{"location":"migration/guide/#data-migration","text":"Next, you can stop the old HANA database and proceed with migration of the data. Following this order of execution can minimize the downtime of the application.","title":"Data migration"},{"location":"setup/","text":"Local Setup Overview You can deploy XSK locally using Docker or Tomcat server. Steps Deploy as a Docker container or on Tomcat server. Docker Tomcat Prerequisites Install Docker . Pull the XSK Docker image: docker pull dirigiblelabs/xsk:latest Start the container: Run with Mounted Volume with HANA Cloud docker run --name xsk \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest docker run --name xsk \\ -v <your-local-directory>:/usr/local/tomcat/target \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest docker run --name xsk \\ -e DIRIGIBLE_DATABASE_PROVIDER=\"custom\" \\ -e DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=\"HANA\" \\ -e DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=\"HANA\" \\ -e HANA_DRIVER=\"com.sap.db.jdbc.Driver\" \\ -e HANA_URL=\"jdbc:sap://<hanaHost>?encrypt=true&validateCertificate=true\" \\ -e HANA_USERNAME=\"<hanaUsername>\" \\ -e HANA_PASSWORD=\"<hanaPassword>\" \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest Note Replace the <hanaHost> placeholder with the HANA Cloud host that you're going to use. Replace the <hanaUsername> placeholder with the HANA Cloud username that you're going to use. Replace the <hanaPassword> placeholder with the HANA Cloud password that you're going to use. Windows For setup on Windows OS, issues may appear with the way the environment variables ( -e XXX=YYY ) are provided. Either they should be properly escaped, or they could be supplied as *.env file : docker run --name xsk \\ --env-file env-variables.env \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest Prerequisites Java 11 or Java 13 installed (default, required during runtime). Java 8 JRE/JDK installed (additional, required for compatability reasons). Download ROOT.war for Tomcat from: https://github.com/SAP/xsk/releases/latest Note For local test & development purposes, we recommend the server distribution. Configure the Users store under $CATALINA_HOME/conf/tomcat-users.xml : <tomcat-users> <role rolename= \"Developer\" /> <role rolename= \"Operator\" /> <role rolename= \"Everyone\" /> <user username= \"dirigible\" password= \"dirigible\" roles= \"Developer,Operator,Everyone\" /> </tomcat-users> Copy the XSK's ROOT.war to $TOMCAT/webapps folder. Provide the Java 8 JRE/JDK path. export JAVA8_HOME=<pathToJava8> Note Replace the <pathToJava8> placeholder with the actual path to your Java 8 installation (e.g. /usr/lib/jvm/java-8-openjdk-amd64/ ) . Configure connection to HANA Cloud instance. export HANA_DRIVER=com.sap.db.jdbc.Driver export HANA_URL=jdbc:sap://<hanaHost>?encrypt=true&validateCertificate=true export HANA_USERNAME=<hanaUsername> export HANA_PASSWORD=<hanaPassword> Note Replace the <hanaHost> placeholder with the HANA Cloud host that you're going to use. Replace the <hanaUsername> placeholder with the HANA Cloud username that you're going to use. Replace the <hanaPassword> placeholder with the HANA Cloud password that you're going to use. Start the Tomcat server. XSK versions Instead of using the latest tag (version), for production and development use cases it is recommended that you use a stable release version: You can find all released versions here . You can find all XSK Docker images and tags (versions) here . Open a web browser and go to: http://localhost:8080/ Note The default user name and password are dirigible/dirigible . Stop the container: docker stop dirigible","title":"Local"},{"location":"setup/#local-setup","text":"","title":"Local Setup"},{"location":"setup/#overview","text":"You can deploy XSK locally using Docker or Tomcat server.","title":"Overview"},{"location":"setup/#steps","text":"Deploy as a Docker container or on Tomcat server. Docker Tomcat Prerequisites Install Docker . Pull the XSK Docker image: docker pull dirigiblelabs/xsk:latest Start the container: Run with Mounted Volume with HANA Cloud docker run --name xsk \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest docker run --name xsk \\ -v <your-local-directory>:/usr/local/tomcat/target \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest docker run --name xsk \\ -e DIRIGIBLE_DATABASE_PROVIDER=\"custom\" \\ -e DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=\"HANA\" \\ -e DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=\"HANA\" \\ -e HANA_DRIVER=\"com.sap.db.jdbc.Driver\" \\ -e HANA_URL=\"jdbc:sap://<hanaHost>?encrypt=true&validateCertificate=true\" \\ -e HANA_USERNAME=\"<hanaUsername>\" \\ -e HANA_PASSWORD=\"<hanaPassword>\" \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest Note Replace the <hanaHost> placeholder with the HANA Cloud host that you're going to use. Replace the <hanaUsername> placeholder with the HANA Cloud username that you're going to use. Replace the <hanaPassword> placeholder with the HANA Cloud password that you're going to use. Windows For setup on Windows OS, issues may appear with the way the environment variables ( -e XXX=YYY ) are provided. Either they should be properly escaped, or they could be supplied as *.env file : docker run --name xsk \\ --env-file env-variables.env \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest Prerequisites Java 11 or Java 13 installed (default, required during runtime). Java 8 JRE/JDK installed (additional, required for compatability reasons). Download ROOT.war for Tomcat from: https://github.com/SAP/xsk/releases/latest Note For local test & development purposes, we recommend the server distribution. Configure the Users store under $CATALINA_HOME/conf/tomcat-users.xml : <tomcat-users> <role rolename= \"Developer\" /> <role rolename= \"Operator\" /> <role rolename= \"Everyone\" /> <user username= \"dirigible\" password= \"dirigible\" roles= \"Developer,Operator,Everyone\" /> </tomcat-users> Copy the XSK's ROOT.war to $TOMCAT/webapps folder. Provide the Java 8 JRE/JDK path. export JAVA8_HOME=<pathToJava8> Note Replace the <pathToJava8> placeholder with the actual path to your Java 8 installation (e.g. /usr/lib/jvm/java-8-openjdk-amd64/ ) . Configure connection to HANA Cloud instance. export HANA_DRIVER=com.sap.db.jdbc.Driver export HANA_URL=jdbc:sap://<hanaHost>?encrypt=true&validateCertificate=true export HANA_USERNAME=<hanaUsername> export HANA_PASSWORD=<hanaPassword> Note Replace the <hanaHost> placeholder with the HANA Cloud host that you're going to use. Replace the <hanaUsername> placeholder with the HANA Cloud username that you're going to use. Replace the <hanaPassword> placeholder with the HANA Cloud password that you're going to use. Start the Tomcat server. XSK versions Instead of using the latest tag (version), for production and development use cases it is recommended that you use a stable release version: You can find all released versions here . You can find all XSK Docker images and tags (versions) here . Open a web browser and go to: http://localhost:8080/ Note The default user name and password are dirigible/dirigible . Stop the container: docker stop dirigible","title":"Steps"},{"location":"setup/cloud-foundry/","text":"Setup in Cloud Foundry Overview You can deploy XSK in the SAP BTP 1 , Cloud Foundry environment. Prerequisites Install the Cloud Foundry Command Line Interface . Access to an SAP BTP global account. To create an SAP BTP Trial account, navigate to the SAP BTP Trial home page . Create a SAP HANA Cloud service instance in SAP BTP Cloud Foundry space. Create a separate SAP HANA Cloud user that will be used from the XSK engine. Steps Set the SAP BTP Cloud Foundry API host: cf api <cloud-foundry-api-host> Log in to the SAP BTP, Cloud Foundry environment with: cf login Create an XSUAA service instance: Copy and paste the following content into xs-security.json : { \"xsappname\" : \"<applicationName>-xsuaa\" , \"tenant-mode\" : \"shared\" , \"scopes\" : [ { \"name\" : \"$XSAPPNAME.Developer\" , \"description\" : \"Developer scope\" }, { \"name\" : \"$XSAPPNAME.Operator\" , \"description\" : \"Operator scope\" } ], \"role-templates\" : [ { \"name\" : \"Developer\" , \"description\" : \"Developer related roles\" , \"scope-references\" : [ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"Operator\" , \"description\" : \"Operator related roles\" , \"scope-references\" : [ \"$XSAPPNAME.Operator\" ] } ], \"role-collections\" : [ { \"name\" : \"XSK Developer\" , \"description\" : \"XSK Developer\" , \"role-template-references\" : [ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"XSK Operator\" , \"description\" : \"XSK Operator\" , \"role-template-references\" : [ \"$XSAPPNAME.Operator\" ] } ] } Note Replace the <applicationName> placeholder with your application name, e.g. xsk . Create an XSUAA service instance: cf create-service xsuaa application <applicationName>-xsuaa -c xs-security.json Note Use the same <applicationName> as in the previous step. Create map route: cf create-route <org-name> --hostname xsk cf map-route xsk <org-name> --hostname xsk Deploy XSK: Docker Buildpack cf push xsk \\ --docker-image=dirigiblelabs/xsk-cf:latest \\ -m 2G -k 2G Note Replace the <org-name> placeholder with your subaccount's Subdomain value. XSK versions Instead of using the latest tag (version), for production and development use cases it is recommended that you use a stable release version: You can find all released versions at https://github.com/sap/xsk/releases/ . You can find all XSK Docker images and tags (versions) at https://hub.docker.com/u/dirigiblelabs . Bind the XSUAA and HANA Cloud service instances to the XSK deployment: cf bind-service xsk <applicationName>-xsuaa cf bind-service xsk <hanaCloudInstanceName> cf set-env xsk HANA_USERNAME <hanaCloudUsername> cf set-env xsk HANA_PASSWORD <hanaCloudPassword> Note Replace the <applicationName> placeholder with the application name used in the previous steps. Replace the <hanaCloudInstanceName> placeholder with the HANA Cloud service instance name that will be used. Replace the <hanaUsername> placeholder with the HANA Cloud username that will be used. Replace the <hanaPassword> placeholder with the HANA Cloud password that will be used. Restart the xsk deployment: cf restart xsk Download the sap-cf binaries from the downloads site: https://github.com/SAP/xsk/releases Unzip the downloaded archive to extract the ROOT.war file. Create manifest.yaml file in the same directory where the ROOT.war is located: applications : - name : xsk host : xsk-<org-name> memory : 2G buildpack : sap_java_buildpack path : ROOT.war env : JBP_CONFIG_COMPONENTS : \"jres: ['com.sap.xs.java.buildpack.jdk.SAPMachineJDK']\" JBP_CONFIG_SAP_MACHINE_JRE : 'jre: { version: 11.+ }' HANA_USERNAME : <hanaUsername> HANA_PASSWORD : <hanaPassword> services : - <applicationName>-xsuaa - <hanaCloudInstanceName> Note Replace the <org-name> placeholder with your subaccount's Subdomain value. Replace the <applicationName> placeholder with the application name used in the previous steps. Replace the <hanaUsername> placeholder with the HANA Cloud username that will be used. Replace the <hanaPassword> placeholder with the HANA Cloud password that will be used. Replace the <hanaCloudInstanceName> placeholder with the HANA Cloud service instance name that will be used. Deploy with: cf push Assign the Developer and Operator roles. Log in. Additional Information For more details, see the step-by-step tutorial How to deploy Eclipse Dirigible in the SAP Cloud Platform Cloud Foundry environment on SAP Community. SAP Cloud Platform is called SAP Business Technology Platform (SAP BTP) as of 2021. \u21a9","title":"Cloud Foundry"},{"location":"setup/cloud-foundry/#setup-in-cloud-foundry","text":"","title":"Setup in Cloud Foundry"},{"location":"setup/cloud-foundry/#overview","text":"You can deploy XSK in the SAP BTP 1 , Cloud Foundry environment. Prerequisites Install the Cloud Foundry Command Line Interface . Access to an SAP BTP global account. To create an SAP BTP Trial account, navigate to the SAP BTP Trial home page . Create a SAP HANA Cloud service instance in SAP BTP Cloud Foundry space. Create a separate SAP HANA Cloud user that will be used from the XSK engine.","title":"Overview"},{"location":"setup/cloud-foundry/#steps","text":"Set the SAP BTP Cloud Foundry API host: cf api <cloud-foundry-api-host> Log in to the SAP BTP, Cloud Foundry environment with: cf login Create an XSUAA service instance: Copy and paste the following content into xs-security.json : { \"xsappname\" : \"<applicationName>-xsuaa\" , \"tenant-mode\" : \"shared\" , \"scopes\" : [ { \"name\" : \"$XSAPPNAME.Developer\" , \"description\" : \"Developer scope\" }, { \"name\" : \"$XSAPPNAME.Operator\" , \"description\" : \"Operator scope\" } ], \"role-templates\" : [ { \"name\" : \"Developer\" , \"description\" : \"Developer related roles\" , \"scope-references\" : [ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"Operator\" , \"description\" : \"Operator related roles\" , \"scope-references\" : [ \"$XSAPPNAME.Operator\" ] } ], \"role-collections\" : [ { \"name\" : \"XSK Developer\" , \"description\" : \"XSK Developer\" , \"role-template-references\" : [ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"XSK Operator\" , \"description\" : \"XSK Operator\" , \"role-template-references\" : [ \"$XSAPPNAME.Operator\" ] } ] } Note Replace the <applicationName> placeholder with your application name, e.g. xsk . Create an XSUAA service instance: cf create-service xsuaa application <applicationName>-xsuaa -c xs-security.json Note Use the same <applicationName> as in the previous step. Create map route: cf create-route <org-name> --hostname xsk cf map-route xsk <org-name> --hostname xsk Deploy XSK: Docker Buildpack cf push xsk \\ --docker-image=dirigiblelabs/xsk-cf:latest \\ -m 2G -k 2G Note Replace the <org-name> placeholder with your subaccount's Subdomain value. XSK versions Instead of using the latest tag (version), for production and development use cases it is recommended that you use a stable release version: You can find all released versions at https://github.com/sap/xsk/releases/ . You can find all XSK Docker images and tags (versions) at https://hub.docker.com/u/dirigiblelabs . Bind the XSUAA and HANA Cloud service instances to the XSK deployment: cf bind-service xsk <applicationName>-xsuaa cf bind-service xsk <hanaCloudInstanceName> cf set-env xsk HANA_USERNAME <hanaCloudUsername> cf set-env xsk HANA_PASSWORD <hanaCloudPassword> Note Replace the <applicationName> placeholder with the application name used in the previous steps. Replace the <hanaCloudInstanceName> placeholder with the HANA Cloud service instance name that will be used. Replace the <hanaUsername> placeholder with the HANA Cloud username that will be used. Replace the <hanaPassword> placeholder with the HANA Cloud password that will be used. Restart the xsk deployment: cf restart xsk Download the sap-cf binaries from the downloads site: https://github.com/SAP/xsk/releases Unzip the downloaded archive to extract the ROOT.war file. Create manifest.yaml file in the same directory where the ROOT.war is located: applications : - name : xsk host : xsk-<org-name> memory : 2G buildpack : sap_java_buildpack path : ROOT.war env : JBP_CONFIG_COMPONENTS : \"jres: ['com.sap.xs.java.buildpack.jdk.SAPMachineJDK']\" JBP_CONFIG_SAP_MACHINE_JRE : 'jre: { version: 11.+ }' HANA_USERNAME : <hanaUsername> HANA_PASSWORD : <hanaPassword> services : - <applicationName>-xsuaa - <hanaCloudInstanceName> Note Replace the <org-name> placeholder with your subaccount's Subdomain value. Replace the <applicationName> placeholder with the application name used in the previous steps. Replace the <hanaUsername> placeholder with the HANA Cloud username that will be used. Replace the <hanaPassword> placeholder with the HANA Cloud password that will be used. Replace the <hanaCloudInstanceName> placeholder with the HANA Cloud service instance name that will be used. Deploy with: cf push Assign the Developer and Operator roles. Log in. Additional Information For more details, see the step-by-step tutorial How to deploy Eclipse Dirigible in the SAP Cloud Platform Cloud Foundry environment on SAP Community. SAP Cloud Platform is called SAP Business Technology Platform (SAP BTP) as of 2021. \u21a9","title":"Steps"},{"location":"setup/helm/","text":"Setup with Helm Overview You can deploy XSK via Helm chart in a Kubernetes cluster. Prerequisites Install the Helm CLI . Make sure you have access to a Kubernetes Cluster . Setup Add the XSK Helm repository: helm repo add xsk https://www.xsk.io helm repo update Verify XSK Helm charts: From key server helm pull xsk/xsk --prov gpg --keyserver keys.openpgp.org --recv-key 734B0E32368A2283290E0B966010F454D1819484 gpg --export > ~/.gnupg/pubring.gpg helm verify xsk-<version>.tgz From github Note Use command wget for download public key instead of curl helm pull xsk/xsk --prov wget https://sap.github.io/xsk/charts/pubring.gpg -O ~/.gnupg/pubring.gpg helm verify xsk-<version>.tgz Deployment To deploy XSK, you can use the following instructions: Basic Kyma Kyma with SAP HANA database Kyma with custom roles helm install xsk xsk/xsk Accessing the XSK Instance Running this command will install XSK Deployment and Service with ClusterIP only. To access the XSK instance, execute the command that was printed in the console. Example: export POD_NAME=$(kubectl get pods --namespace default -l \"app.kubernetes.io/name=xsk,app.kubernetes.io/instance=xsk\" -o jsonpath=\"{.items[0].metadata.name}\") echo \"Visit http://127.0.0.1:8080 to use your application\" kubectl --namespace default port-forward $POD_NAME 8080:8080 Navigate to: http://127.0.0.1:8080 Log in with these username and password: dirigible / dirigible helm install xsk xsk/xsk \\ --set kyma.enabled=true \\ --set kyma.host=<kyma-host> This will install additionally an ApiRule and XSUAA ServiceInstance and ServiceBinding . The appropriate roles should be assigned to the user. helm install xsk xsk/xsk \\ --set hana.enabled=true \\ --set hana.url=<hana-url> \\ --set hana.username=<hana-username> \\ --set hana.password=<hana-password> \\ --set kyma.enabled=true \\ --set kyma.host=<kyma-apirule-host> This will install additionally an ApiRule , XSUAA ServiceInstance , ServiceBinding and HANA instance. The appropriate roles should be assigned to the user. helm install xsk xsk \\ --set kyma.enabled=true \\ --set kyma.host=<kyma-apirule-host> \\ --set kyma.addRoles=true \\ --set kyma.roles={\"<new-role>\"\\,\"<new-role>\"} This will install additionally an ApiRule and XSUAA ServiceInstance and ServiceBinding with default roles Developer and Operator and will add your new roles. The appropriate roles should be assigned to the user. Configuration Options Name Description Default replicaCount Number of replicas 1 deployment.strategyType Deployment strategy type Recreate deployment.readinessProbePeriodSeconds Readiness probe period seconds 10 deployment.readinessProbeInitialDelaySeconds Readiness probe initial delay 5 deployment.readinessProbeHttpGetPort Readiness probe http get port 8080 deployment.LivenessProbePeriodSeconds Liveness probe period seconds 60 deployment.LivenessProbeInitialDelaySeconds Liveness probe initial delay 60 deployment.LivenessProbeHttpGetPort Liveness probe http get port 8080 deployment.volumeMountsName Volume mount name xsk-volume deployment.volumeMountsMountPath Volume mounts mount Path /usr/local/tomcat/target/dirigible/repository deployment.volumesName Volume name xsk-volume deployment.volumespersistentVolumeClaimClaimName Volume spersistent volume claim xsk-claim persistentVolumeClaim.enabled Persistent volume claim enable true persistentVolumeClaim.Name Persistent volume claim name xsk-claim persistentVolumeClaim.accessModes Persistent volume claim access modes ReadWriteOnce persistentVolumeClaim.resourcesStorage Persistent volume claim resources storage 1Gi serviceAccount.create Create service account false serviceAccount.annotations Add annotations to sa `` serviceAccount.name Service account name `` securityContext.allowPrivilegeEscalation Allow privileged escalation false securityContext.seccompProfile.type Enable seccomp profile RuntimeDefault podSecurityContext Pod Security Context `` service.type Type of service ClusterIP service.port Port of service 8080 nameOverride Name override `` fullNameOverride Full name override `` kyma.enabled Enable Kyma `` kyma.host Kyma host `` kyma.serverMaxHttpHeaderSize Tomcat max http header size 48000 kyma.addRoles Enable add new roles `` kyma.roles Name for new roles `` kyma.roleCollections.description Set role collections description XSK Developer , XSK Operator kyma.roleCollections.name Set role collections name XSK-Developer , XSK Operator kyma.roleCollections.role-template-references Set role collections role template $XSAPPNAME.Developer , $XSAPPNAME.Operator kyma.roleTemplates.description Set role templates description Developer related roles , Operator related roles kyma.roleTemplates.name Set role templates name Developer , Operator kyma.roleTemplates.scopeReferences Set role templates scope references $XSAPPNAME.Developer , $XSAPPNAME.Operator kyma.scopes.description Set scopes description Developer scope , Operator scope kyma.scopes.name Set scopes name $XSAPPNAME.Developer , $XSAPPNAME.Operator application.image Application image `` application.homeUrl Home url for XSK `` application.imagePullPolicy Image pull policy Always application.privateDockerRegistry Paramater to enable docker registry `` application.dockerSecretName Secret name for docker registry docker-registry-secret application.dockerServer Parameter to set Docker server https://index.docker.io/v1/ application.dockerUsername User name for docker registry `` application.dockerPassword Password for docker registry `` application.dockerEmail Email for docker registry `` hana.enabled Hana enable option `` hana.secretName Hana secret name hana-secret hana.url Hana url instance `` hana.username Hana username `` hana.password Hana password `` Uninstall If you want to uninstall Helm, run: helm uninstall xsk Note If you created namespace with helm install --create-namespace namespace <your-namespace> . If you want the namespace to be deleted you need to delete you namespace manually kubectl delete namespace <your-namespace> . Setup - Kpack You can choose to build and package your XSK application from source with Helm and Kpack by following these instructions: Add the XSK kpack Helm repository: helm repo add xsk https://www.xsk.io helm repo update Deployment Prerequisites Install kpack . All in One Cluster Builder (Only) Image Builder (Only) Image (Only) helm install xsk-image xsk/xsk-kpack \\ --set install.all=true \\ --set docker.server=https://index.docker.io/v1/ \\ --set docker.username=<your-docker-username> \\ --set docker.password=<your-docker-password> \\ --set docker.email=<your-email> \\ --set image.repository=<your-repository-for-your-OCI-image> \\ --set imageBuilder.repository=<builder-image> \\ --set image.source=<your-application-source> This will build and package an OCI image for your application. helm install xsk-cluster-builder xsk/xsk-kpack \\ --set install.clusterBuilder=true \\ --set docker.server=https://index.docker.io/v1/ \\ --set docker.username=<your-docker-username> \\ --set docker.password=<your-docker-password> \\ --set docker.email=<your-email> \\ This will install a kpack ClusterStore and ClusterStack resources. helm install xsk-image-builder xsk/xsk-kpack \\ --set install.imageBuilder=true \\ --set imageBuilder.repository=<builder-image> This will install a kpack Builder resource. helm install xsk-image xsk/xsk-kpack \\ --set create.image=true \\ --set image.repository=<your-repository-for-your-OCI-image> \\ --set image.source=<your-application-source> This will build and package an OCI image for your application. Note Due to synchronization issues the All in One setup could fail. To overcome this issue you could execute the Cluster Builder (Only) , Image Builder (Only) and Image (Only) steps. Tip You can tail the logs for your image that is currently building using the Kpack CLI . kp build logs xsk-image -n default You can check your image with: kubectl -n default get image xsk-image To download and run the newly created OCI image, execute: docker run -p 8080:8080 <latest-image-with-digest> The application image that was built could be used as well in the installation of XSK with Helm , Kyma and Cloud Foundry . Note You can use for build Kyma (which is default), local and Cloud Foundry. For ClusterStack build image you can use --set clusterBuilder.buildImage and choose one of this: dirigiblelabs/buildpacks-stack-build-xsk-kyma - Kyma dirigiblelabs/buildpacks-stack-build-xsk-cf - Cloud Foundry dirigiblelabs/buildpacks-stack-build-xsk - Local For ClusterStack run image you can use --set clusterBuilder.runImage and choose one of this: dirigiblelabs/buildpacks-stack-run-xsk-kyma - Kyma dirigiblelabs/buildpacks-stack-run-xsk-cf - Cloud Foundry dirigiblelabs/buildpacks-stack-run-xsk - Local For Builder image you can use --set imageBuilder.buildpack and choose one of this: --set imageBuilder.buildpack=dirigiblelabs/buildpacks-xsk-kyma - Kyma --set imageBuilder.buildpack=dirigiblelabs/buildpacks-xsk-cf - Cloud Foundry --set imageBuilder.buildpack=dirigiblelabs/buildpacks-xsk - Local Configuration Options Name Description Default install.clusterBuilder Kpack cluster store and stack false install.imageBuilder Kpack builder false install.allInOne Option to build all false create.image Kpack create OCI image false create.namespace Create namespace default docker.server Docker server url `` docker.username Docker username `` docker.password Docker password `` docker.email Docker email `` docker.secretName Docker secret name docker-registry-secret docker.serviceAccountName Docker service account name docker-registry-service-account imageBuilder.repository Docker service account name `` imageBuilder.buildpack Docker service account name dirigiblelabs/buildpacks-xsk image.repository Docker service account name `` image.source Docker service account name `` image.serviceAccountName Docker service account name docker-registry-service-account clusterBuilder.buildImage Docker service account name dirigiblelabs/buildpacks-stack-build-xsk-kyma:latest clusterBuilder.runImage Docker service account name dirigiblelabs/buildpacks-stack-run-xskyma:latest clusterBuilder.serviceAccountName Docker service account name docker-registry-service-account Uninstall If you want to uninstall the Helm kpack chart, run: helm uninstall xsk-kpack","title":"Helm"},{"location":"setup/helm/#setup-with-helm","text":"","title":"Setup with Helm"},{"location":"setup/helm/#overview","text":"You can deploy XSK via Helm chart in a Kubernetes cluster. Prerequisites Install the Helm CLI . Make sure you have access to a Kubernetes Cluster .","title":"Overview"},{"location":"setup/helm/#setup","text":"Add the XSK Helm repository: helm repo add xsk https://www.xsk.io helm repo update Verify XSK Helm charts: From key server helm pull xsk/xsk --prov gpg --keyserver keys.openpgp.org --recv-key 734B0E32368A2283290E0B966010F454D1819484 gpg --export > ~/.gnupg/pubring.gpg helm verify xsk-<version>.tgz From github Note Use command wget for download public key instead of curl helm pull xsk/xsk --prov wget https://sap.github.io/xsk/charts/pubring.gpg -O ~/.gnupg/pubring.gpg helm verify xsk-<version>.tgz Deployment To deploy XSK, you can use the following instructions: Basic Kyma Kyma with SAP HANA database Kyma with custom roles helm install xsk xsk/xsk Accessing the XSK Instance Running this command will install XSK Deployment and Service with ClusterIP only. To access the XSK instance, execute the command that was printed in the console. Example: export POD_NAME=$(kubectl get pods --namespace default -l \"app.kubernetes.io/name=xsk,app.kubernetes.io/instance=xsk\" -o jsonpath=\"{.items[0].metadata.name}\") echo \"Visit http://127.0.0.1:8080 to use your application\" kubectl --namespace default port-forward $POD_NAME 8080:8080 Navigate to: http://127.0.0.1:8080 Log in with these username and password: dirigible / dirigible helm install xsk xsk/xsk \\ --set kyma.enabled=true \\ --set kyma.host=<kyma-host> This will install additionally an ApiRule and XSUAA ServiceInstance and ServiceBinding . The appropriate roles should be assigned to the user. helm install xsk xsk/xsk \\ --set hana.enabled=true \\ --set hana.url=<hana-url> \\ --set hana.username=<hana-username> \\ --set hana.password=<hana-password> \\ --set kyma.enabled=true \\ --set kyma.host=<kyma-apirule-host> This will install additionally an ApiRule , XSUAA ServiceInstance , ServiceBinding and HANA instance. The appropriate roles should be assigned to the user. helm install xsk xsk \\ --set kyma.enabled=true \\ --set kyma.host=<kyma-apirule-host> \\ --set kyma.addRoles=true \\ --set kyma.roles={\"<new-role>\"\\,\"<new-role>\"} This will install additionally an ApiRule and XSUAA ServiceInstance and ServiceBinding with default roles Developer and Operator and will add your new roles. The appropriate roles should be assigned to the user. Configuration Options Name Description Default replicaCount Number of replicas 1 deployment.strategyType Deployment strategy type Recreate deployment.readinessProbePeriodSeconds Readiness probe period seconds 10 deployment.readinessProbeInitialDelaySeconds Readiness probe initial delay 5 deployment.readinessProbeHttpGetPort Readiness probe http get port 8080 deployment.LivenessProbePeriodSeconds Liveness probe period seconds 60 deployment.LivenessProbeInitialDelaySeconds Liveness probe initial delay 60 deployment.LivenessProbeHttpGetPort Liveness probe http get port 8080 deployment.volumeMountsName Volume mount name xsk-volume deployment.volumeMountsMountPath Volume mounts mount Path /usr/local/tomcat/target/dirigible/repository deployment.volumesName Volume name xsk-volume deployment.volumespersistentVolumeClaimClaimName Volume spersistent volume claim xsk-claim persistentVolumeClaim.enabled Persistent volume claim enable true persistentVolumeClaim.Name Persistent volume claim name xsk-claim persistentVolumeClaim.accessModes Persistent volume claim access modes ReadWriteOnce persistentVolumeClaim.resourcesStorage Persistent volume claim resources storage 1Gi serviceAccount.create Create service account false serviceAccount.annotations Add annotations to sa `` serviceAccount.name Service account name `` securityContext.allowPrivilegeEscalation Allow privileged escalation false securityContext.seccompProfile.type Enable seccomp profile RuntimeDefault podSecurityContext Pod Security Context `` service.type Type of service ClusterIP service.port Port of service 8080 nameOverride Name override `` fullNameOverride Full name override `` kyma.enabled Enable Kyma `` kyma.host Kyma host `` kyma.serverMaxHttpHeaderSize Tomcat max http header size 48000 kyma.addRoles Enable add new roles `` kyma.roles Name for new roles `` kyma.roleCollections.description Set role collections description XSK Developer , XSK Operator kyma.roleCollections.name Set role collections name XSK-Developer , XSK Operator kyma.roleCollections.role-template-references Set role collections role template $XSAPPNAME.Developer , $XSAPPNAME.Operator kyma.roleTemplates.description Set role templates description Developer related roles , Operator related roles kyma.roleTemplates.name Set role templates name Developer , Operator kyma.roleTemplates.scopeReferences Set role templates scope references $XSAPPNAME.Developer , $XSAPPNAME.Operator kyma.scopes.description Set scopes description Developer scope , Operator scope kyma.scopes.name Set scopes name $XSAPPNAME.Developer , $XSAPPNAME.Operator application.image Application image `` application.homeUrl Home url for XSK `` application.imagePullPolicy Image pull policy Always application.privateDockerRegistry Paramater to enable docker registry `` application.dockerSecretName Secret name for docker registry docker-registry-secret application.dockerServer Parameter to set Docker server https://index.docker.io/v1/ application.dockerUsername User name for docker registry `` application.dockerPassword Password for docker registry `` application.dockerEmail Email for docker registry `` hana.enabled Hana enable option `` hana.secretName Hana secret name hana-secret hana.url Hana url instance `` hana.username Hana username `` hana.password Hana password `` Uninstall If you want to uninstall Helm, run: helm uninstall xsk Note If you created namespace with helm install --create-namespace namespace <your-namespace> . If you want the namespace to be deleted you need to delete you namespace manually kubectl delete namespace <your-namespace> .","title":"Setup"},{"location":"setup/helm/#setup-kpack","text":"You can choose to build and package your XSK application from source with Helm and Kpack by following these instructions: Add the XSK kpack Helm repository: helm repo add xsk https://www.xsk.io helm repo update Deployment Prerequisites Install kpack . All in One Cluster Builder (Only) Image Builder (Only) Image (Only) helm install xsk-image xsk/xsk-kpack \\ --set install.all=true \\ --set docker.server=https://index.docker.io/v1/ \\ --set docker.username=<your-docker-username> \\ --set docker.password=<your-docker-password> \\ --set docker.email=<your-email> \\ --set image.repository=<your-repository-for-your-OCI-image> \\ --set imageBuilder.repository=<builder-image> \\ --set image.source=<your-application-source> This will build and package an OCI image for your application. helm install xsk-cluster-builder xsk/xsk-kpack \\ --set install.clusterBuilder=true \\ --set docker.server=https://index.docker.io/v1/ \\ --set docker.username=<your-docker-username> \\ --set docker.password=<your-docker-password> \\ --set docker.email=<your-email> \\ This will install a kpack ClusterStore and ClusterStack resources. helm install xsk-image-builder xsk/xsk-kpack \\ --set install.imageBuilder=true \\ --set imageBuilder.repository=<builder-image> This will install a kpack Builder resource. helm install xsk-image xsk/xsk-kpack \\ --set create.image=true \\ --set image.repository=<your-repository-for-your-OCI-image> \\ --set image.source=<your-application-source> This will build and package an OCI image for your application. Note Due to synchronization issues the All in One setup could fail. To overcome this issue you could execute the Cluster Builder (Only) , Image Builder (Only) and Image (Only) steps. Tip You can tail the logs for your image that is currently building using the Kpack CLI . kp build logs xsk-image -n default You can check your image with: kubectl -n default get image xsk-image To download and run the newly created OCI image, execute: docker run -p 8080:8080 <latest-image-with-digest> The application image that was built could be used as well in the installation of XSK with Helm , Kyma and Cloud Foundry . Note You can use for build Kyma (which is default), local and Cloud Foundry. For ClusterStack build image you can use --set clusterBuilder.buildImage and choose one of this: dirigiblelabs/buildpacks-stack-build-xsk-kyma - Kyma dirigiblelabs/buildpacks-stack-build-xsk-cf - Cloud Foundry dirigiblelabs/buildpacks-stack-build-xsk - Local For ClusterStack run image you can use --set clusterBuilder.runImage and choose one of this: dirigiblelabs/buildpacks-stack-run-xsk-kyma - Kyma dirigiblelabs/buildpacks-stack-run-xsk-cf - Cloud Foundry dirigiblelabs/buildpacks-stack-run-xsk - Local For Builder image you can use --set imageBuilder.buildpack and choose one of this: --set imageBuilder.buildpack=dirigiblelabs/buildpacks-xsk-kyma - Kyma --set imageBuilder.buildpack=dirigiblelabs/buildpacks-xsk-cf - Cloud Foundry --set imageBuilder.buildpack=dirigiblelabs/buildpacks-xsk - Local Configuration Options Name Description Default install.clusterBuilder Kpack cluster store and stack false install.imageBuilder Kpack builder false install.allInOne Option to build all false create.image Kpack create OCI image false create.namespace Create namespace default docker.server Docker server url `` docker.username Docker username `` docker.password Docker password `` docker.email Docker email `` docker.secretName Docker secret name docker-registry-secret docker.serviceAccountName Docker service account name docker-registry-service-account imageBuilder.repository Docker service account name `` imageBuilder.buildpack Docker service account name dirigiblelabs/buildpacks-xsk image.repository Docker service account name `` image.source Docker service account name `` image.serviceAccountName Docker service account name docker-registry-service-account clusterBuilder.buildImage Docker service account name dirigiblelabs/buildpacks-stack-build-xsk-kyma:latest clusterBuilder.runImage Docker service account name dirigiblelabs/buildpacks-stack-run-xskyma:latest clusterBuilder.serviceAccountName Docker service account name docker-registry-service-account Uninstall If you want to uninstall the Helm kpack chart, run: helm uninstall xsk-kpack","title":"Setup - Kpack"},{"location":"setup/kyma/","text":"Setup in Kyma Overview You can deploy XSK in the SAP BTP 1 , Kyma environment. Prerequisites (Optional) Install kubectl . Access to an SAP BTP global account. To create an SAP BTP Trial account, navigate to the SAP BTP Trial home page . Warning At the time of writing these setup instructions (20.12.2021) , creating a HANA Cloud service instance in the SAP BTP Kyma environment was not possible, thus the setup is currently suitable only for test & demo purposes. To workaround this limitation: Create HANA Cloud service instance in Cloud Foundry , allowing traffic coming outside of the SAP BTP Cloud Foundry environment. Add HANA related environment variables in the Kubernetes Deployment (described in detail bellow) . To learn more about this limitation visit the GitHub discussion . HANA Cloud Network Visibility To update the HANA Cloud network visibility: Navigate to your SAP BTP subaccount. Go to the SAP HANA Cloud section. Find your HANA Cloud database and from the Actions dropdown select SAP HANA Cloud Central . Find your database instance, click the more details button ( ... ) and select Manage Configuration . Click the Edit button and in the Connections section make the desired changes. To apply your changes click the Save button. Steps Access the SAP BTP, Kyma environment via the SAP BTP cockpit. Create an SAP HANA Cloud secret. Prerequisites Follow the Database User setup guide. kubectl create secret generic hana-cloud-database \\ --from-literal=DIRIGIBLE_DATABASE_PROVIDER=custom \\ --from-literal=DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=HANA \\ --from-literal=DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=HANA \\ --from-literal=HANA_DRIVER=com.sap.db.jdbc.Driver \\ --from-literal=HANA_URL='jdbc:sap://<your-hana-cloud-host>/?encrypt=true&validateCertificate=false' \\ --from-literal=HANA_USERNAME=<your-hana-cloud-username> \\ --from-literal=HANA_PASSWORD=<your-hana-cloud-password> Note Before executing the command, replace the placeholders: <your-hana-cloud-host> with the HANA Cloud host URL (e.g. bc6e8e95-xxx.hanacloud.ondemand.com ) . <your-hana-cloud-username> with the HANA Cloud username (e.g. XSK_USER ) . <your-hana-cloud-password> with the HANA Cloud password. Deploy XSK: All in One Deployment (Only) APIRule (Only) apiVersion : apps/v1 kind : Deployment metadata : name : xsk namespace : default spec : replicas : 1 strategy : type : Recreate selector : matchLabels : app : xsk template : metadata : labels : app : xsk spec : containers : - name : xsk image : dirigiblelabs/xsk-kyma:latest imagePullPolicy : Always envFrom : - secretRef : name : hana-cloud-database env : - name : DIRIGIBLE_THEME_DEFAULT value : fiori - name : DIRIGIBLE_HOST value : https://xsk.<your-kyma-cluster-host> - name : SERVER_MAXHTTPHEADERSIZE value : \"48000\" volumeMounts : - name : xsk-volume mountPath : /usr/local/tomcat/target/dirigible/repository ports : - containerPort : 8080 name : xsk protocol : TCP volumes : - name : xsk-volume persistentVolumeClaim : claimName : xsk-claim --- apiVersion : v1 kind : PersistentVolumeClaim metadata : name : xsk-claim namespace : default spec : accessModes : - ReadWriteOnce resources : requests : storage : 1Gi --- apiVersion : v1 kind : Service metadata : labels : app : xsk name : xsk namespace : default spec : ports : - name : xsk port : 8080 protocol : TCP targetPort : 8080 selector : app : xsk type : ClusterIP --- apiVersion : gateway.kyma-project.io/v1alpha1 kind : APIRule metadata : name : xsk namespace : default spec : gateway : kyma-gateway.kyma-system.svc.cluster.local rules : - accessStrategies : - config : {} handler : noop methods : - GET - POST - PUT - PATCH - DELETE - HEAD path : /.* service : host : xsk.<your-kyma-cluster-host> name : xsk port : 8080 Info Appling this definition will create Deployment and PersistentVolumeClaim resoures only. To install XSK with single definition file, use the All in One section. apiVersion : apps/v1 kind : Deployment metadata : name : xsk namespace : default spec : replicas : 1 strategy : type : Recreate selector : matchLabels : app : xsk template : metadata : labels : app : xsk spec : containers : - name : xsk image : dirigiblelabs/xsk-kyma:latest imagePullPolicy : Always envFrom : - secretRef : name : hana-cloud-database env : - name : DIRIGIBLE_THEME_DEFAULT value : fiori - name : DIRIGIBLE_HOST value : https://xsk.<your-kyma-cluster-host> - name : SERVER_MAXHTTPHEADERSIZE value : \"48000\" volumeMounts : - name : xsk-volume mountPath : /usr/local/tomcat/target/dirigible/repository ports : - containerPort : 8080 name : xsk protocol : TCP volumes : - name : xsk-volume persistentVolumeClaim : claimName : xsk-claim --- apiVersion : v1 kind : Service metadata : labels : app : xsk name : xsk namespace : default spec : ports : - name : xsk port : 8080 protocol : TCP targetPort : 8080 selector : app : xsk type : ClusterIP --- apiVersion : v1 kind : PersistentVolumeClaim metadata : name : xsk-claim namespace : default spec : accessModes : - ReadWriteOnce resources : requests : storage : 1Gi Info Appling this definition will create Service and APIRule resoures only. To install XSK with single definition file, use the All in One section. apiVersion : gateway.kyma-project.io/v1alpha1 kind : APIRule metadata : name : xsk namespace : default spec : gateway : kyma-gateway.kyma-system.svc.cluster.local rules : - accessStrategies : - config : {} handler : noop methods : - GET - POST - PUT - PATCH - DELETE - HEAD path : /.* service : host : xsk.<your-kyma-cluster-host> name : xsk port : 8080 Note Copy the content into YAML file(s) (e.g. all.yaml , deployment.yaml or apirule.yaml ) . By default deployment strategy type is Recreate which will recreate deployment resources when you apply new changes. Replace the placeholders: <your-kyma-cluster-host> with your Kyma cluster host (e.g. c-xxx.kyma.xxx.ondemand.com ) . XSK versions Instead of using the latest tag (version), for production and development use cases it is recommended that you use a stable release version: You can find all released versions here . You can find all XSK Docker images and tags (versions) here . Navigate to your Kyma dashboard and select the default namespace. Click the Deploy new resource button and select the all.yaml , deployment.yaml or apirule.yaml file(s). Note Alternatively, you can use the kubectl apply -f <file-name> to deploy the desired resources (e.g. all.yaml , deployment.yaml or apirule.yaml ) . Create an XSUAA service instance: with Kyma dashboard with kubectl From the Kyma dashboard, go to Service Management \u2192 Catalog . Find the Authorization & Trust Management service. Create a new service instance. Provide the following additional parameters: { \"xsappname\" : \"xsk-xsuaa\" , \"oauth2-configuration\" :{ \"token-validity\" : 7200 , \"redirect-uris\" :[ \"https://xsk.<your-kyma-cluster-host>\" ] }, \"scopes\" :[ { \"name\" : \"$XSAPPNAME.Developer\" , \"description\" : \"Developer scope\" }, { \"name\" : \"$XSAPPNAME.Operator\" , \"description\" : \"Operator scope\" } ], \"role-templates\" :[ { \"name\" : \"Developer\" , \"description\" : \"Developer related roles\" , \"scope-references\" :[ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"Operator\" , \"description\" : \"Operator related roles\" , \"scope-references\" :[ \"$XSAPPNAME.Operator\" ] } ], \"role-collections\" :[ { \"name\" : \"XSK Developer\" , \"description\" : \"XSK Developer\" , \"role-template-references\" :[ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"XSK Operator\" , \"description\" : \"XSK Operator\" , \"role-template-references\" :[ \"$XSAPPNAME.Operator\" ] } ] } Bind the servce instance to the xsk application. Copy and paste the following content into xsuaa.yaml : apiVersion : servicecatalog.k8s.io/v1beta1 kind : ServiceInstance metadata : name : xsuaa-xsk namespace : default spec : clusterServiceClassExternalName : xsuaa clusterServiceClassRef : name : xsuaa clusterServicePlanExternalName : broker parameters : xsappname : xsk-xsuaa oauth2-configuration : redirect-uris : - https://xsk.<your-kyma-host> token-validity : 7200 role-collections : - description : XSK Developer name : XSK Developer role-template-references : - $XSAPPNAME.Developer - description : XSK Operator name : XSK Operator role-template-references : - $XSAPPNAME.Operator role-templates : - description : Developer related roles name : Developer scope-references : - $XSAPPNAME.Developer - description : Operator related roles name : Operator scope-references : - $XSAPPNAME.Operator scopes : - description : Developer scope name : $XSAPPNAME.Developer - description : Operator scope name : $XSAPPNAME.Operator --- apiVersion : servicecatalog.k8s.io/v1beta1 kind : ServiceBinding metadata : name : xsuaa-xsk-binding namespace : default spec : instanceRef : name : xsuaa-xsk parameters : {} secretName : xsuaa-xsk-binding --- apiVersion : servicecatalog.kyma-project.io/v1alpha1 kind : ServiceBindingUsage metadata : name : xsuaa-xsk-usage namespace : default spec : parameters : envPrefix : name : \"\" serviceBindingRef : name : xsuaa-xsk-binding usedBy : kind : deployment name : xsk Note Execute the following command to apply the XSUAA configuration: kubectl apply -f xsuaa.yaml or use the Deploy new resource functionality. Note Replace the <your-kyma-cluster-host> placeholder with your Kyma cluster host (e.g. c-xxxxxxx.kyma.xxx.xxx.xxx.ondemand.com ). Create an Destination service instance (optional) with Kyma dashboard with kubectl From the Kyma dashboard, go to Service Management \u2192 Catalog . Find the Destination service. Create a new service instance. Bind the servce instance to the xsk application NOTE: For Prefix for injected variables make sure to specify destination_ Copy and paste the following content into destination.yaml : apiVersion : servicecatalog.k8s.io/v1beta1 kind : ServiceInstance metadata : name : destination-xsk namespace : default spec : clusterServiceClassExternalName : destination clusterServiceClassRef : name : destination clusterServicePlanExternalName : lite parameters : {} --- apiVersion : servicecatalog.k8s.io/v1beta1 kind : ServiceBinding metadata : name : destination-xsk-binding namespace : default spec : instanceRef : name : destination-xsk parameters : {} secretName : destination-xsk-binding --- apiVersion : servicecatalog.kyma-project.io/v1alpha1 kind : ServiceBindingUsage metadata : name : destination-xsk-usage namespace : default spec : parameters : envPrefix : name : \"destination_\" serviceBindingRef : name : destination-xsk-binding usedBy : kind : deployment name : xsk Note Execute the following command to apply the Destination configuration: kubectl apply -f destination.yaml or use the Deploy new resource functionality. Assign the Developer and Operator roles. Navigate to the SAP BTP Cockpit. Log in to your subaccount. Go to Security \u2192 Users . Select your username. Choose Assign Role Collection . From the list of roles, select the XSK Developer and XSK Operator roles. Choose Assign Role Collection to update the assigned role collections. Log in. Go to https://xsk.<your-kyma-cluster-host> or navigate to Configurations \u2192 APIRules section from the Kyma dashboard. Maintenance Version Update To update the XSK version either use the kubectl or update the Deployment YAML as follows: with kubectl with Deployment YAML kubectl set image deployment/xsk xsk=dirigiblelabs/xsk-kyma:<xsk-version> spec : containers : - name : xsk image : dirigiblelabs/xsk-kyma:<xsk-version> imagePullPolicy : Always XSK versions Update the <xsk-version> placeholder with a stable release version: You can find all released versions here . You can find all XSK Docker images and tags (versions) here . Scaling The XSK Deployment could be scaled horizontally by adding/removing Pods as follows: Scale to Zero Scale Up kubectl scale deployment/xsk --replicas=0 kubectl scale deployment/xsk --replicas=<number-of-replicas> Note To learn more about application scaling in Kubernetes, see Horizontal Pod Autoscaling . Debugging To debug the XSK engine via Remote Java Debugging execute the following command: kubectl port-forward deployment/xsk 8000:8000 SAP Cloud Platform is called SAP Business Technology Platform (SAP BTP) as of 2021. \u21a9","title":"Kyma"},{"location":"setup/kyma/#setup-in-kyma","text":"","title":"Setup in Kyma"},{"location":"setup/kyma/#overview","text":"You can deploy XSK in the SAP BTP 1 , Kyma environment. Prerequisites (Optional) Install kubectl . Access to an SAP BTP global account. To create an SAP BTP Trial account, navigate to the SAP BTP Trial home page . Warning At the time of writing these setup instructions (20.12.2021) , creating a HANA Cloud service instance in the SAP BTP Kyma environment was not possible, thus the setup is currently suitable only for test & demo purposes. To workaround this limitation: Create HANA Cloud service instance in Cloud Foundry , allowing traffic coming outside of the SAP BTP Cloud Foundry environment. Add HANA related environment variables in the Kubernetes Deployment (described in detail bellow) . To learn more about this limitation visit the GitHub discussion . HANA Cloud Network Visibility To update the HANA Cloud network visibility: Navigate to your SAP BTP subaccount. Go to the SAP HANA Cloud section. Find your HANA Cloud database and from the Actions dropdown select SAP HANA Cloud Central . Find your database instance, click the more details button ( ... ) and select Manage Configuration . Click the Edit button and in the Connections section make the desired changes. To apply your changes click the Save button.","title":"Overview"},{"location":"setup/kyma/#steps","text":"Access the SAP BTP, Kyma environment via the SAP BTP cockpit. Create an SAP HANA Cloud secret. Prerequisites Follow the Database User setup guide. kubectl create secret generic hana-cloud-database \\ --from-literal=DIRIGIBLE_DATABASE_PROVIDER=custom \\ --from-literal=DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=HANA \\ --from-literal=DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=HANA \\ --from-literal=HANA_DRIVER=com.sap.db.jdbc.Driver \\ --from-literal=HANA_URL='jdbc:sap://<your-hana-cloud-host>/?encrypt=true&validateCertificate=false' \\ --from-literal=HANA_USERNAME=<your-hana-cloud-username> \\ --from-literal=HANA_PASSWORD=<your-hana-cloud-password> Note Before executing the command, replace the placeholders: <your-hana-cloud-host> with the HANA Cloud host URL (e.g. bc6e8e95-xxx.hanacloud.ondemand.com ) . <your-hana-cloud-username> with the HANA Cloud username (e.g. XSK_USER ) . <your-hana-cloud-password> with the HANA Cloud password. Deploy XSK: All in One Deployment (Only) APIRule (Only) apiVersion : apps/v1 kind : Deployment metadata : name : xsk namespace : default spec : replicas : 1 strategy : type : Recreate selector : matchLabels : app : xsk template : metadata : labels : app : xsk spec : containers : - name : xsk image : dirigiblelabs/xsk-kyma:latest imagePullPolicy : Always envFrom : - secretRef : name : hana-cloud-database env : - name : DIRIGIBLE_THEME_DEFAULT value : fiori - name : DIRIGIBLE_HOST value : https://xsk.<your-kyma-cluster-host> - name : SERVER_MAXHTTPHEADERSIZE value : \"48000\" volumeMounts : - name : xsk-volume mountPath : /usr/local/tomcat/target/dirigible/repository ports : - containerPort : 8080 name : xsk protocol : TCP volumes : - name : xsk-volume persistentVolumeClaim : claimName : xsk-claim --- apiVersion : v1 kind : PersistentVolumeClaim metadata : name : xsk-claim namespace : default spec : accessModes : - ReadWriteOnce resources : requests : storage : 1Gi --- apiVersion : v1 kind : Service metadata : labels : app : xsk name : xsk namespace : default spec : ports : - name : xsk port : 8080 protocol : TCP targetPort : 8080 selector : app : xsk type : ClusterIP --- apiVersion : gateway.kyma-project.io/v1alpha1 kind : APIRule metadata : name : xsk namespace : default spec : gateway : kyma-gateway.kyma-system.svc.cluster.local rules : - accessStrategies : - config : {} handler : noop methods : - GET - POST - PUT - PATCH - DELETE - HEAD path : /.* service : host : xsk.<your-kyma-cluster-host> name : xsk port : 8080 Info Appling this definition will create Deployment and PersistentVolumeClaim resoures only. To install XSK with single definition file, use the All in One section. apiVersion : apps/v1 kind : Deployment metadata : name : xsk namespace : default spec : replicas : 1 strategy : type : Recreate selector : matchLabels : app : xsk template : metadata : labels : app : xsk spec : containers : - name : xsk image : dirigiblelabs/xsk-kyma:latest imagePullPolicy : Always envFrom : - secretRef : name : hana-cloud-database env : - name : DIRIGIBLE_THEME_DEFAULT value : fiori - name : DIRIGIBLE_HOST value : https://xsk.<your-kyma-cluster-host> - name : SERVER_MAXHTTPHEADERSIZE value : \"48000\" volumeMounts : - name : xsk-volume mountPath : /usr/local/tomcat/target/dirigible/repository ports : - containerPort : 8080 name : xsk protocol : TCP volumes : - name : xsk-volume persistentVolumeClaim : claimName : xsk-claim --- apiVersion : v1 kind : Service metadata : labels : app : xsk name : xsk namespace : default spec : ports : - name : xsk port : 8080 protocol : TCP targetPort : 8080 selector : app : xsk type : ClusterIP --- apiVersion : v1 kind : PersistentVolumeClaim metadata : name : xsk-claim namespace : default spec : accessModes : - ReadWriteOnce resources : requests : storage : 1Gi Info Appling this definition will create Service and APIRule resoures only. To install XSK with single definition file, use the All in One section. apiVersion : gateway.kyma-project.io/v1alpha1 kind : APIRule metadata : name : xsk namespace : default spec : gateway : kyma-gateway.kyma-system.svc.cluster.local rules : - accessStrategies : - config : {} handler : noop methods : - GET - POST - PUT - PATCH - DELETE - HEAD path : /.* service : host : xsk.<your-kyma-cluster-host> name : xsk port : 8080 Note Copy the content into YAML file(s) (e.g. all.yaml , deployment.yaml or apirule.yaml ) . By default deployment strategy type is Recreate which will recreate deployment resources when you apply new changes. Replace the placeholders: <your-kyma-cluster-host> with your Kyma cluster host (e.g. c-xxx.kyma.xxx.ondemand.com ) . XSK versions Instead of using the latest tag (version), for production and development use cases it is recommended that you use a stable release version: You can find all released versions here . You can find all XSK Docker images and tags (versions) here . Navigate to your Kyma dashboard and select the default namespace. Click the Deploy new resource button and select the all.yaml , deployment.yaml or apirule.yaml file(s). Note Alternatively, you can use the kubectl apply -f <file-name> to deploy the desired resources (e.g. all.yaml , deployment.yaml or apirule.yaml ) . Create an XSUAA service instance: with Kyma dashboard with kubectl From the Kyma dashboard, go to Service Management \u2192 Catalog . Find the Authorization & Trust Management service. Create a new service instance. Provide the following additional parameters: { \"xsappname\" : \"xsk-xsuaa\" , \"oauth2-configuration\" :{ \"token-validity\" : 7200 , \"redirect-uris\" :[ \"https://xsk.<your-kyma-cluster-host>\" ] }, \"scopes\" :[ { \"name\" : \"$XSAPPNAME.Developer\" , \"description\" : \"Developer scope\" }, { \"name\" : \"$XSAPPNAME.Operator\" , \"description\" : \"Operator scope\" } ], \"role-templates\" :[ { \"name\" : \"Developer\" , \"description\" : \"Developer related roles\" , \"scope-references\" :[ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"Operator\" , \"description\" : \"Operator related roles\" , \"scope-references\" :[ \"$XSAPPNAME.Operator\" ] } ], \"role-collections\" :[ { \"name\" : \"XSK Developer\" , \"description\" : \"XSK Developer\" , \"role-template-references\" :[ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"XSK Operator\" , \"description\" : \"XSK Operator\" , \"role-template-references\" :[ \"$XSAPPNAME.Operator\" ] } ] } Bind the servce instance to the xsk application. Copy and paste the following content into xsuaa.yaml : apiVersion : servicecatalog.k8s.io/v1beta1 kind : ServiceInstance metadata : name : xsuaa-xsk namespace : default spec : clusterServiceClassExternalName : xsuaa clusterServiceClassRef : name : xsuaa clusterServicePlanExternalName : broker parameters : xsappname : xsk-xsuaa oauth2-configuration : redirect-uris : - https://xsk.<your-kyma-host> token-validity : 7200 role-collections : - description : XSK Developer name : XSK Developer role-template-references : - $XSAPPNAME.Developer - description : XSK Operator name : XSK Operator role-template-references : - $XSAPPNAME.Operator role-templates : - description : Developer related roles name : Developer scope-references : - $XSAPPNAME.Developer - description : Operator related roles name : Operator scope-references : - $XSAPPNAME.Operator scopes : - description : Developer scope name : $XSAPPNAME.Developer - description : Operator scope name : $XSAPPNAME.Operator --- apiVersion : servicecatalog.k8s.io/v1beta1 kind : ServiceBinding metadata : name : xsuaa-xsk-binding namespace : default spec : instanceRef : name : xsuaa-xsk parameters : {} secretName : xsuaa-xsk-binding --- apiVersion : servicecatalog.kyma-project.io/v1alpha1 kind : ServiceBindingUsage metadata : name : xsuaa-xsk-usage namespace : default spec : parameters : envPrefix : name : \"\" serviceBindingRef : name : xsuaa-xsk-binding usedBy : kind : deployment name : xsk Note Execute the following command to apply the XSUAA configuration: kubectl apply -f xsuaa.yaml or use the Deploy new resource functionality. Note Replace the <your-kyma-cluster-host> placeholder with your Kyma cluster host (e.g. c-xxxxxxx.kyma.xxx.xxx.xxx.ondemand.com ). Create an Destination service instance (optional) with Kyma dashboard with kubectl From the Kyma dashboard, go to Service Management \u2192 Catalog . Find the Destination service. Create a new service instance. Bind the servce instance to the xsk application NOTE: For Prefix for injected variables make sure to specify destination_ Copy and paste the following content into destination.yaml : apiVersion : servicecatalog.k8s.io/v1beta1 kind : ServiceInstance metadata : name : destination-xsk namespace : default spec : clusterServiceClassExternalName : destination clusterServiceClassRef : name : destination clusterServicePlanExternalName : lite parameters : {} --- apiVersion : servicecatalog.k8s.io/v1beta1 kind : ServiceBinding metadata : name : destination-xsk-binding namespace : default spec : instanceRef : name : destination-xsk parameters : {} secretName : destination-xsk-binding --- apiVersion : servicecatalog.kyma-project.io/v1alpha1 kind : ServiceBindingUsage metadata : name : destination-xsk-usage namespace : default spec : parameters : envPrefix : name : \"destination_\" serviceBindingRef : name : destination-xsk-binding usedBy : kind : deployment name : xsk Note Execute the following command to apply the Destination configuration: kubectl apply -f destination.yaml or use the Deploy new resource functionality. Assign the Developer and Operator roles. Navigate to the SAP BTP Cockpit. Log in to your subaccount. Go to Security \u2192 Users . Select your username. Choose Assign Role Collection . From the list of roles, select the XSK Developer and XSK Operator roles. Choose Assign Role Collection to update the assigned role collections. Log in. Go to https://xsk.<your-kyma-cluster-host> or navigate to Configurations \u2192 APIRules section from the Kyma dashboard.","title":"Steps"},{"location":"setup/kyma/#maintenance","text":"","title":"Maintenance"},{"location":"setup/kyma/#version-update","text":"To update the XSK version either use the kubectl or update the Deployment YAML as follows: with kubectl with Deployment YAML kubectl set image deployment/xsk xsk=dirigiblelabs/xsk-kyma:<xsk-version> spec : containers : - name : xsk image : dirigiblelabs/xsk-kyma:<xsk-version> imagePullPolicy : Always XSK versions Update the <xsk-version> placeholder with a stable release version: You can find all released versions here . You can find all XSK Docker images and tags (versions) here .","title":"Version Update"},{"location":"setup/kyma/#scaling","text":"The XSK Deployment could be scaled horizontally by adding/removing Pods as follows: Scale to Zero Scale Up kubectl scale deployment/xsk --replicas=0 kubectl scale deployment/xsk --replicas=<number-of-replicas> Note To learn more about application scaling in Kubernetes, see Horizontal Pod Autoscaling .","title":"Scaling"},{"location":"setup/kyma/#debugging","text":"To debug the XSK engine via Remote Java Debugging execute the following command: kubectl port-forward deployment/xsk 8000:8000 SAP Cloud Platform is called SAP Business Technology Platform (SAP BTP) as of 2021. \u21a9","title":"Debugging"},{"location":"setup/local/","text":"Local Setup Overview You can deploy XSK locally using Docker or Tomcat server. Steps Deploy as a Docker container or on Tomcat server. Docker Tomcat Prerequisites Install Docker . Pull the XSK Docker image: docker pull dirigiblelabs/xsk:latest Start the container: Run with Mounted Volume with HANA Cloud with Java Debugging Options docker run --name xsk \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest docker run --name xsk \\ -v <your-local-directory>:/usr/local/tomcat/target \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest docker run --name xsk \\ -e DIRIGIBLE_DATABASE_PROVIDER=\"custom\" \\ -e DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=\"HANA\" \\ -e DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=\"HANA\" \\ -e HANA_DRIVER=\"com.sap.db.jdbc.Driver\" \\ -e HANA_URL=\"jdbc:sap://<hanaHost>?encrypt=true&validateCertificate=false\" \\ -e HANA_USERNAME=\"<hanaUsername>\" \\ -e HANA_PASSWORD=\"<hanaPassword>\" \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest Note Replace the <hanaHost> placeholder with the HANA Cloud host that you're going to use. Replace the <hanaUsername> placeholder with the HANA Cloud username that you're going to use. Replace the <hanaPassword> placeholder with the HANA Cloud password that you're going to use. Windows For setup on Windows OS, issues may appear with the way the environment variables ( -e XXX=YYY ) are provided. Either they should be properly escaped, or they could be supplied as *.env file : docker run --name xsk \\ --env-file env-variables.env \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest docker run --name xsk \\ -e JPDA_ADDRESS=0.0.0.0:8000 \\ -e JPDA_TRANSPORT=dt_socket \\ --rm -p 8080:8080 -p 8081:8081 -p 8000:8000 \\ dirigiblelabs/xsk:latest Prerequisites Java 11 or Java 13 installed (default, required during runtime). Java 8 JRE/JDK installed (additional, required for compatability reasons). Download ROOT.war for Tomcat from: https://github.com/SAP/xsk/releases/latest Note For local test & development purposes, we recommend the server distribution. Configure the Users store under $CATALINA_HOME/conf/tomcat-users.xml : <tomcat-users> <role rolename= \"Developer\" /> <role rolename= \"Operator\" /> <role rolename= \"Everyone\" /> <user username= \"dirigible\" password= \"dirigible\" roles= \"Developer,Operator,Everyone\" /> </tomcat-users> Copy the XSK's ROOT.war to $TOMCAT/webapps folder. Provide the Java 8 JRE/JDK path. export JAVA8_HOME=<pathToJava8> Note Replace the <pathToJava8> placeholder with the actual path to your Java 8 installation (e.g. /usr/lib/jvm/java-8-openjdk-amd64/ ) . Configure connection to HANA Cloud instance. export HANA_DRIVER=com.sap.db.jdbc.Driver export HANA_URL=jdbc:sap://<hanaHost>?encrypt=true&validateCertificate=true export HANA_USERNAME=<hanaUsername> export HANA_PASSWORD=<hanaPassword> Note Replace the <hanaHost> placeholder with the HANA Cloud host that you're going to use. Replace the <hanaUsername> placeholder with the HANA Cloud username that you're going to use. Replace the <hanaPassword> placeholder with the HANA Cloud password that you're going to use. Start the Tomcat server. XSK versions Instead of using the latest tag (version), for production and development use cases it is recommended that you use a stable release version: You can find all released versions here . You can find all XSK Docker images and tags (versions) here . Open a web browser and go to: http://localhost:8080/ Note The default user name and password are dirigible/dirigible . Stop the container: docker stop dirigible","title":"Local"},{"location":"setup/local/#local-setup","text":"","title":"Local Setup"},{"location":"setup/local/#overview","text":"You can deploy XSK locally using Docker or Tomcat server.","title":"Overview"},{"location":"setup/local/#steps","text":"Deploy as a Docker container or on Tomcat server. Docker Tomcat Prerequisites Install Docker . Pull the XSK Docker image: docker pull dirigiblelabs/xsk:latest Start the container: Run with Mounted Volume with HANA Cloud with Java Debugging Options docker run --name xsk \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest docker run --name xsk \\ -v <your-local-directory>:/usr/local/tomcat/target \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest docker run --name xsk \\ -e DIRIGIBLE_DATABASE_PROVIDER=\"custom\" \\ -e DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=\"HANA\" \\ -e DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=\"HANA\" \\ -e HANA_DRIVER=\"com.sap.db.jdbc.Driver\" \\ -e HANA_URL=\"jdbc:sap://<hanaHost>?encrypt=true&validateCertificate=false\" \\ -e HANA_USERNAME=\"<hanaUsername>\" \\ -e HANA_PASSWORD=\"<hanaPassword>\" \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest Note Replace the <hanaHost> placeholder with the HANA Cloud host that you're going to use. Replace the <hanaUsername> placeholder with the HANA Cloud username that you're going to use. Replace the <hanaPassword> placeholder with the HANA Cloud password that you're going to use. Windows For setup on Windows OS, issues may appear with the way the environment variables ( -e XXX=YYY ) are provided. Either they should be properly escaped, or they could be supplied as *.env file : docker run --name xsk \\ --env-file env-variables.env \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/xsk:latest docker run --name xsk \\ -e JPDA_ADDRESS=0.0.0.0:8000 \\ -e JPDA_TRANSPORT=dt_socket \\ --rm -p 8080:8080 -p 8081:8081 -p 8000:8000 \\ dirigiblelabs/xsk:latest Prerequisites Java 11 or Java 13 installed (default, required during runtime). Java 8 JRE/JDK installed (additional, required for compatability reasons). Download ROOT.war for Tomcat from: https://github.com/SAP/xsk/releases/latest Note For local test & development purposes, we recommend the server distribution. Configure the Users store under $CATALINA_HOME/conf/tomcat-users.xml : <tomcat-users> <role rolename= \"Developer\" /> <role rolename= \"Operator\" /> <role rolename= \"Everyone\" /> <user username= \"dirigible\" password= \"dirigible\" roles= \"Developer,Operator,Everyone\" /> </tomcat-users> Copy the XSK's ROOT.war to $TOMCAT/webapps folder. Provide the Java 8 JRE/JDK path. export JAVA8_HOME=<pathToJava8> Note Replace the <pathToJava8> placeholder with the actual path to your Java 8 installation (e.g. /usr/lib/jvm/java-8-openjdk-amd64/ ) . Configure connection to HANA Cloud instance. export HANA_DRIVER=com.sap.db.jdbc.Driver export HANA_URL=jdbc:sap://<hanaHost>?encrypt=true&validateCertificate=true export HANA_USERNAME=<hanaUsername> export HANA_PASSWORD=<hanaPassword> Note Replace the <hanaHost> placeholder with the HANA Cloud host that you're going to use. Replace the <hanaUsername> placeholder with the HANA Cloud username that you're going to use. Replace the <hanaPassword> placeholder with the HANA Cloud password that you're going to use. Start the Tomcat server. XSK versions Instead of using the latest tag (version), for production and development use cases it is recommended that you use a stable release version: You can find all released versions here . You can find all XSK Docker images and tags (versions) here . Open a web browser and go to: http://localhost:8080/ Note The default user name and password are dirigible/dirigible . Stop the container: docker stop dirigible","title":"Steps"},{"location":"setup/configurations/environment-variables/","text":"Environment Variables Configuration Types Depending on the layer that defines the configuration variables, they have the following priorities: Runtime Environment Deployment Module Highest precedence: No rebuild or restart of the application is required when a configuration is changed. You can use the Configuration API to apply changes in the Runtime configuration. Second precedence: No rebuild is required when a configuration is changed. However, you should restart the application to apply the environment changes. Usually, the Environment configurations are provided during the application deployment, as part of application descriptor (e.g. Define environment variable for container in Kubernetes , or in Cloud Foundry App Manifest ) . Third precedence: Rebuild and redeployment are required. \"Default\" deployment ( ROOT.war ) configuration variables are taken from dirigible.properties properties file. You can find a sample here . Lowest precedence: Rebuild and redeployment are required. \"Default\" module (e.g. dirigible-database-custom.jar , dirigible-database-h2.jar ) configuration variables are taken from dirigible-xxx.properties properties files. You can find samples here and here . Note The precedence order means that if the there is an Environment variable with name DIRIGIBLE_TEST and Runtime variable with the same name, the Runtime variable will have higher priority and will be applied. You can find all applied configuration values under the Configurations View . Configuration Parameters HDI Environment Variables Parameter Description Default* XSK_HDI_SUPPORTED Whether the HDI API is supported by the database (e.g. HANA) true XSK_HDI_ONLY Database models to be processed only via the HDI API false XSK_SYNCHRONIZER_XSJOB_ENABLED Whether the XS Jobs synchronizer is enabled false Additional Information To find all Eclipse Dirigible related environment variables, see Environment Variables .","title":"Environment Variables"},{"location":"setup/configurations/environment-variables/#environment-variables","text":"","title":"Environment Variables"},{"location":"setup/configurations/environment-variables/#configuration-types","text":"Depending on the layer that defines the configuration variables, they have the following priorities: Runtime Environment Deployment Module Highest precedence: No rebuild or restart of the application is required when a configuration is changed. You can use the Configuration API to apply changes in the Runtime configuration. Second precedence: No rebuild is required when a configuration is changed. However, you should restart the application to apply the environment changes. Usually, the Environment configurations are provided during the application deployment, as part of application descriptor (e.g. Define environment variable for container in Kubernetes , or in Cloud Foundry App Manifest ) . Third precedence: Rebuild and redeployment are required. \"Default\" deployment ( ROOT.war ) configuration variables are taken from dirigible.properties properties file. You can find a sample here . Lowest precedence: Rebuild and redeployment are required. \"Default\" module (e.g. dirigible-database-custom.jar , dirigible-database-h2.jar ) configuration variables are taken from dirigible-xxx.properties properties files. You can find samples here and here . Note The precedence order means that if the there is an Environment variable with name DIRIGIBLE_TEST and Runtime variable with the same name, the Runtime variable will have higher priority and will be applied. You can find all applied configuration values under the Configurations View .","title":"Configuration Types"},{"location":"setup/configurations/environment-variables/#configuration-parameters","text":"","title":"Configuration Parameters"},{"location":"setup/configurations/environment-variables/#hdi-environment-variables","text":"Parameter Description Default* XSK_HDI_SUPPORTED Whether the HDI API is supported by the database (e.g. HANA) true XSK_HDI_ONLY Database models to be processed only via the HDI API false XSK_SYNCHRONIZER_XSJOB_ENABLED Whether the XS Jobs synchronizer is enabled false Additional Information To find all Eclipse Dirigible related environment variables, see Environment Variables .","title":"HDI Environment Variables"},{"location":"setup/configurations/hdi/","text":"HDI - HANA Deployment Infrastructure SAP HANA Deployment Infrastructure (HDI) is a service that enables you to deploy database development artifacts to so-called containers. HDI is supported in XSK via the *.hdi and *.hdiconfig files. SAP Help Portal For more information, see SAP HANA Deployment Infrastructure Reference (SAP HANA Cloud) . Overview To support the deployment of database development artifacts via HDI, create *.hdi and *.hdiconfig files in your project: *.hdi *.hdiconfig { \"configuration\" : \"/hdi-ext/config.hdiconfig\" , \"users\" : [ \"XSK_SAMPLES_HDI_EXT\" ], \"group\" : \"XSK_HDI_EXT_GROUP\" , \"container\" : \"XSK_HDI_EXT\" , \"deploy\" : [ \"/hdi-ext/Customers.hdbsynonym\" , \"/hdi-ext/CustomersCalcView.hdbcalculationview\" ], \"undeploy\" : [] } { \"file_suffixes\" :{ \"hdbsynonym\" :{ \"plugin_name\" : \"com.sap.hana.di.synonym\" }, \"hdbpublicsynonym\" :{ \"plugin_name\" : \"com.sap.hana.di.publicsynonym\" }, \"hdbcalculationview\" :{ \"plugin_name\" : \"com.sap.hana.di.calculationview\" } } } Maintenance Drop HDI Container Grant HDI Privileges CREATE LOCAL TEMPORARY COLUMN TABLE # DROP_CONTAINER_PARAMETERS LIKE _SYS_DI . TT_PARAMETERS ; INSERT INTO # DROP_CONTAINER_PARAMETERS ( KEY , VALUE ) VALUES ( 'ignore_work' , 'true' ); INSERT INTO # DROP_CONTAINER_PARAMETERS ( KEY , VALUE ) VALUES ( 'ignore_deployed' , 'true' ); CALL _SYS_DI #< HDI - Container - Group > . DROP_CONTAINER ( '<HDI-Container-Name>' , # DROP_CONTAINER_PARAMETERS , ? , ? , ? ); DROP TABLE # DROP_CONTAINER_PARAMETERS ; Note Replace the following placeholders: <HDI-Container-Group> - the HDI Container Group <HDI-Container-Name> - the HDI Container Name For more information, see: Drop a Container To grant HDI priviliges to HANA database user, execute the following script: CREATE LOCAL TEMPORARY TABLE # PRIVILEGES LIKE _SYS_DI . TT_API_PRIVILEGES ; INSERT INTO # PRIVILEGES ( PRINCIPAL_NAME , PRIVILEGE_NAME , OBJECT_NAME ) SELECT '<HANA-Username>' , PRIVILEGE_NAME , OBJECT_NAME FROM _SYS_DI . T_DEFAULT_DI_ADMIN_PRIVILEGES ; CALL _SYS_DI . GRANT_CONTAINER_GROUP_API_PRIVILEGES ( '_SYS_DI' , # PRIVILEGES , _SYS_DI . T_NO_PARAMETERS , ? , ? , ? ); DROP TABLE # PRIVILEGES ; Note Replace the <HANA-Username> placeholder with the HANA database user, used for the migration. HDI Plugins List of HDI supported database development artifacts: Application Time-Period Table Plug-in (.hdbapplicationtime) \"hdbapplicationtime\" : { \"plugin_name\" : \"com.sap.hana.di.applicationtime\" } Analytic Privileges (.hdbanalyticprivilege) \"hdbanalyticprivilege\" : { \"plugin_name\" : \"com.sap.hana.di.analyticprivilege\" } Calculation Views (.hdbcalculationview) \"hdbcalculationview\" : { \"plugin_name\" : \"com.sap.hana.di.calculationview\" } Constraints (.hdbconstraint) \"hdbconstraint\" : { \"plugin_name\" : \"com.sap.hana.di.constraint\" } Copy Only (.txt) \"txt\" : { \"plugin_name\" : \"com.sap.hana.di.copyonly\" } Document Store Collections (.hdbcollection) \"hdbcollection\" : { \"plugin_name\" : \"com.sap.hana.di.collection\" } Document Store Collection Index (.hdbcollectionindex) Flowgraph (.hdbflowgraph) \"hdbflowgraph\" : { \"plugin_name\" : \"com.sap.hana.di.flowgraph\" } Functions (.hdbfunction) \"hdbfunction\" : { \"plugin_name\" : \"com.sap.hana.di.function\" } Graph Workspaces (.hdbgraphworkspace) \"hdbgraphworkspace\" : { \"plugin_name\" : \"com.sap.hana.di.graphworkspace\" } Indexes (.hdbindex) \"hdbindex\" : { \"plugin_name\" : \"com.sap.hana.di.index\" } Libraries (.hdblibrary) \"hdblibrary\" : { \"plugin_name\" : \"com.sap.hana.di.library\" } Logical Schema Definition (.hdblogicalschema) \"hdblogicalschema\" : { \"plugin_name\" : \"com.sap.hana.di.logicalschema\" } Migration Tables (.hdbmigrationtable) \"hdbmigrationtable\" : { \"plugin_name\" : \"com.sap.hana.di.table.migration\" } Procedures (.hdbprocedure) \"hdbprocedure\" : { \"plugin_name\" : \"com.sap.hana.di.procedure\" } Projection Views (.hdbprojectionview) \"hdbprojectionview\" : { \"plugin_name\" : \"com.sap.hana.di.projectionview\" }, \"hdbprojectionviewconfig\" : { \"plugin_name\" : \"com.sap.hana.di.projectionview.config\" } Public Synonym (.hdbpublicsynonym) \"hdbpublicsynonym\" : { \"plugin_name\" : \"com.sap.hana.di.publicsynonym\" } Replication Task (.hdbreptask) \"hdbreptask\" : { \"plugin_name\" : \"com.sap.hana.di.reptask\" } Result Cache (.hdbresultcache) \"hdbresultcache\" : { \"plugin_name\" : \"com.sap.hana.di.resultcache\" } Roles (.hdbrole) \"hdbrole\" : { \"plugin_name\" : \"com.sap.hana.di.role\" }, \"hdbroleconfig\" : { \"plugin_name\" : \"com.sap.hana.di.role.config\" } Search Rule Set (.hdbsearchruleset) \"hdbsearchruleset\" : { \"plugin_name\" : \"com.sap.hana.di.searchruleset\" } Sequence (.hdbsequence) \"hdbsequence\" : { \"plugin_name\" : \"com.sap.hana.di.sequence\" } SQL Views (.hdbview) \"hdbview\" : { \"plugin_name\" : \"com.sap.hana.di.view\" } Statistics (.hdbstatistics) \"hdbstatistics\" : { \"plugin_name\" : \"com.sap.hana.di.statistics\" } Structured Privilege (.hdbstructuredprivilege) \"hdbstructuredprivilege\" : { \"plugin_name\" : \"com.sap.hana.di.structuredprivilege\" } Synonyms (.hdbsynonym and .hdbsynonymconfig) \"hdbsynonym\" : { \"plugin_name\" : \"com.sap.hana.di.synonym\" }, \"hdbsynonymconfig\" : { \"plugin_name\" : \"com.sap.hana.di.synonym.config\" } System Versioning Table (.hdbsystemversioning) \"hdbsystemversioning\" : { \"plugin_name\" : \"com.sap.hana.di.systemversioning\" } Tables (.hdbtable and .hdbdropcreatetable) \"hdbtable\" : { \"plugin_name\" : \"com.sap.hana.di.table\" }, \"hdbdropcreatetable\" : { \"plugin_name\" : \"com.sap.hana.di.dropcreatetable\" } Table Data (.hdbtabledata) \"hdbtabledata\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" }, \"csv\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" } Table Data Properties (.properties) \"properties\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" }, \"tags\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" } Table Type (.hdbtabletype) \"hdbtabletype\" : { \"plugin_name\" : \"com.sap.hana.di.tabletype\" } Triggers (.hdbtrigger) \"hdbtrigger\" : { \"plugin_name\" : \"com.sap.hana.di.trigger\" } Virtual Functions (.hdbvirtualfunction) \"hdbvirtualfunction\" : { \"plugin_name\" : \"com.sap.hana.di.virtualfunction\" } \"hdbvirtualfunctionconfig\" : { \"plugin_name\" : \"com.sap.hana.di.virtualfunction.config\" } Virtual Procedures (.hdbvirtualprocedure) \"hdbvirtualprocedure\" : { \"plugin_name\" : \"com.sap.hana.di.virtualprocedure\" }, \"hdbprojectionviewconfig\" : { \"plugin_name\" : \"com.sap.hana.di.virtualprocedure.config\" } Virtual Tables (.hdbvirtualtable) \"hdbvirtualtable\" : { \"plugin_name\" : \"com.sap.hana.di.virtualtable\" }, \"hdbvirtualtableconfig\" : { \"plugin_name\" : \"com.sap.hana.di.virtualtable.config\" } Virtual Packages (.hdbvirtualpackage) \"hdbvirtualpackagehadoop\" : { \"plugin_name\" : \"com.sap.hana.di.virtualpackage.hadoop\" }, \"hdbvirtualpackagesparksql\" : { \"plugin_name\" : \"com.sap.hana.di.virtualpackage.sparksql\" }","title":"HDI"},{"location":"setup/configurations/hdi/#hdi-hana-deployment-infrastructure","text":"SAP HANA Deployment Infrastructure (HDI) is a service that enables you to deploy database development artifacts to so-called containers. HDI is supported in XSK via the *.hdi and *.hdiconfig files. SAP Help Portal For more information, see SAP HANA Deployment Infrastructure Reference (SAP HANA Cloud) .","title":"HDI - HANA Deployment Infrastructure"},{"location":"setup/configurations/hdi/#overview","text":"To support the deployment of database development artifacts via HDI, create *.hdi and *.hdiconfig files in your project: *.hdi *.hdiconfig { \"configuration\" : \"/hdi-ext/config.hdiconfig\" , \"users\" : [ \"XSK_SAMPLES_HDI_EXT\" ], \"group\" : \"XSK_HDI_EXT_GROUP\" , \"container\" : \"XSK_HDI_EXT\" , \"deploy\" : [ \"/hdi-ext/Customers.hdbsynonym\" , \"/hdi-ext/CustomersCalcView.hdbcalculationview\" ], \"undeploy\" : [] } { \"file_suffixes\" :{ \"hdbsynonym\" :{ \"plugin_name\" : \"com.sap.hana.di.synonym\" }, \"hdbpublicsynonym\" :{ \"plugin_name\" : \"com.sap.hana.di.publicsynonym\" }, \"hdbcalculationview\" :{ \"plugin_name\" : \"com.sap.hana.di.calculationview\" } } }","title":"Overview"},{"location":"setup/configurations/hdi/#maintenance","text":"Drop HDI Container Grant HDI Privileges CREATE LOCAL TEMPORARY COLUMN TABLE # DROP_CONTAINER_PARAMETERS LIKE _SYS_DI . TT_PARAMETERS ; INSERT INTO # DROP_CONTAINER_PARAMETERS ( KEY , VALUE ) VALUES ( 'ignore_work' , 'true' ); INSERT INTO # DROP_CONTAINER_PARAMETERS ( KEY , VALUE ) VALUES ( 'ignore_deployed' , 'true' ); CALL _SYS_DI #< HDI - Container - Group > . DROP_CONTAINER ( '<HDI-Container-Name>' , # DROP_CONTAINER_PARAMETERS , ? , ? , ? ); DROP TABLE # DROP_CONTAINER_PARAMETERS ; Note Replace the following placeholders: <HDI-Container-Group> - the HDI Container Group <HDI-Container-Name> - the HDI Container Name For more information, see: Drop a Container To grant HDI priviliges to HANA database user, execute the following script: CREATE LOCAL TEMPORARY TABLE # PRIVILEGES LIKE _SYS_DI . TT_API_PRIVILEGES ; INSERT INTO # PRIVILEGES ( PRINCIPAL_NAME , PRIVILEGE_NAME , OBJECT_NAME ) SELECT '<HANA-Username>' , PRIVILEGE_NAME , OBJECT_NAME FROM _SYS_DI . T_DEFAULT_DI_ADMIN_PRIVILEGES ; CALL _SYS_DI . GRANT_CONTAINER_GROUP_API_PRIVILEGES ( '_SYS_DI' , # PRIVILEGES , _SYS_DI . T_NO_PARAMETERS , ? , ? , ? ); DROP TABLE # PRIVILEGES ; Note Replace the <HANA-Username> placeholder with the HANA database user, used for the migration.","title":"Maintenance"},{"location":"setup/configurations/hdi/#hdi-plugins","text":"List of HDI supported database development artifacts:","title":"HDI Plugins"},{"location":"setup/configurations/hdi/#application-time-period-table-plug-in-hdbapplicationtime","text":"\"hdbapplicationtime\" : { \"plugin_name\" : \"com.sap.hana.di.applicationtime\" }","title":"Application Time-Period Table Plug-in (.hdbapplicationtime)"},{"location":"setup/configurations/hdi/#analytic-privileges-hdbanalyticprivilege","text":"\"hdbanalyticprivilege\" : { \"plugin_name\" : \"com.sap.hana.di.analyticprivilege\" }","title":"Analytic Privileges (.hdbanalyticprivilege)"},{"location":"setup/configurations/hdi/#calculation-views-hdbcalculationview","text":"\"hdbcalculationview\" : { \"plugin_name\" : \"com.sap.hana.di.calculationview\" }","title":"Calculation Views (.hdbcalculationview)"},{"location":"setup/configurations/hdi/#constraints-hdbconstraint","text":"\"hdbconstraint\" : { \"plugin_name\" : \"com.sap.hana.di.constraint\" }","title":"Constraints (.hdbconstraint)"},{"location":"setup/configurations/hdi/#copy-only-txt","text":"\"txt\" : { \"plugin_name\" : \"com.sap.hana.di.copyonly\" }","title":"Copy Only (.txt)"},{"location":"setup/configurations/hdi/#document-store-collections-hdbcollection","text":"\"hdbcollection\" : { \"plugin_name\" : \"com.sap.hana.di.collection\" }","title":"Document Store Collections (.hdbcollection)"},{"location":"setup/configurations/hdi/#document-store-collection-index-hdbcollectionindex","text":"","title":"Document Store Collection Index (.hdbcollectionindex)"},{"location":"setup/configurations/hdi/#flowgraph-hdbflowgraph","text":"\"hdbflowgraph\" : { \"plugin_name\" : \"com.sap.hana.di.flowgraph\" }","title":"Flowgraph (.hdbflowgraph)"},{"location":"setup/configurations/hdi/#functions-hdbfunction","text":"\"hdbfunction\" : { \"plugin_name\" : \"com.sap.hana.di.function\" }","title":"Functions (.hdbfunction)"},{"location":"setup/configurations/hdi/#graph-workspaces-hdbgraphworkspace","text":"\"hdbgraphworkspace\" : { \"plugin_name\" : \"com.sap.hana.di.graphworkspace\" }","title":"Graph Workspaces (.hdbgraphworkspace)"},{"location":"setup/configurations/hdi/#indexes-hdbindex","text":"\"hdbindex\" : { \"plugin_name\" : \"com.sap.hana.di.index\" }","title":"Indexes (.hdbindex)"},{"location":"setup/configurations/hdi/#libraries-hdblibrary","text":"\"hdblibrary\" : { \"plugin_name\" : \"com.sap.hana.di.library\" }","title":"Libraries (.hdblibrary)"},{"location":"setup/configurations/hdi/#logical-schema-definition-hdblogicalschema","text":"\"hdblogicalschema\" : { \"plugin_name\" : \"com.sap.hana.di.logicalschema\" }","title":"Logical Schema Definition (.hdblogicalschema)"},{"location":"setup/configurations/hdi/#migration-tables-hdbmigrationtable","text":"\"hdbmigrationtable\" : { \"plugin_name\" : \"com.sap.hana.di.table.migration\" }","title":"Migration Tables (.hdbmigrationtable)"},{"location":"setup/configurations/hdi/#procedures-hdbprocedure","text":"\"hdbprocedure\" : { \"plugin_name\" : \"com.sap.hana.di.procedure\" }","title":"Procedures (.hdbprocedure)"},{"location":"setup/configurations/hdi/#projection-views-hdbprojectionview","text":"\"hdbprojectionview\" : { \"plugin_name\" : \"com.sap.hana.di.projectionview\" }, \"hdbprojectionviewconfig\" : { \"plugin_name\" : \"com.sap.hana.di.projectionview.config\" }","title":"Projection Views (.hdbprojectionview)"},{"location":"setup/configurations/hdi/#public-synonym-hdbpublicsynonym","text":"\"hdbpublicsynonym\" : { \"plugin_name\" : \"com.sap.hana.di.publicsynonym\" }","title":"Public Synonym (.hdbpublicsynonym)"},{"location":"setup/configurations/hdi/#replication-task-hdbreptask","text":"\"hdbreptask\" : { \"plugin_name\" : \"com.sap.hana.di.reptask\" }","title":"Replication Task (.hdbreptask)"},{"location":"setup/configurations/hdi/#result-cache-hdbresultcache","text":"\"hdbresultcache\" : { \"plugin_name\" : \"com.sap.hana.di.resultcache\" }","title":"Result Cache (.hdbresultcache)"},{"location":"setup/configurations/hdi/#roles-hdbrole","text":"\"hdbrole\" : { \"plugin_name\" : \"com.sap.hana.di.role\" }, \"hdbroleconfig\" : { \"plugin_name\" : \"com.sap.hana.di.role.config\" }","title":"Roles (.hdbrole)"},{"location":"setup/configurations/hdi/#search-rule-set-hdbsearchruleset","text":"\"hdbsearchruleset\" : { \"plugin_name\" : \"com.sap.hana.di.searchruleset\" }","title":"Search Rule Set (.hdbsearchruleset)"},{"location":"setup/configurations/hdi/#sequence-hdbsequence","text":"\"hdbsequence\" : { \"plugin_name\" : \"com.sap.hana.di.sequence\" }","title":"Sequence (.hdbsequence)"},{"location":"setup/configurations/hdi/#sql-views-hdbview","text":"\"hdbview\" : { \"plugin_name\" : \"com.sap.hana.di.view\" }","title":"SQL Views (.hdbview)"},{"location":"setup/configurations/hdi/#statistics-hdbstatistics","text":"\"hdbstatistics\" : { \"plugin_name\" : \"com.sap.hana.di.statistics\" }","title":"Statistics (.hdbstatistics)"},{"location":"setup/configurations/hdi/#structured-privilege-hdbstructuredprivilege","text":"\"hdbstructuredprivilege\" : { \"plugin_name\" : \"com.sap.hana.di.structuredprivilege\" }","title":"Structured Privilege (.hdbstructuredprivilege)"},{"location":"setup/configurations/hdi/#synonyms-hdbsynonym-and-hdbsynonymconfig","text":"\"hdbsynonym\" : { \"plugin_name\" : \"com.sap.hana.di.synonym\" }, \"hdbsynonymconfig\" : { \"plugin_name\" : \"com.sap.hana.di.synonym.config\" }","title":"Synonyms (.hdbsynonym and .hdbsynonymconfig)"},{"location":"setup/configurations/hdi/#system-versioning-table-hdbsystemversioning","text":"\"hdbsystemversioning\" : { \"plugin_name\" : \"com.sap.hana.di.systemversioning\" }","title":"System Versioning Table (.hdbsystemversioning)"},{"location":"setup/configurations/hdi/#tables-hdbtable-and-hdbdropcreatetable","text":"\"hdbtable\" : { \"plugin_name\" : \"com.sap.hana.di.table\" }, \"hdbdropcreatetable\" : { \"plugin_name\" : \"com.sap.hana.di.dropcreatetable\" }","title":"Tables (.hdbtable and .hdbdropcreatetable)"},{"location":"setup/configurations/hdi/#table-data-hdbtabledata","text":"\"hdbtabledata\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" }, \"csv\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" }","title":"Table Data (.hdbtabledata)"},{"location":"setup/configurations/hdi/#table-data-properties-properties","text":"\"properties\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" }, \"tags\" : { \"plugin_name\" : \"com.sap.hana.di.tabledata.properties\" }","title":"Table Data Properties (.properties)"},{"location":"setup/configurations/hdi/#table-type-hdbtabletype","text":"\"hdbtabletype\" : { \"plugin_name\" : \"com.sap.hana.di.tabletype\" }","title":"Table Type (.hdbtabletype)"},{"location":"setup/configurations/hdi/#triggers-hdbtrigger","text":"\"hdbtrigger\" : { \"plugin_name\" : \"com.sap.hana.di.trigger\" }","title":"Triggers (.hdbtrigger)"},{"location":"setup/configurations/hdi/#virtual-functions-hdbvirtualfunction","text":"\"hdbvirtualfunction\" : { \"plugin_name\" : \"com.sap.hana.di.virtualfunction\" } \"hdbvirtualfunctionconfig\" : { \"plugin_name\" : \"com.sap.hana.di.virtualfunction.config\" }","title":"Virtual Functions (.hdbvirtualfunction)"},{"location":"setup/configurations/hdi/#virtual-procedures-hdbvirtualprocedure","text":"\"hdbvirtualprocedure\" : { \"plugin_name\" : \"com.sap.hana.di.virtualprocedure\" }, \"hdbprojectionviewconfig\" : { \"plugin_name\" : \"com.sap.hana.di.virtualprocedure.config\" }","title":"Virtual Procedures (.hdbvirtualprocedure)"},{"location":"setup/configurations/hdi/#virtual-tables-hdbvirtualtable","text":"\"hdbvirtualtable\" : { \"plugin_name\" : \"com.sap.hana.di.virtualtable\" }, \"hdbvirtualtableconfig\" : { \"plugin_name\" : \"com.sap.hana.di.virtualtable.config\" }","title":"Virtual Tables (.hdbvirtualtable)"},{"location":"setup/configurations/hdi/#virtual-packages-hdbvirtualpackage","text":"\"hdbvirtualpackagehadoop\" : { \"plugin_name\" : \"com.sap.hana.di.virtualpackage.hadoop\" }, \"hdbvirtualpackagesparksql\" : { \"plugin_name\" : \"com.sap.hana.di.virtualpackage.sparksql\" }","title":"Virtual Packages (.hdbvirtualpackage)"},{"location":"setup/prerequisites/","text":"To start using project XSK, first you need to meet several requirements. Once these requirements are met, you can choose to set up XSK in four different ways. Before You Start Before you start the setup process, you need to make sure that: You have created a delivery unit. To learn how to create a new delivery unit using SAP HANA Application Lifecycle Management, see Create Delivery Units . You have an SAP HANA Cloud database user. To learn how to create a new SAP HANA Cloud database user, see SAP HANA Cloud Database User . Setup Options You can set up project XSK in four different ways: You can deploy it locally using Docker or a Tomcat server. See Local . You can deploy it in the SAP BTP, Cloud Foundry environment. See Cloud Foundry . You can deploy it in the SAP BTP, Kyma environment. See Kyma . You can deploy it via Helm chart in a Kubernetes cluster. See Helm .","title":"Prerequisites"},{"location":"setup/prerequisites/#before-you-start","text":"Before you start the setup process, you need to make sure that: You have created a delivery unit. To learn how to create a new delivery unit using SAP HANA Application Lifecycle Management, see Create Delivery Units . You have an SAP HANA Cloud database user. To learn how to create a new SAP HANA Cloud database user, see SAP HANA Cloud Database User .","title":"Before You Start"},{"location":"setup/prerequisites/#setup-options","text":"You can set up project XSK in four different ways: You can deploy it locally using Docker or a Tomcat server. See Local . You can deploy it in the SAP BTP, Cloud Foundry environment. See Cloud Foundry . You can deploy it in the SAP BTP, Kyma environment. See Kyma . You can deploy it via Helm chart in a Kubernetes cluster. See Helm .","title":"Setup Options"},{"location":"setup/prerequisites/database-user/","text":"SAP HANA (Cloud) Database User Overview To perform a successful migration, you need database users in HANA on Neo and HANA Cloud. We recommend that you create a new database user instead of the default ones ( SYSTEM and DBADMIN respectively). Steps SAP HANA on Neo To create a new database user in SAP HANA on Neo, execute the following statement: CREATE USER < XSK - USERNAME > PASSWORD < XSK - PASSWORD > NO FORCE_FIRST_PASSWORD_CHANGE ; GRANT SELECT ON _SYS_REPO . DELIVERY_UNITS TO < XSK - USERNAME > ; GRANT SELECT ON _SYS_REPO . ACTIVE_OBJECT TO < XSK - USERNAME > ; GRANT CATALOG READ TO < XSK - USERNAME > ; GRANT EXPORT TO < XSK - USERNAME > ; GRANT EXECUTE ON REPOSITORY_REST to < XSK - USERNAME > ; GRANT REPO . READ ON \".REPO_PACKAGE_ROOT\" TO < XSK - USERNAME > ; SAP HANA Cloud To create a new database user in SAP HANA Cloud, go through the following steps: SAP HANA Cockpit SQL Console Navigate to the SAP HANA Cockpit for your SAP HANA Cloud instance. Switch to the User Management application. Choose the + button and then Create User . Provide the user details. Note Switch the Force Password Change on Next Logon option to No , so that the provided password for the migration database user won't be changed and could be used in the XSK setup steps. Switch to the Privilege Assignment application. Search for the newly created database user. From the System Privileges tab, choose Edit and then Add . Search for the CREATE SCHEMA privilege. Save the changes. From the Object Privileges tab, choose Edit , then Add , and add the following object privileges: Object Schema Privilege CREATE_CONTAINER_GROUP _SYS_DI EXECUTE GRANT_CONTAINER_GROUP_API_PRIVILEGES _SYS_DI EXECUTE TT_API_PRIVILEGES _SYS_DI SELECT TT_FILESFOLDERS _SYS_DI SELECT TT_FILESFOLDERS_CONTENT _SYS_DI SELECT TT_FILESFOLDERS_PARAMETERS _SYS_DI SELECT TT_SCHEMA_PRIVILEGES _SYS_DI SELECT T_DEFAULT_CONTAINER_ADMIN_PRIVILEGES _SYS_DI SELECT T_DEFAULT_CONTAINER_GROUP_ADMIN_PRIVILEGES _SYS_DI SELECT T_DEFAULT_DI_ADMIN_PRIVILEGES _SYS_DI SELECT T_NO_PARAMETERS _SYS_DI SELECT Save the changes. Create the user: CREATE USER < XSK - USERNAME > PASSWORD < XSK - PASSWORD > NO FORCE_FIRST_PASSWORD_CHANGE SET USERGROUP DEFAULT ; Note Replace the <XSK-USERNAME> placeholder with the username and <XSK-PASSWORD> with the password. Grant CREATE SCHEMA privileges: GRANT CREATE SCHEMA TO < XSK - USERNAME > ; Note Replace the <XSK-USERNAME> placeholder with the username. Grant HDI administrator privileges: CREATE LOCAL TEMPORARY TABLE # PRIVILEGES LIKE _SYS_DI . TT_API_PRIVILEGES ; INSERT INTO # PRIVILEGES ( PRINCIPAL_NAME , PRIVILEGE_NAME , OBJECT_NAME ) SELECT '<XSK-USERNAME>' , PRIVILEGE_NAME , OBJECT_NAME FROM _SYS_DI . T_DEFAULT_DI_ADMIN_PRIVILEGES ; CALL _SYS_DI . GRANT_CONTAINER_GROUP_API_PRIVILEGES ( '_SYS_DI' , # PRIVILEGES , _SYS_DI . T_NO_PARAMETERS , ? , ? , ? ); DROP TABLE # PRIVILEGES ; Note Replace the <XSK-USERNAME> placeholder with the username.","title":"Database User"},{"location":"setup/prerequisites/database-user/#sap-hana-cloud-database-user","text":"","title":"SAP HANA (Cloud) Database User"},{"location":"setup/prerequisites/database-user/#overview","text":"To perform a successful migration, you need database users in HANA on Neo and HANA Cloud. We recommend that you create a new database user instead of the default ones ( SYSTEM and DBADMIN respectively).","title":"Overview"},{"location":"setup/prerequisites/database-user/#steps","text":"","title":"Steps"},{"location":"setup/prerequisites/database-user/#sap-hana-on-neo","text":"To create a new database user in SAP HANA on Neo, execute the following statement: CREATE USER < XSK - USERNAME > PASSWORD < XSK - PASSWORD > NO FORCE_FIRST_PASSWORD_CHANGE ; GRANT SELECT ON _SYS_REPO . DELIVERY_UNITS TO < XSK - USERNAME > ; GRANT SELECT ON _SYS_REPO . ACTIVE_OBJECT TO < XSK - USERNAME > ; GRANT CATALOG READ TO < XSK - USERNAME > ; GRANT EXPORT TO < XSK - USERNAME > ; GRANT EXECUTE ON REPOSITORY_REST to < XSK - USERNAME > ; GRANT REPO . READ ON \".REPO_PACKAGE_ROOT\" TO < XSK - USERNAME > ;","title":"SAP HANA on Neo"},{"location":"setup/prerequisites/database-user/#sap-hana-cloud","text":"To create a new database user in SAP HANA Cloud, go through the following steps: SAP HANA Cockpit SQL Console Navigate to the SAP HANA Cockpit for your SAP HANA Cloud instance. Switch to the User Management application. Choose the + button and then Create User . Provide the user details. Note Switch the Force Password Change on Next Logon option to No , so that the provided password for the migration database user won't be changed and could be used in the XSK setup steps. Switch to the Privilege Assignment application. Search for the newly created database user. From the System Privileges tab, choose Edit and then Add . Search for the CREATE SCHEMA privilege. Save the changes. From the Object Privileges tab, choose Edit , then Add , and add the following object privileges: Object Schema Privilege CREATE_CONTAINER_GROUP _SYS_DI EXECUTE GRANT_CONTAINER_GROUP_API_PRIVILEGES _SYS_DI EXECUTE TT_API_PRIVILEGES _SYS_DI SELECT TT_FILESFOLDERS _SYS_DI SELECT TT_FILESFOLDERS_CONTENT _SYS_DI SELECT TT_FILESFOLDERS_PARAMETERS _SYS_DI SELECT TT_SCHEMA_PRIVILEGES _SYS_DI SELECT T_DEFAULT_CONTAINER_ADMIN_PRIVILEGES _SYS_DI SELECT T_DEFAULT_CONTAINER_GROUP_ADMIN_PRIVILEGES _SYS_DI SELECT T_DEFAULT_DI_ADMIN_PRIVILEGES _SYS_DI SELECT T_NO_PARAMETERS _SYS_DI SELECT Save the changes. Create the user: CREATE USER < XSK - USERNAME > PASSWORD < XSK - PASSWORD > NO FORCE_FIRST_PASSWORD_CHANGE SET USERGROUP DEFAULT ; Note Replace the <XSK-USERNAME> placeholder with the username and <XSK-PASSWORD> with the password. Grant CREATE SCHEMA privileges: GRANT CREATE SCHEMA TO < XSK - USERNAME > ; Note Replace the <XSK-USERNAME> placeholder with the username. Grant HDI administrator privileges: CREATE LOCAL TEMPORARY TABLE # PRIVILEGES LIKE _SYS_DI . TT_API_PRIVILEGES ; INSERT INTO # PRIVILEGES ( PRINCIPAL_NAME , PRIVILEGE_NAME , OBJECT_NAME ) SELECT '<XSK-USERNAME>' , PRIVILEGE_NAME , OBJECT_NAME FROM _SYS_DI . T_DEFAULT_DI_ADMIN_PRIVILEGES ; CALL _SYS_DI . GRANT_CONTAINER_GROUP_API_PRIVILEGES ( '_SYS_DI' , # PRIVILEGES , _SYS_DI . T_NO_PARAMETERS , ? , ? , ? ); DROP TABLE # PRIVILEGES ; Note Replace the <XSK-USERNAME> placeholder with the username.","title":"SAP HANA Cloud"},{"location":"setup/prerequisites/delivery-unit/","text":"Create Delivery Units A delivery unit (DU) is a group of transportable packages that contain objects used for content delivery. You can use the SAP HANA Application Lifecycle Management to create a DU for your application content or your software component. SAP Help Portal For more information, see Create a Delivery Unit . Prerequisites To create a delivery unit with the SAP HANA Application Lifecycle Management, you must ensure the following prerequisites are met: You have access to an SAP HANA system. You have the privileges granted by a role based on the SAP HANA sap.hana.xs.lm.roles::Administrator user role template. The vendor ID is defined for the DU; the vendor ID defines the repository namespace in which the new DU resides. Context You use a DU to transport the design-time objects that are stored in the SAP HANA repository between two systems, for example, from a development system to a consolidation system. To create a new delivery unit using the SAP HANA application lifecycle management, perform the following steps. Steps Open SAP HANA Application Lifecycle Management. SAP HANA Application Lifecycle Management is available on the SAP HANA XS Web server at the following URL: http://<WebServerHost>:80<SAPHANAinstance>/sap/hana/XS/lm Choose the PRODUCTS tab. Choose the Delivery Units tab. Choose Create . The New Delivery Unit dialog box appears. Enter details for the new DU. When entering details, note the following points: Name This field is mandatory and you must follow strict naming conventions. For example, you must use capital letters. Vendor This field is mandatory. However, you cannot enter a vendor here. The box is populated by the value you enter when defining the vendor in the SETTINGS tab. Version Version numbers must take the form #.#.# , for example, 1.0.5 , where: 1 - the DU version number. 0 - the support package version (if required). 5 - the patch version (if required). Note The numbers you enter here refer to the application component that you are developing. The numbers do not refer to the patch or service-pack level deployed on the SAP HANA server. Choose Create . The new delivery unit is added to the SAP HANA repository in the namespace specified by the vendor ID and the application path. Check the status bar at the bottom of the browser window for error messages. Choose the message link to display the message text.","title":"Delivery Unit"},{"location":"setup/prerequisites/delivery-unit/#create-delivery-units","text":"A delivery unit (DU) is a group of transportable packages that contain objects used for content delivery. You can use the SAP HANA Application Lifecycle Management to create a DU for your application content or your software component. SAP Help Portal For more information, see Create a Delivery Unit .","title":"Create Delivery Units"},{"location":"setup/prerequisites/delivery-unit/#prerequisites","text":"To create a delivery unit with the SAP HANA Application Lifecycle Management, you must ensure the following prerequisites are met: You have access to an SAP HANA system. You have the privileges granted by a role based on the SAP HANA sap.hana.xs.lm.roles::Administrator user role template. The vendor ID is defined for the DU; the vendor ID defines the repository namespace in which the new DU resides.","title":"Prerequisites"},{"location":"setup/prerequisites/delivery-unit/#context","text":"You use a DU to transport the design-time objects that are stored in the SAP HANA repository between two systems, for example, from a development system to a consolidation system. To create a new delivery unit using the SAP HANA application lifecycle management, perform the following steps.","title":"Context"},{"location":"setup/prerequisites/delivery-unit/#steps","text":"Open SAP HANA Application Lifecycle Management. SAP HANA Application Lifecycle Management is available on the SAP HANA XS Web server at the following URL: http://<WebServerHost>:80<SAPHANAinstance>/sap/hana/XS/lm Choose the PRODUCTS tab. Choose the Delivery Units tab. Choose Create . The New Delivery Unit dialog box appears. Enter details for the new DU. When entering details, note the following points: Name This field is mandatory and you must follow strict naming conventions. For example, you must use capital letters. Vendor This field is mandatory. However, you cannot enter a vendor here. The box is populated by the value you enter when defining the vendor in the SETTINGS tab. Version Version numbers must take the form #.#.# , for example, 1.0.5 , where: 1 - the DU version number. 0 - the support package version (if required). 5 - the patch version (if required). Note The numbers you enter here refer to the application component that you are developing. The numbers do not refer to the patch or service-pack level deployed on the SAP HANA server. Choose Create . The new delivery unit is added to the SAP HANA repository in the namespace specified by the vendor ID and the application path. Check the status bar at the bottom of the browser window for error messages. Choose the message link to display the message text.","title":"Steps"}]}